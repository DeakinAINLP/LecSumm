 Clustering Distance Metrics  Euclidean distance 2:22pm  Straight line distance between two points  Cityblock/Manhattan distance 2:20 pm  Measuring distance between two points, using distance measurement with city  block distance using grid-like system Find horizontal distance and vertical distance  Absolute value, not negative values  Chebyshev distance 2:24pm  Distance between two points in grid like distance similar to manhattan distance  and using only the maximum value of the distance between two points,  Minkowski distance 2:25pm   Is a generalization of these distances using a p-norm form.  Mahalanobis distance 2:28pm  Another distance matrix, instead of find the distance between two points, not only takes account of two point and also cares about the correlation and distribution of the data of these two features  Multiplying the variance of the data and removing the bias from the data  If data is independent it will be the same as Euclidean distance.   Jaccard distance 2:33pm  Measuring distance between TWO SETS instead of two vectors Using this finding the similarities between features  Clustering Algorithms 2:37pm  Have to group objects of similar properties together  There are two algorithmic goals    Intra-distance, where we minimize the distance between points in the same cluster. TO find how close they are. Inter-distance, where we maximize the distance between points from different clusters   3 steps 2:40pm  Define distance metric between objects Define objective function in find a proper cluster, takes the input data  K-Means 2:43pm  K represents number of clusters Randomly assigns points as a centroid creating clusters, then choosing and  moving centroids by calculation based on retrieving new point data, it will iterate until the clusters will not change anymore.  Disadvantage in K-mean, it tries to generate those k centroids randomly and you  are not getting the proper clusters needed.  Evaluation of clustering 2:48pm  External assessment, Internal Assessment There will be a sample of ground truth(C) Rand Index  Rand Index can be used for evaluating clustering, measuring similarities  between the ground truth and the generated clusters.  Purity 2:52pm  HOw similar the clusters are assigned, where it divides the amount of correctly classified by the total number of elements in each cluster.  Mutual Information 2:55 pm   Find out how similar they are using mutual information, where C’ clustering is Silhouette Coefficient 2:58pm  Measure how similar an object is to its own cluster compared to other  clusters  Doesn’t use ground truth(C)  Finding the average distance between the instances   Limitations of Kmeans 3:01pm  Random initialisation means, meaning you will get different clusters each time We need to give a number of clusters beforehand Can’t find cluster of arbitrary shapes Can’t detect noisy data points   Finding the number of clusters  Elbow method Revisited in 3:20pm  Find the best number of k clusters  Using sum of squared error  Find the best lowest cluster number with a low score of sum of squared error that has decreased significantly.  Kmeans++ 3:07pm  Start with allocating one cluster centre randomly, then search for other  centroids given the first one  Other Clustering Algorithms 3:13 pm  Need to explore hierarchical based clustering, density based clustering  and shape based clustering  Hierarchical based clustering Clustering algorithm trying to group  clustering where it starts with all data being a cluster then adding close data into one cluster called Agglomerative clustering while Divisives clustering is the opposite that starts with one cluster and then splitting into multiple clusters.    density based clustering Using euclidean distance, we use user-defined parameters and set a minimum number of data points and distance which will be used to create clusters.  Has 3 core concepts, core points are points in the dataset with a minimum number of neighboring data points within a certain distance.  Border points are points that have fewer neighbors than the  minimum but are still within the defined distance of the core point  shape based clustering Working with geometric shape, extracting features in a object, trying to put similar objects together  Kmeans Clustering in Python     Learnt how to load in data and use the elbow method to find the optimum k value in order to model the Kmeans cluster Learnt how to find the purity scores of the Kmeans clustering using the true cluster index and the predicted cluster index. Learnt the general idea of DBSCAN clustering and finding the purity score    