Summarise the main points that were covered. Main points covered in topic 3 of the unit content:    Clustering, which can help to find insights from unlabelled data.   Ways to measure the distance between data points. For example, Euclidean Distance, Cosine Distance, Mahalanobis distance, Manhattan distance, Minkowski distance, and Jaccard distance.   Kmeans.   Evaluating the performance of clustering tests. These evaluation methods fall under two categories, external assessment, and internal assessment. Some example of evaluation methods discussed were rand index, purity, silhouette coefficient, etc.    The elbow method for finding the optimal number of clusters.  Reflection My reflection on the knowledge gained this topic from reading the unit contents for this topic with respect to machine learning.  This is a reflection on the knowledge that I gained during topic 3 in regard to machine learning. Above I also listed the main points that were covered in the unit content, that also doubles as knowledge related to machine learning that I gained this topic.  This topic I was introduced to ways to measure the distance between data points. I enjoyed spending time to understand the math/process behind the measurements when reviewing the unit content this topic.  I learnt about the Kmeans algorithm for clustering that is used on unlabelled data sets. In the unit content there were videos with pictures that demonstrated the step-by-step process of the algorithm which I found helpful. While working on the practical coding task I also learnt to understand kmeans++, which is similar but uses a slightly different technique for initialising the starting centroids for the data set.  I gained knowledge about different performance metrics in machine learning. I also was able to spend time programming the Purity method, and Silhouette Coefficient during the programming exercises. I also learnt how to find the classification report with Python which contained information such as the F1 score, but I found it to be not as useful for the clustering/unsupervised learning tasks in the topic 3 programming tasks (compared to the other methods).  I was introduced to the elbow method, which can be used as an option when finding the optimal number of clusters for a particular dataset. The value can be found by viewing the graph and finding the elbow point of the line. This value can then be used as the parameter for the number of clusters when initialising the Kmeans algorithm.  