 topic 3 was on clustering techniques, an essential component of unsupervised learning that helps discover paterns and structures in unlabelled data.  The fundamental concepts and techniques covered this topic include:  K-means Clustering A prevalent clustering technique that divides data into K clusters by minimising the sum of squared distances between data points and their respective cluster centroids. The procedure assigns points to the nearest centroid and recalculates the centroid positions until convergence is achieved.    K-means++ A modiﬁcation to the K-means algorithm that addresses the problem of initialising centroids. K-means++ selects the initial centroids in a more strategic manner, which can result in quicker convergence and improved clustering outcomes.  Optimal K Value Selecting the optimal number of clusters is crucial for the K-means algorithm's eﬃcacy. By evaluating the quality of clusters based on intra-cluster and inter-cluster distances, a number of techniques, such as the Silhouete Coeﬃcient, can help determine the optimal K value.  DBSCAN DBSCAN is a method for identifying clusters based on the density of data points. It can detect arbitrary shapes and exclude noise points, and it groups points that are densely clustered. The algorithm necessitates the adjustment of two parameters: eps (distance threshold) and min_samples. (minimum points required to form a dense region).  Metrics for Evaluating Performance It is essential to evaluate the quality of clustering results to ensure that the selected algorithm is eﬀective. Several metrics, including the Silhouete Score, Calinski-Harabasz Score, and Davies-Bouldin Score, can be used to evaluate the performance of clustering.  