 In the topic three online class we mainly learnt about clustering, which is one of the forms of  unsupervised machine learning. We discussed distance metrics and its examples such as nearest  neighbor  classification  and  image  retrieval,  distance  measurement  types  such  as  Cityblock/Manhattan distance, Euclidean distance, Chebyshev distance, Minkowski distance,  Cosine distance, Mahalanobis distance and Jaccard distance.  During the second half of the class, we learned about the usage clustering algorithms and then  we discussed about Kmeans, which is the most popular clustering algorithm and how it works.  Next, we went through the two main categories of evaluation methods for clustering that are  internal and external assessment. We also talked about rand index, purity, mutual information  and silhouette coefficient. After that we concentrated on the limitations of Kmeans algorithm  and  how  to  finding  the  number  of  clusters  using  the  elbow  method.  We  also  learnt  what  Kmeans++ algorithm is and the differences of it over Kmeans algorithm. Finally, we briefly  discussed  some  other  clustering  algorithms  including  density  based  clustering  such  as  DBSCAN,  Hierarchical  based  clustering  such  as  agglomerative  hierarchical  clustering  and  shape based clustering such as VAT and iVAT.  In  the  programming  part  of  this  unit,  we'll  learn  how  to  use  Python  packages  to  create  unsupervised models, reduce dimensionality of the data and how to visualize high dimensional  data.  In  this  topicâ€™s  workshop,  we  acquired  hands-on  experience  on  Kmeans  clustering,  2D  correlated and uncorrelated data related functions and plotting.  