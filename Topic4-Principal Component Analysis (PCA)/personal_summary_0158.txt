 This topic's focus was on clustering, a machine learning technique that groups similar data points or objects together. The topic began with a discussion on distance metrics, which are used  to  determine  the  degree  of  similarity  or  dissimilarity  between  data  points.  Various distance  measurement  types  such  as  Cityblock/Manhattan  distance,  Euclidean  distance, Chebyshev distance, Minkowski distance, Cosine distance, Mahalanobis distance, and Jaccard distance were covered in detail. Then proceeded to explore different clustering algorithms, with a particular emphasis on the widely used K-means algorithm. Topics covered included how K-means works, its limitations, and techniques for evaluating clustering results. Additionally, we learned methods for finding the optimal number of clusters in a dataset. Furthermore, we examined K-means++, a modified version of K-means that addresses some of its limitations. K-means++ achieves better accuracy by selecting better initial cluster centres. In  summary,  this  topic  provided  a  comprehensive  understanding  of  clustering  techniques, distance  metrics, and their applications in machine  learning. The knowledge gained will be useful in developing accurate and effective machine learning models in the future.  