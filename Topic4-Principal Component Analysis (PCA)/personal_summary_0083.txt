 There are multiple ways to measure distance between data points. One common  distance metric is euclidean distance which calculates the straight line distance between two points. Others include cosine similarity, Mahalanobis distance, and cityblock/manhattan distance  clustering is a technique in machine learning that involves grouping similar data points together. Kmeans is the most commonly used clustering technique that  works by assigning data points to a cluster based on itâ€™s closest centroid, moving those centroids based on the average position of each cluster, then repeating until no significant change occurs  There are many methods of evaluating clustering such as rand or purity. The most common one being the mutual information approach that essentially  compares two clustering assignments to determine how much they agree on.  Kmeans assigns the initial centroids randomly which can make it take longer to  reach convergence. Kmeans++ aims to aid this by assigning centroids by  randomly assigning one centroid, noting the distance between all the data points  and that centroid, then choosing a new centroid based on probability where  further away is more likely to be chosen.   