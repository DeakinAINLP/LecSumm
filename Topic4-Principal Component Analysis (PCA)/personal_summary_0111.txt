Topic 3 summary  The topic for this topic’s discussion is unsupervised learning.  Diﬀerent Distance Metrics:   Euclidean Distance: Euclidean distance is the ordinary straight-line distance between two points in Euclidean (everyday) space.   Cosine Distance: The cosine of the angular distance between two vectors.   Mahalanobis Distance: The Mahalanobis distance (MD) is the distance between two points in multivariate space.   Manha(cid:425)an/City block Distance: Distance between two vectors measured along axes at right angles.   The Minkowski distance: Deﬁnes a distance between two points in a normed vector space.   The Jaccard distance: Distance used to measure diversity of any two sets.  Diﬀerent methods of clustering:   K-means: In this algorithm, k represents the center points or centroid of clusters. You start oﬀ with these centroids and then measure teach data point to ﬁnd its closest centroid.  o Elbow method is used to ﬁnd the ideal number of clusters for a dataset.  o Kmeans++ is an algorithm used choosing the initial cluster’s center values or centroids for the Kmeans clustering algorithm.   Hierarchical Clustering: These are algorithms that ﬁnd clusters that have a predetermined order.  o Agglomerative clustering (bo(cid:425)om-up): A “bo(cid:425)om up” approach in which each observation starts in its own cluster, and pairs of clusters are merged as one moves up the hierarchy.  o Divisive clustering (top-down): A “top down” approach in which all observations start in one cluster, and splits are performed as one moves down the hierarchy.   DBSCAN: Clustering algorithm that clusters certain items in a group based on a given data point.   Shape-based clustering, VAT: Visualization technique that transforms the distance matrix of a dataset into a visual representation in the form of a re-ordered matrix.        Evaluation metrics:   External assessment: compare clustering performance against a known clustering (o(cid:332)en called Ground truth or gold standard).  o The Rand index: measure of the similarity between two data clusters.  o Purity: measure the purity for all clusters in terms of class labels of the data in each cluster.  o Mutual Information: It measure the agreement between two clustering assignments.   Internal assessment: determine if clustering follows certain intrinsic assumptions  o The silhoue(cid:425)e value: measure of how similar an object is to its own cluster (cohesion/similarity) compared to other clusters (separation/diﬀerence).  I refer W3school website for python programming. The greater part of learning is from the classes and the workshops.   