 ● This topic we learn about Clustering, which is an unsupervised Machine Learning (ML)  algorithm. Clustering is a way to identify/classify similar data points in a dataset ● To find similar points, we need to find the distances among them and based on the  theory that the closer the points are in terms of their features, the more similar they are to each other.  ● There are multiple ways to find distances among the data points such as Euclidean distance, cosine distance, Mahalanobis distance, Cityblock/Manhattan distance, Minkowski distance, and Jaccard distance. These distance measures are used by many ML algorithms.  ● Humans have an inherent ability to search for patterns in seemingly random things. Most of the time we are looking for patterns in visual stimulations but sometimes we are also able to catch patterns that could be numerical, graphical, olfactory, or audible. But one major drawback is that we are limited to how many dimensions/features we can process simultaneously.  ● Unlike humans, machines work at a much higher capacity than humans. They can  process higher-dimension data and can look for patterns that we cannot. But to achieve this we need to make sure we are using the appropriate models with good tunning parameters that yield the best results.  ● One of the popular clustering algorithms is KMeans clustering. The “K” in KMeans  stands for the number of centroids to be located for the clusters. It works on randomly assuming centroids and then by finding the nearing data points in the clusters it works its way to the central mean of the cluster where it does not change even after n iterations.  ● Some limitations of KMeans are that it cannot find patterns of arbitrary shapes, it cannot detect noise in the data, the number of clusters is to be supplied beforehand and random initialisation may result in different outcomes each time we run the algorithm.  ● One way to combat the random initialisation is to use the KMeans++ algorithm which initialises one cluster centroid randomly and then works its way towards the best solution.  ● Other clustering algorithms that are also popularly used in the industry are Hierarchical  clustering, DBSCAN, and Shape-based clustering (VAT and iVAT).  ● After we have performed the clustering algorithms, we need a way to determine if the  model has learnt what was expected and if the outcome is affected by unknown factors. This step is called the evaluation step where we test the model’s performance and determine how it fits with our expectations  ● Evaluation can be done using several metrics like Rand Index, Purity, Mutual Information  and Silhouette coefficient  ● Further, we study how to apply KMeans clustering in Python using the famous sklearn package and then evaluate the performance using the metrics available in the same package.  