This topic's focus was on unsupervised machine learning, which involves clustering and measuring distances between data points. Clustering is a process of grouping data into similar sets, and Kmeans is the most commonly used algorithm for clustering. It starts by randomly selecting a centroid, assigns data points to the nearest centroid, and updates the centroid based on the mean of the assigned data points. This process is repeated until the centroid no longer changes significantly. We also discussed the evaluation of clustering algorithms, which is important to determine their effectiveness. Two commonly used metrics are silhouette score and inertia. Silhouette score measures how well each data point fits into its assigned cluster, while inertia measures the sum of squared distances between each data point and its assigned centroid. While Kmeans is popular, it has limitations such as sensitivity to initial centroids and a tendency to form spherical clusters. These limitations can be addressed with Kmeans++. Additionally, other clustering algorithms were introduced, including DBSCAN and hierarchical clustering. We learned how to implement Kmeans clustering using Python libraries such as Scikit-learn and NumPy. The performance of the Kmeans clustering algorithm was evaluated using various metrics, including silhouette score and inertia. In summary, this topic's topics covered unsupervised machine learning, clustering algorithms, their limitations, and their evaluation using Python. We learned about Kmeans and its improvement, Kmeans++, as well as other clustering algorithms such as DBSCAN and hierarchical clustering. We also learned how to implement and evaluate Kmeans clustering using Python libraries. 