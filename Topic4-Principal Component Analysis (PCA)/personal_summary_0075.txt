Topic 3 summary  Topic3 has covered the various distance and similarity measure used in developing machine learning algorithms, clustering concept and various clustering approaches. It has introduced the algorithms for unsupervised machine learning. In the unsupervised machine learning, we have approaches such as clustering, dimensionality reduction. Clustering helps to find patterns in large data sets if the data is not labelled.  The distances between different data points measurement is the fundamental of the ML algorithms. There are various measurements can be utilised depends on the nature of the data point. Distance metrics define the distance between two data instance and measure the similarity. We hace Euclidean distance, cosine distance, Mahalanobis distance, cityblock/Manhattan distance, Minkowski distance and Jaccard distance.  Clustering algorithms puts data points into groups, it groups unlabelled data objects with similar properties together, discover interesting perhaps unexpected clusters in the data and find a valid or useful organisation of the data. Kmean is the most popular clustering algorithm, k represents the centre points of clusters, start off with the centroids and then measure teach data point to find its closest centroid. We have a few limitations for kmeans, one is the assumption we have to make about the number of clusters to start with. We can use Elbow method to find the number. However, this method can be find the appropriate number which become a challenge. Except kmean, we have kmeans++ which has a little difference from kmean, it starts with allocating one cluster centre randomly and then searches for other centre given the first one. And we have two main categories of evaluation methods for clustering, one is external assessment that compare clustering performance against a known clustering. Another is the internal assessment which determine if clustering follows certain intrinsic assumptions.  Moreover, we have others clustering algorithms. One is hierarchical clustering, it find clusters that have a predetermined order. It has two types which are agglomerative clustering(bottom-up) and divisive clustering(top-down). Besides that, we have DBSCAN clustering algorithms which clusters certain items in a group based on a given data point. Lastly, we have shape-based clustering, VAT,iVAT. They are useful tools for exploratory data analysis, it get insight into the underlying structure of the data and identify the number of clusters for subsequent clustering algorithms.   