Distance Metrics(maths method)  ● Find the measurement between 2 or more data ● Measure the similarity of the instance ○ Clustering algorithms ○ K-Nearest-Neighbor ○ Support Vector Machines (SVM) ○ data visualisation ○ information retrieval ○ Ranking ● Type of Distance Metrics  ○ Euclidean distance: Calculating the straight line of two points in the euclidean space ○ Cosine distance: Cosine measurement of angle for two vectors in the high dimension  vector  ○ Mahalanobis distance: Calculating the absolute difference between the 2 points in  the multivarious space  ○ Cityblock / Manhattan distance: Distance metrics calculating the absolute  difference between the 2 points in dimension difference vectors  ○ Minkowski distance: Calculating the distance between 2 points in the normed  method space. Also generalisation of Euclidean distance and Manhattan distance  ○ Jaccard distance: Measurement of 2 sets  ■ Equation: size of intersection / size of union  Clustering Algorithms  Kmeans  ● Partition data into k clustered depending on similar data point ● Works on unlabelled data ● K = central point of cluster ● How does it works ?  1. Select the number of k (cluster) 2. Random select the k point as starting point 3. Assign each k to the nearest starting point (centroids) depending on Euclidean  distance 4. Recalculate 5. Repeat  Kmeans++  ● Smarter version of Kmean ● Start by randomly selecting a starting point then it select the highest minimum distance to  the starting point (a better solution)  Evaluation of Clustering  ● External assessment: Comparing between a the performance of known clustering ● Internal assessment: Find out if the clustering depends on intrinsic (Exp: Silhouette  coefficient, Dunn index, etc…)  Rand Index: Measuring similarity by comparing 2 sets of data clusters. Rand index range from 0(no similarity) to 1(perfect similarity)  Purity: Evaluation method for clustering. Measurement to check how data points are labelled in different groups.  Mutual Information To check how much information a group of clusters can say about another group. Check the similarity of two group cluster  Silhouette Coefficient Finding the similarity about the cluster in a group compare to other cluster.  Other Clustering Hierarchical clustering:  ● Search for clusters that have a predetermined order ● 2 types:  ○ Agglomerative clustering (bottom-up): starts in its own object(cluster), and pairs of objects are grouped together as one moves up the hierarchy. Each cluster merge together until one cluster remain  ○ Divisive clustering (top-down): Start by splitting / dividing the cluster until the cluster  only have one object (cluster is by itself)  DBSCAN (Density-Based Spatial Clustering of Applications with Noise)  ● Cluster specific item in group depending on the data (highest density region) ● How does it starts ?  a. Choose one random point that has been visited b. While searching for each point (core point) calculate the distance and it is only counts(combine) as a core point if the number of the data is at least the same between the distance  c. Border points are define there are not core point within the distance and the rest are  call “noise”  d. The process will continue until there are no more point  Shape-based clustering, VAT, iVAT  ● VAT (Visual Assessment of cluster tendency ): A visualisation technique that visualises the distance matrix of a dataset. The rearranging of clustering until it display the underlying cluster structure  ● iVAT (iterative VAT): apply VAT algorithm repeatedly to rearrange the matrix to refine the  structure. It repeats until the clustering is stable.    