In this topic we focused learning about unsupervised machine learning which is majorly discussed as Clustering and Dimensionality reduction. We studied clustering concepts, Distance matrices and its types. We studied distance measurement and its different types like Euclidean distance, Cosine distance, Mahalanobis distance, cityblock distance, Minkowski distance and jaccard distance.  Clustering algorithm do not rely on data labels to classify the data points. Different Clustering algorithms are used on the basis on nature of data and desired outcome for various applications like anomaly detection, customer segmentation, image segmentation and recommendation systems.  K-mean initializes the centroid randomly then assigns each data to nearest centroid and again calculates the centroid of every cluster, this process is repeated until maximum number of iterations are reached. K-means++ algorithm initializes the k centroids in a smarter way to get better result, it’s an advanced version of k-means algorithm. Hierarchical clustering does not require number of clusters to be specified previously, It’s output is tree like structure, which can be cut at a certain level to obtain specific number of clusters. It’s capable of finding nested clusters. Density based clustering algorithm group together high-density region data and separates the low density region ones. It uses Epsilon and minimum points to specify the distance between two points and minimum number of points needed to form a dense region. Shape based clustering is done by grouping the data points together on the basis of geometrical shape. It is applied on various domains like computer vision, pattern recognition and bioinformatics. It is used to identify the clusters with complex shape and non-linear boundaries.     