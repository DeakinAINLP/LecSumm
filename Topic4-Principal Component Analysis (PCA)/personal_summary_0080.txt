Topic 3 clustering Machine learning  Measuring distances  Definition and Properties  Measuring similarity or distances between data points is fundamental to many machine learning algorithms. We will be looking at these issues this topic.  The most related examples in machine learning are:  ● clustering algorithms (we looked at examples of clustering last topic) ● K-Nearest-Neighbor ● Support Vector Machines (SVM) ● data visualisation ● information retrieval ● Ranking  Different distance metrics  You will see the following distance measures being demonstrated:  ■ Euclidean distance ■ Cosine distance ■ Mahalanobis distance ■ Cityblock/Manhattan distance ■ Minkowski distance ■ Jaccard distance  Clustering Algorithms  Clustering puts data points into groups. It uses similarity and difference of features (or dimensions) to create groups in material that is unclassified and has no known targets. It’s particularly used in unsupervised learning as it can deal with vast amounts of uncategorised data however it creates groups so it’s useful in supervised learning as well  K-means  ● Assigning data points to clusters based on the currently defined centroids  (points which are the centre of a cluster).  ● Choosing centroids based on the current assignment of data points to  clusters.  Evaluation of Clustering  ● Rand Index ● Purity ● Mutual Information ● Silhouette Coefficient  Other clustering algorithms  ● Kmeans (as we know) ● Hierarchical clustering ● DBSCAN (density based) ● Shape-based Clustering  