Topic 3 unsupervised machine learning  Summarizing all the important topics from this topic:  1. Definition and Properties  ● Distance metrics  Distance metrics are used widely in machine learning algorithms. Distance measures are functions that define a distance d(xi,xj) between any two data instances xi and xj The most related examples in machine learning are:  1. clustering algorithms (we looked at examples of clustering last topic) 2. K-Nearest-Neighbor 3. Support Vector Machines (SVM) 4. data visualization 5. 6.  information retrieval ranking  2. Types of distance measurements ❖ Euclidean distance: ❖ Euclidean distance is the ordinary straight-line distance between two points in Euclidean (everyday) space. For any two data instances, represented by d-dimensional feature vectors xi,xj their Euclidean distance is computed as  ❖ Cosine distance: ❖ We previously introduced cosine distance in course 1. But as a reminder, we  define Cosine distance for any two data instance represented by d- dimensional feature vectors xi,xj The Cosine distance for these two feature vectors are computed as:  ■  ❖ Mahalanobis distance  ■ The Mahalanobis distance (MD) is the distance between two points in multivariate space. For any two data instances, represented by d- dimensional feature vectors xi,xj their Mahalanobis distance is computed as:  ■  ❖ City Block//Manhattan distance ❖ For any two data instances, represented by d- dimensional feature vectors ❖ Xi,xj their Cityblock distance is computed as:  Sharon Abraham Shaji 222555241  ❖ ❖ Minkowski distance: ❖ The Minkowski distance defines a distance between two points in a normed vector space. Think of Euclidean distance (2 norm of xi, - xj) and Cityblock distance as (1 norm of xi - ,xi ) Minkowski distance is a generalization of these distances defined for any p-norm.  ❖ ❖ Jaccard distance: ❖ The Jaccard distance is a distance used to measure diversity of any two sets. Consider any two instances xi and xj as binary vectors indicating presence or absence of features. Jaccard distance between xi and xj is defined as:  ❖  3. Clustering and its applications  ● Clustering Algorithms:  Clustering puts data points into groups. It uses similarity and difference of features (or dimensions) to create groups in material that is unclassified and has no known targets. It’s particularly used in unsupervised learning as it can deal with vast amounts of uncategorised data however it creates groups so it’s useful in supervised learning as well.  4. How Kmeans Works  The most popular clustering algorithm in machine learning is called K-means.  5. Evaluation of Clustering  ❖ Evaluation of clustering methods is not easy. But, generally there are two  main categories of evaluation methods for clustering:  ❖ External assessment:  ➢ compare clustering performance against a known clustering (often  called Ground truth or Gold standard).  ❖ Internal assessment:  ➢ determine if clustering follows certain intrinsic assumptions (e.g.  cluster-to-cluster distance or cluster size etc.).  ■ Examples: ■ Silhouette coefficient, Dunn index etc  Sharon Abraham Shaji 222555241  6. Limitations of Kmeans  ❖ Kmeans clustering has a number of limitations. ❖ The most important limitations of simple Kmeans are:  ❖ Random initialisation means that you may get different clusters each time. As a solution, we can use a Kmeans++ initialisation algorithm to initialise better.  ❖ We have to supply the number of clusters beforehand. We can use the  Elbow method to choose but it may not be straightforward.  ❖ It cannot find clusters of arbitrary shapes. ❖ It cannot detect noisy data points, i.e. data points that should not be taken into account for cluster analysis. (The K-median method is less affected but cannot identify noisy data points either.)  7. Other clustering algorithms  Kmeans is one of the most popular clustering methods in machine learning but it is not the only clustering algorithm. there are two more clustering methods:  ● Kmeans (as we know) ● Hierarchical clustering ● DBSCAN (density based) ● Shape-based Clustering  8. Kmeans Clustering with Python 9. Evaluating performance of Kmeans clustering  performance metric  A. Purity B. Mutual Information C. Silhouette Coefficient D. f1 E. recall F. accuracy G. precision  Reflection: This topic's focus was on machine learning, its definition, real-world applications, and its different types, including supervised, unsupervised, and reinforcement learning. We also learned about the necessary steps involved in machine learning, such as data manipulation, analytics, exploratory data analysis, and refinement. In terms of mathematics, we explored  vectors, matrices, and probability, as well as Python programming for machine learning using various modules and packages. Overall, this topic's material provided a comprehensive introduction to the fundamentals of machine learning and its mathematical foundations.  Sharon Abraham Shaji 222555241  