Unsupervised Machine Learning:  Topic -3  In general, Machine learning algorithm deals with dataset which have inputs labelled and with outputs for the algorithm to find underlying relationship between input and output (i.e., Supervised learning algorithm ). But in cases where we don’t know the output and the inputs are not labelled such algorithm can’t find the underlying pattern. In such cases, we make use of Unsupervised algorithms which deals with such datasets.  In Unsupervised learning method, it focuses on finding the similarities and grouping the datapoints based on the distance between them which is known as Clustering. The distance between these datapoints is used to identify the similarities between the them.    Euclidean Distance   Cosine Distance   Mahalanobis Distance   Cityblock /Manhattan Distance   Minkowski Distance  Jaccard Distance  The data points are measured based on these metrics. These metrics are also used in Supervise Machine learning.  The most popular Unsupervised machine learning algorithms are Clustering algorithms, Hierarchical Clustersing and Data visualization.  Cluster:  Clustering algorithms focuses on clustering datapoints together based on distance between them and their centres and creating imaginary partitions between them such that the datapoints don’t overlap between them. Cluster algorithm is one of the simplest and most commonly used.  In general, clustering algorithm does the following steps:  1.  The algorithm focuses on randomly selecting the datapoints to a centroid. 2.  Then the algorithm focus on measuring the distance between centroids and datapoints using  the metrics distances to calculate the similarity and dissimilarity among them.  3.  Then clustering algorithm based on the distance between datapoints and centroid assigns  them to a cluster.  4.  After data points are clustered together, the algorithm focuses on searching new centroid  based on the cluster centroid.  5.  Clustering algorithm is iterative process and repeats step 3 and 4 until the centroids no  longer moves.  One of the most popular Clustering algorithms is Kmeans.  Kmeans algorithm a datapoint is considered to a part of specific cluster based on the distance between the datapoint and centroid. K-means algorithm focus on selecting the best centroid within the cluster which defines the cluster best. This algorithm focuses on alternating between two steps which are iterative.  1.  Assigning each data point to the closet cluster centre.  2.  Then setting each  cluster as the mean of the datapoint that are assigned to it .  Another popular method of cluster algorithm is K-means++ algorithm. Unlike K-means algorithm focuses on randomly assigning data points as its centre. While in K-means++ algorithm does initially starts with randomly selecting centroid after which it starts selecting centroid based on the empirical probability distribution of the points . This gives the algorithm a better start at the initial.  Hierarchical clustering:  In this method the each cluster are considered to be individual clusters and then merges closest clusters to together as one. This process is repeated until all the datapoints are clustered into different groups based on the distance between these datapoint until one single cluster remains.  There are two methods of approaches for Hierarchical clusters:  1.  Agglomerative Clustering: The bottom-up approach, here the datapoints are considered as individual clusters and merged together until one big cluster creating an hierarchy from bottom to top.  2.  Divisive clustering : this approach is the reserves of divisive clusters, from one huge cluster the data points are divided into individual clusters, maximizing the distance between the datapoints.  DBSCAN (Density based spatial clustering of Application with Noise):  DBSCAN is a clustering algorithm which doesn’t require information on how many cluster are needed prior. Instead DBSCAN focuses on areas with large number of datapoints gathered. These points are referred as dense regions. The two parameters of DBSCAN :-  1.  Min_samples = number of data points to be consider a region as dense 2.  Eps = the most important parameter in a DBSCAN cluster, it determines the distance from  which data points should pick its neighbour.  Evaluation of Clustering Algorithm:  Evaluation of clustering algorithm is very to hard to evaluate it, There are two types of evaluations used to evaluate cluster algorithm.    External Assessment: This approach uses Groundtruth clustering , the most important in    method are Adjusted rand index(ARI) and normalized mutual information(NMI) Internal Assessment: This method of approach is used to measure the quality of the clusters produced. Such as Silhouette coefficient , Sum of squared errors .  