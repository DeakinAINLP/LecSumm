 1.  Definition:  Clustering  is  a  type  of  unsupervised  machine  learning  which involves  pattern  recognition  by  virtue  of  grouping  and  identifying  similarities between the data points.  2.  Distance metrics: distance is usually used as a metric to estimate similarity between 2 data points. For a distance measure to qualify as distance metrics, it needs to satisfy the following criteria:    The distance of an instance xi with itself is zero.   Symmetry. D(xi, xj) = D(xj, xi)   Distance measure must follow triangular inequality.  3.  Distance Measurement Types: We then explored the various ways in which  we can calculate distance between data points, such as: Cityblock/Manhattan distance i. Euclidean distance ii. iii. Chebyshev distance iv.  Minkowski distance v. vi.  Mahalanobis distance Jaccard distance  4.  Clustering  Method:  In  general,  we  need  to  find  a  way  to  minimize  intra  distance and maximize inter distance. Step1: Define a distance metric between objects Step2: Define an objective function Step3: Devise an algorithm to optimize the objective function  5.  K-means  Clustering  Algorithm:  We  then  shifted  focus  to  the  k-means clustering algorithm in particular which assumes random centroids and assigns each data point to a centroid. In further iterations it optimizes the centroids and data points belonging to that centroid.  6.  Disadvantages of K-means:  Initial centroids are chosen randomly We have to mention no. of centroids beforehand  i. ii. iii.  We cannot find clusters of arbitrary shapes iv.  We cannot detect noisy data points  However, we can overcome (i) using the K-means++ algorithm which logically chooses the initial set of centroids.        7.  Evaluation  of  Clustering:  We  learnt  about  various  evaluation  techniques between  the  ground  truth  and  reality  through  methods  such  as  rand  index, purity score, mutual information and silhouette coefficient.  8.  Optimal k value: We learnt about the elbow method and how we can determine  the number of centroids without overfitting.  9.  Other  Clustering  Methods:  Lastly,  we  briefly  learnt  about  other  clustering  methods such as: i.  Hierarchical Clustering: Tries to group similar data points in a hierarchy using a bottom-up approach. Eg. Agglomerative hierarchical clustering. Density Clustering: Where we define the minimum number of points required to form a cluster and an epsilon value. Eg. DBSCAN Shape-based Clustering: Mainly used in image processing. Eg. VAT and iVAT  ii.  iii.            