 This topic's content was all about clustering of data and focussed on K-means in particular. The first lot of content covered the different methods for calculating distance between points in a dataset such as euclidean distance, cosine distance and Jaccard distance.  We then went over K-means clustering and how it actually works. A value K is selected which represents the number of centroids used for defining clusters within the dataset. The distance is then measured between each point in the dataset to the centroids. The point is then classed as part of the closest centroid in the dataset. After each distance is measured to each point from each cluster, the centroids are moved to the new centre of the cluster and the process repeats until the centroids do not move from their location.  After learning how K-means works, we were then shown how to evaluate clustering. One of these methods was Purity which assigns a label to the cluster based on the majority or classified points within that cluster. The number of the majority points in each cluster is then added together and divided by the total number of data points to get a purity value. Another method was the Silhouette coefficient which measures and averages the distance between a point and all its neighbouring points in the same cluster and the point and all the other points in the other clusters. It ranges from -1 to +1 and having a value closer to +1 means it is appropriately clustered.  We then learnt how to implement a K-means clustering algorithm in python and compared its output with the K-means++ algorithm which iteratively creates centroids until k is reached.  Reflection  I have briefly gone over K-means before this unit but never fully understood it until watching a few of the videos included in the learning material. Learning the evaluation methods was also very interesting as I wasnâ€™t sure of any way to determine how well clustering had occurred but knowing that now has made it a bit easier to use K-means. This will definitely be useful in classifying large datasets into desired groups, as long as some understanding of the data is there.   