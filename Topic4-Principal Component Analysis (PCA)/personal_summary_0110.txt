 Different Distance Metrics:    Euclidean Distance: Euclidean distance is the ordinary straight-line distance between two  points in Euclidean (everyday) space.    Cosine Distance: The cosine of the angular distance between two vectors.   Mahalanobis Distance: The Mahalanobis distance (MD) is the distance between two points in  multivariate space.    Manhattan Distance: Distance between two vectors measured along axes at right angles.   The Minkowski distance:  Defines a distance between two points in a normed vector space.   The Jaccard distance:  Distance used to measure diversity of any two sets.  Different methods of clustering:    K-means: In this algorithm, k represents the center points of clusters. You start off with these  centroids and then measure teach data point to find its closest centroid. o  Elbow method is used to find the ideal number of clusters. o  Kmeans++ is an algorithm used choosing the initial cluster’s center values or  centroids for the Kmeans clustering algorithm.    Hierarchical Clustering: These are algorithms that find clusters that have a predetermined  order.  o  Agglomerative clustering (bottom-up): A “bottom up” approach in which each  observation starts in its own cluster, and pairs of clusters are merged as one moves up the hierarchy.  o  Divisive clustering (top-down): A “top down” approach in which all observations start  in one cluster, and splits are performed as one moves down the hierarchy.    DBSCAN: Clustering algorithm that clusters certain items in a group based on a given data  point.    Shape-based clustering, VAT: Visualization technique that transforms the distance matrix of a  dataset into a visual representation in the form of a re-ordered matrix.  Evaluation metrics:    External assessment: compare clustering performance against a known clustering (often  called Ground truth or gold standard).  o  The Rand index: measure of the similarity between two data clusters. o  Purity: measure the purity for all clusters in terms of class labels of the data in each  cluster.  o  Mutual Information: It measure the agreement between two clustering assignments.    Internal assessment: determine if clustering follows certain intrinsic assumptions  o  The silhouette value:  measure of how similar an object is to its own cluster (cohesion/similarity) compared to other clusters (separation/difference).  