This topics module covered the clustering aspect of unsupervised machine learning. We looked at different metrics for finding the distance between data points, clustering algorithms, and clustering evaluation metrics. The goal of this module was to understand how to analyse datasets, perform clustering, and evaluate performance of clustering, with aim of preparing unlabelled datasets for unsupervised machine learning.  The problem solving task for this module involved performing clustering using KMeans and KMeans++ on a label dataset containing data points with 64 different features. To find the optimum k values for clustering I measured the silhouette score on the clustering for various values of k. I expected to see an optimum k value of 10 for this dataset because that was the number of unique labels for this dataset. From this I found an optimum k value of 9 which may indicate that there is significant overlap on the underlying data structure for 2 of the labelled categories. As the dataset had data points with high dimensionality, it is unreasonable to try a plot the dataset to examine the performance of the clustering. To evaluate the performance of the clustering I decided to use a combination of Purity score and Mutual Information (specifically Adjusted Mutual Information which accounts for chance and is normalised so that itâ€™s easy to compare).  Over 50 trials I found that KMeans++ has constintently better performance for clustering that KMeans.  Overall I feel like I learned a lot in this module, clustering is not a topic encountered before but I found it fairly straight forward to complete this module. I made heavy use of both scikit-learn and pandas for the programming aspect of this module, with their documentation being extremely helpful (https://scikit-learn.org/stable/modules/classes.html, https://pandas.pydata.org/docs/reference/index.html).  For the quiz this topic I mainly had trouble with the wording on one of the questions, the answer being both yes and no confused me.   