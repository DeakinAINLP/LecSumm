3.1P  Summary:  3.1:  Clustering is used to find patterns in large data sets when data is unlabelled. Dimensionality reduction manages the volume of features.  3.2:  Distance measures are functions, used to gauge similarity of two data points.  For any instance of data, it has a distance to itself of 0; For an instance pairs, the distance is nonnegative and symmetric. Distance measures follow triangular inequality. Those that satisfy these requirements are distance metrics.  ▪  Euclidean distance is the straight line between two points; Cosine distance is the  cosine of the angle between the vectors.  ▪  Mahalanobis distance is the distance between two points in multivariate space. ▪  Cityblock distance computes roughly to Euclidean distance with lessened  similarity between points across a single dimension.  ▪  Minkowski distance is between two points in a normed vector space. ▪  Jacard distance measures diversity in two sets.  3.4:  Clustering algorithms are designed to group similar properties together and reveal useful patterns in data. They should minimise  distance between points of the same cluster and maximise distance between points of different clusters.  3.5:  Kmeans works by randomly assigning centroids, and groups data based on their proximity to these points. Then updating the centroid position to the centre of the current division. It does this until the centroid no longer moves significantly.  3.6:  Evaluating clustering can be done internally, where the check is made against intrinsic assumptions, or externally where the check is against a known clustering.  ▪  Rand index measures similarity between two clusters. ▪  Purity evaluates clustering methods, it checks for ‘purity’ of clustered data in  terms of class labels.  ▪  Mutual agreement measures the agreement between two clustering assignments. ▪  Silhouette coefficient uses silhouette values, the measure of similarity of a point  with its cluster.    3.7:  ▪  Kmeans may result in different clusters due to random initial centroids. ▪ ▪ ▪  It relies on cluster count being supplied. It cannot find clusters in arbitrary shapes. It cannot filter out noise in the data.  3.8:  Kmeans++ is an algorithm that can choose the initial centroids for Kmeans.  