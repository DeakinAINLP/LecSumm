Supervised learning involves providing data to a learning model with labelled or meaningful data. This could be images for a classifier model to determine whether an image is a cat or a dog, where we would provide many images labelled as ‘cat’ or ‘dog’ to train the model and then test with unlabelled images. After the training data this model would be better equipped to successfully label the unlabelled images.  As well as such classifiers, regression is another common form of supervised learning. An example of this is linear regression which plots the data and applies a regression model (regression meaning to measure the difference between data and a target) to plot a line through the most populated  area of the axis. This line indicates the direction of the data and acts as a point of reference to measure how much variance there is across the data by measuring the distance from the points to the line.  This line is also indicative of the predictions that this model will produce on unlabelled data.  This idea of training the models is common across supervised learning methods with a common method of splitting the dataset is into a 70:30 split of training data and test data respectively.  We can mix up and re-arrange or randomise the training and test data and test over multiple iterations in order to maximise the training to the model without oversampling to the training data. Such methods for how we split and organise the training data are random subsampling, stratified sampling and cross validation.  The overall goal of a supervised learning method is to create a function which is as close to the actual function of the data provided. The closer the function being used by the model is to the actual function the more accurate the predictions will become.  Model complexity is also a factor, as a more complex model will be more inclined to ‘overfit’ meaning to adhere itself to the variance of the data too much which takes away from the wholistic accuracy of the model, or to ‘underfit’ meaning to ignore too much of the variance which will miss important insight into the data.     