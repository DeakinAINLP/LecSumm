Topic 5: Fundamentals of supervised learning  Supervised learning is a type of machine learning where the algorithm learns to predict output variables based on input variables. In supervised learning, the model is trained on a labeled dataset, where the input variables are paired with their corresponding output variables.  There are several forms of supervised learning, including:  Regression: In regression, the output variable is a continuous value. The algorithm learns to predict a numerical output based on input variables. Linear regression, polynomial regression, and decision tree regression are some common regression algorithms.  Classification: In classification, the output variable is a discrete value. The algorithm learns to classify input variables into different categories or classes. Some common classification algorithms are logistic regression, decision tree classification, and support vector machines, neural networks  Ranking Problems:  A supervised learning algorithm:  In supervised learning, the algorithm tries to learn a mapping function that maps input variables to output variables. This mapping function is typically represented by a hypothesis space, which is a set of possible functions that the algorithm can learn.  To find the best function in the hypothesis space, the algorithm tries to minimize a loss function, which measures the difference between the predicted output and the actual output. The loss function captures how well the function fits the training data. The objective of supervised learning is to find the function that minimizes the loss function.  The process of finding the function that minimizes the loss function is called empirical risk minimization. The empirical risk is the average loss of the function over the training data. The algorithm learns the function that minimizes the empirical risk.  Model complexity refers to the ability of a machine learning model to capture the underlying patterns in the data. A model with high complexity can capture complex patterns in the data, but it may also overfit the training data and perform poorly on new, unseen data. On the other hand, a model with low complexity may not be able to capture all the relevant patterns in the data, leading to underfitting.  In supervised machine learning, the choice of model complexity is often a trade-off between overfitting and underfitting. Overfitting occurs when the model fits the training data too closely, resulting in a model that is too complex and cannot generalize well to new data. Underfitting occurs when the model is too simple and cannot capture all the relevant patterns in the data.        To choose the appropriate model complexity, various techniques can be used, such as cross- validation, regularization, and feature selection. Cross-validation helps to estimate the model's performance on new data, while regularization techniques such as L1 or L2 regularization help to reduce model complexity by adding a penalty term to the loss function. Feature selection helps to select the most relevant features for the model, reducing its complexity.  Occam’s Razor, a famous problem-solving principle, is used as a heuristic guide in the development of theoretical models. This principle often paraphrased as: All other things being equal, the simplest solution is the best.  It also addresses the problem of Which hypothesis to choose if there are multiple hypothesis with similar fit?  So based on Occam’s razor and its simplistic principle, we define another risk value which is called Structural Risk.  Structural risk minimisation seeks to prevent over-fitting by incorporating a penalty on the model complexity that prefers simpler functions over more complex ones. So the general idea is to minimise both Structural Riskand Empirical Risk.  Classification metrics  The metrics that you choose to evaluate your machine learning model are very important. The choice of evaluation metrics influences how performance is measured and compared.  The most common type of machine learning applications are classification problems. There are myriad metrics that can be used to evaluate predictions for these types of problems.    Confusion matrix is a common way to evaluate the performance of a classification model. It is a table that shows the number of true positives, false positives, true negatives, and false negatives for a given model.    The ROC (Receiver Operating Characteristic) curve is a graphical representation of the  performance of a binary classifier. The ROC curve plots the true positive rate (TPR) against the false positive rate (FPR) for different classification thresholds.    F-1 Measure: The F-1 measure, also known as the F-score, is a common metric used to  evaluate the performance of a classification model. It is a weighted average of the precision and recall of the model, where precision is the proportion of true positives among all positive predictions, and recall is the proportion of true positives among all actual positive samples.The F-1 score is defined as the harmonic mean of precision and recall, where a score of 1 indicates a perfect classification, and a score of 0 indicates a random classification.  Regression Metrics:  1.  Mean Square Error: Mean Square Error (MSE) is a common metric used to evaluate the  performance of a regression model. It measures the average squared difference between the predicted values and the actual values of the target variable.  2.  Explained Variance (R^2): Explained Variance is a statistical metric that measures the  proportion of the variability in the dependent variable that is explained by the independent variables in a regression model. It is commonly used in regression analysis to determine the    effectiveness of a model in explaining the variance of the dependent variable. The Explained Variance is also known as the Coefficient of Determination or R-squared (R^2) and is expressed as a value between 0 and 1. A higher Explained Variance value indicates that the model is more effective in explaining the variance of the dependent variable.  Partitioning data for training and testing:  Some methods for partition data are:    Random subsampling: Instead of using a single split, a more reliable estimate of model  performance can be obtained by random sub-sampling. Random sub-sampling repeatedly partitions the data into random training and test sets in a specified ratio   Stratified sampling: Stratified sampling is a probability sampling technique in which we divide the entire data into different subgroups or strata, then randomly select the final subjects proportionally from the different strata.    Cross validation: In k-fold cross-validation, the data is divided into k equally sized subsets,  and the model is trained and evaluated k times, with each subset being used once for testing and the other k-1 subsets used for training.  Hyperparameters are parameters of a machine learning model that are set prior to training and are not learned from the data, unlike the model's parameters. These hyperparameters can greatly impact the performance of the model, and finding the optimal hyperparameters is crucial for achieving the best possible performance.  A validation set is a sample of data used to provide an unbiased evaluation of a model fit on the training dataset while tuning model hyperparameters. The validation set is used to evaluate a given model and also to fine-tune the model hyperparameters.  One problem that can occur in machine learning is datasets where the total number of one class of data (i.e. positive outcomes) is far less than the total number of another class of data (i.e. negative) outcomes. This problem is very common in practice and can be detected in various disciplines including fraud detection, anomaly detection, medical diagnosis, etc. As you know most machine learning algorithms work best when the number of instances of each classes are roughly equal. When the number of instances of one class far exceeds the other, problems arise.  Issues of imbalanced classes  Now, let us have a close look on possible issues of imbalanced classes.  Problem-1: Since the test data contains only few samples from the minority class, even a dumb classifier that always classifies an instance to the majority class will get very high accuracy!  This problem is dealt with by using other evaluation metrics in place of accuracy.        Problem-2: When doing random subsampling, it is possible that class proportion is not maintained in an individual partition. In fact, we may not sample even one instance from the minority class.This problem can be solved using Stratified Sampling.     