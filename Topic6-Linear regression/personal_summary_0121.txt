 Followed by previous topic topics where unsupervised learning was covered, this topic we focused on fundamentals of supervised machine learning including key concepts and examples.  Supervised learning is used where datasets are labelled so that the algorithm can produce meaning output. The forms of supervised learning include:  Regression  -Linear regression : Analyse the relationship between a dependent variable and other independent variable  -Logistic regression : It analyses the probability of a binary outcome  Classification  -Support vector machines: Used for two-group classification to find the hyperplane  -Decision Trees: Recursively split the datasets into subsets and it learns from the training datasets to build a tree-like model  -Random forest : It learns from training datasets to build multiple decision trees to create a forest of decision trees  -Neural networks: Able to learn complex and non-linear models between input and output ta  Ranking problems – Based on model’s relevance or importance to the task, it assigns a ranking to predict target variable  Classification matrix  -Confusion matrix: Summary of prediction outputs on a classification problems and it’s commonly used to where accuracy is not a reliable metric for the real performance of a classfier.  -ROC curve: Receiver Operating Characteristics curve is used in signal detection theory and useful for domains with imbalanced class distribution and unequal classification error costs  -F-1 Measure: Used to measure performance of model’s accuracy  Regression matrix  The regression matrix is a matrix that contains the input features and output variables used to train the regression model. Each row in the matrix represents an observation or sample, and each column represents a feature or variable. The last column of the matrix contains the output variable, also known as the target variable.  Once the regression model is trained on the regression matrix, it can be used to make predictions on new, unseen data. For example, we can use the model to predict the price of a new house based on its size and location.  Mean square error - measure of the difference between the predicted values of a machine learning model and the actual values of the target variable in the dataset.  Partitioning methods  -Sub-sampling: Split datasets into smaller subsets for training and testing models by randomly selecting subset from original datasets for training and another subset for testing purpose  -Stratified sampling: Create representative subsets of data for training and testing model and it’s useful when dealing with imbalanced datasets  -Cross-validation: The dataset is divided into k-folds and this is to evaluate the performance of a model on new data  How to find the best hyperparameters  Hyperparameters must be set before training begins to find the optimal values of the model  Effect of imbalanced classes  One of the examples where imbalance data can be seen is anomaly detection. In anomaly detection, the number of anomalous instances is often much lower than the number of normal instances. This can cause the model to ignore the anomalous instances and perform poorly on detecting them.  