1)  Supervised learning can appear in many forms like regression problems, classification problems  etc.  2)  If we choose higher complexity, the data will be over fitted and if we choose lower complexity  then data will be under fitted.  3)  Structural risk minimisation seeks to prevent over-fitting by incorporating a penalty on the  model complexity that prefers simpler functions over more complex ones  4)  A confusion matrix is a summary of prediction results on a classification problem 5)  Regression measures how far the expected value is from the actual value 6)  To train a model we do partitioning of data from original samples. This technique is called cross  validation  Part 2: Summary of Reading list:  Regression alludes to prescient demonstrating issues that include foreseeing a numeric worth.  Not the same as order includes foreseeing a class mark. Not at all like order, you can't utilize characterization precision to assess the forecasts made by a Regression model.  All things being equal, you should utilize blunder measurements explicitly intended for assessing expectations made on relapse issues.  https://machinelearningmastery.com/regression-metrics-for-machine-learning/  Model complexity is a critical thought in AI. Basically, it alludes to the quantity of indicator or free factors or highlights that a model necessities to consider to make exact forecasts. For instance, a straight relapse model with only one free factor is somewhat basic, while the model with numerous factors or non-direct connections is more perplexing. A model with a serious level of intricacy might have the option to catch more varieties in the information, however it will likewise be more hard to prepare and might be more inclined to overfitting. Then again, a model with a low level of intricacy might be simpler to prepare yet will most likely be unable to catch all the important data in the information. Finding the right harmony between model intricacy and prescient power is significant for fruitful AI  https://vitalflux.com/model-complexity-overfitting-in-machine-learning/  Part 3: We have supervised learning in may forms like regression problems, ranking problems etc. We do complexity and we have to balance it to train a model because if we do higher complexity then data will be overfitted and if we do lower complexity then data will be under fitted. Regression measures how far is the actual value from original one.    