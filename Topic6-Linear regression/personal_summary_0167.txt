 Supervised Machine Learning (ML) refers to the type of ML where the output label is already known, and these  known output values are used  to train the data and later evaluate using a test dataset. Topic 5 of  Machine  Learning  (SIT720)  dealt  with  the various aspects of this supervised ML.  We started by defining Supervised ML is a different way, which is as a function that maps input data to the output label. Denoted by-  In order to estimate how well this function h fits the training data, we have something known as a “loss function”.  h: X-> Y  Essentially, Supervised ML is of 3 types-  1.  Regression (linear and logistic regression) 2.  Classification 3.  Ranking Problem  Types of Loss function are as follows:  1.  Square Loss function (useful for regression) – it is obtained by getting the  square difference between real and predicted output  2.  Absolute loss function (useful for regression) 3.  0-1 loss function (useful for classification)  Ultimately, our goal in Supervised ML is to get a line that minimizes empirical risk (which is the average of all loss functions).  Model Complexity  Model complexity refers to the flexibility of the model to the particular dataset being considered. If the model has high complexity, it runs the risk of overfitting, whereas if it has low complexity, it runs the risk of underfitting  Occam’s  Razor is  a  principle that  says  that the  simplest solution/model is the best, with  minimal  parameters  to  avoid  overfitting.  Based  on  this,  we  define  another  risk value called structural risk. Minimisation of structural risk in turn minimizes empirical risk.  Model Evaluation Metrics  1.  Classification  model  metrics:  These  include classification supervised ML algorithms, namely – i.  Confusion Matrix: with true positives, true negatives, false positives and false negatives  the  metrics  to  evaluate     ii. iii.  iv.  F1 score ROC (Receiver Operating Characteristics): is obtained by plotting True positive rate against false positive rate. The area under the ROC curve is called area under the curve (AUC) and Youden index is another useful statistic. Accuracy Score, Specificity, Sensitivity  2.  Regression  Model  Metrics: These  include  the  metrics  to  evaluate regression  supervised ML algorithms, namely – i. ii. iii. iv.  Mean Square Error (MSE) Root Mean Square Error (RMSE) Mean Absolute Error R squared error, explained variance and coefficient determination  Partitioning data for Training and Testing  In supervised ML, we partition the data into train set and test set. The train set is used to  train  the  model  to  detect  true  and  false  label  values,  and  the  test  set  is  used  to determine if the model has been effectively trained or not.  Types of partitioning are:  1.  Random sub-sampling: partitions the data into random train and test sets in a  specified ratio.  2.  Stratified Sampling: Original dataset is equally split with 50% of true cases in train and 50% in test set. This helps deal with an imbalanced dataset and also multi-class problems.  3.  Cross-validation: divides the dataset into k-fold equal sized sets. Few of these will be used as train set and one of them as test set. It is useful while dealing with healthcare data.  Finding the Best Hyperparameters  Hyperparameters are parameters of the ML models that are set before the learning process and significantly affect the performance of the model.  The  process  of  finding  the  best  hyperparameters  is  based  on  trial  and  error.  For example, for random forest algorithm we may change the no. of trees, depth, etc.  In order to find the best combination of hyperparameters, we divide the training data into train set and validation set. These are used to evaluate the performance of the model and once the best combination is determined, we apply the model on the test set.  3 ways to navigate through the hyperparameters are as follows:  1.  Grid search (exhaustive search, time consuming) 2.  Random Search (faster than grid)     3.  Bayesian  Optimisation  (most  efficient  of  the  3,  it  is  based  on  probability  principles)  How to handle imbalanced data  Few datasets such as  healthcare datasets may be  imbalanced  in  the set that there might be too few true cases and majority of false cases. In such a case, we can boost their performance by following methods:  1.  Data  augmentation:  oversampling  the  data  from  minority  class  and  under-  sampling the majority class.  2.  Classification Threshold      