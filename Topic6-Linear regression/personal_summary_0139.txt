 This topic was focused on fundamentals of supervised learning, how it is different than unsupervised learning, what are the different supervised machine learning models, and how to evaluate them using different evolution metrics.  In  supervised  learning,  we  already  have  labels  for  the  target  variable,  and  we  use  the feature data to train the model and predict the label for the unseen data. Predicting weather, future  stocks  and  even  age  or  gender  are  some  of  the  common  examples  of  supervised learning.  There  are  two  popular  supervised  models,  the  first  is  regression  which  is  used  to predict  continuous  data,  and  others  are  classification  models,  which  are  used  to  predict categorical data.  To  test  the  performance  of  these  machine  learning  models,  we  partition  the  original dataset into a training and testing dataset. As the name suggests, we use training data to train the supervised learning model and testing data to evaluate the performance.  The purpose of this  is to  test  the  model  on testing  data, where the  correct  instances are  known.  To  evaluate regression model, we use Root mean squared error, root absolute error and r2 score. And for the  classification  model,  we use  confusion  metric,  accuracy,  precision,  and f1-score.    Do  note that  the  evolution  of  metric  values  varies  depending  upon  the  choice  of  partition,  and  the proportion of partition.  Every  model  has/have  parameter(s)  which  can  be  tuned  to  fit  the  model  better  if  the model is under or overfitted. These parameter(s) are called hyperparameters. Finding the right value of these parameters is subjective. Later, in the topic, I learned how to apply these models and test the performance using Python programming language.             