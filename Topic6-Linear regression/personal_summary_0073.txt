 Learning Goals  By the end of topics 5 and 6 you will be able to:    differentiate supervised learning from unsupervised learning.   estimate the performance of different supervised learning models.   implement model selection and compute relevant evaluation measures.  Forms of supervised learning  The most common practical use of machine learning is based around supervised learning over unsupervised learning.  This means that we are essentially making an algorithm based on the known relationship between the input and the output. We develop a mapping function from the input variable to the output variable.  A supervised learning algorithm  A supervised learning algorithm is an algorithm that learns from labelled data to make predictions about new data. It uses a training dataset to build a model that can then be used to predict outcomes for new, unseen data.  The concept of model complexity  Model complexity refers to how sophisticated or intricate a model is in terms of its structure and the number of variables it uses to make predictions. A more complex model may have higher accuracy on the training dataset but may also be more prone to overfitting and perform poorly on new, unseen data.  Model complexity with Occamâ€™s razor  Occam's razor is a principle that suggests the simplest explanation or model is often the best. When choosing between models of similar accuracy, the one that is simpler in structure should be preferred.  Structural risk minimisation  Structural risk minimization is a method for finding a balance between model accuracy and complexity. It involves minimizing the risk of a model overfitting to the training data by selecting a simpler model that fits the data reasonably well.  Classification metrics  Classification metrics are used to evaluate the performance of classification models. Examples include accuracy, precision, recall, and F1-score.  Regression Metrics  Regression metrics are used to evaluate the performance of regression models. Examples include mean squared error, root mean squared error, and R-squared.  Partitioning data for training and testing  Partitioning data into training and testing sets is a common practice in machine learning. This involves splitting the dataset into two separate sets, one for training the model and one for testing the model's performance.  Finding the best Hyper Parameters  Hyperparameters are variables that are set prior to training the model, and they can have a significant impact on the model's performance. Finding the best hyperparameters involves tuning them to improve the model's accuracy and generalization.  Effect of Imbalanced classes  Imbalanced classes occur when the number of observations in different classes is not equal. This can affect the accuracy of a model, as it may be biased towards the majority class. Techniques like resampling, cost-sensitive learning, and ensemble methods can help mitigate this issue.  Fitting regression line  Fitting a regression line involves finding the line that best fits the data points in a scatter plot. This is typically done by minimizing the sum of squared errors between the predicted values and the actual values.  Multivariate regression  Multivariate regression is a type of regression analysis that involves predicting a dependent variable based on multiple independent variables.  Evaluating our model  Evaluating a model involves assessing its performance on new, unseen data. This can involve comparing the predicted outcomes to the actual outcomes and using metrics like accuracy, precision, recall, and F1-score to measure performance.  Data size and regression error  The size of the dataset used to train a regression model can affect its accuracy. Generally, a larger dataset will result in a more accurate model, as it will be less prone to overfitting.  