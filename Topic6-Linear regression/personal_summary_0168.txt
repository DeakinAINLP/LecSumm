  Difference between supervised learning and unsupervised learning. The main distinction between the two approaches is the use of labeled datasets. To put it simply, supervised  learning  uses  labeled  input  and  output  data,  while  an  unsupervised  learning algorithm does not. In supervised learning, the algorithm ‚Äúlearns‚Äù from the training dataset by iteratively making predictions on the data and adjusting for the correct answer. While supervised learning models tend  to  be  more  accurate  than  unsupervised  learning  models,  they  require  upfront  human intervention to label the data appropriately.  Supervised learning is when the model is getting trained on a labelled dataset. A labelled dataset is  one  that  has  both  input  and  output  parameters.  In  this  type  of  learning  both  training  and validation, datasets are labelled as shown in the figures below.  Both the above figures have labelled data set as follows:    Figure A:  It  is  a  dataset  of  a  shopping  store  that  is  useful  in  predicting  whether  a customer will purchase a particular product under consideration or not based on his/ her gender, age, and salary. Input: Gender, Age, Salary Output: Purchased i.e. 0 or 1; 1 means yes the customer will purchase and 0 means that the customer won‚Äôt purchase it.    Figure B: It is a Meteorological dataset that serves the purpose of predicting wind speed  based on different parameters. Input: Dew Point, Temperature, Pressure, Relative Humidity, Wind Direction Output: Wind Speed  Types of supervised learning: classification and regression. Classification is used to predict the outcome of a given sample when the output variable is in the form of categories. A classification model might look at the input data and try to predict labels like "sick" or "healthy."        Regression is used to predict the outcome of a given sample when the output variable is in the form of real values. For example, a regression model might process input data to predict the amount of rainfall, the height of a person, etc.  Hypothesis Space Let‚Äôs say that we have a binary classification task and that the data are two-dimensional. Our goal  is  to  find  a  model  that  classifies  objects  as  positive  or  negative.  Applying  Logistic Regression, which estimate the probability that the object at hand is positive. Each such model is called a hypothesis, while the set of all the hypotheses an algorithm can learn is known as its hypothesis space.  Loss Function Machines  learn  by  means  of  a  loss  function.  It‚Äôs  a  method  of  evaluating  how  well  specific algorithm  models  the  given  data.  If  predictions  deviates  too  much  from  actual  results,  loss function would cough up a very large number. Gradually, with the help of some optimization function, loss function learns to reduce the error in prediction.  Empirical Risk It is a principle in statistical learning theory which defines a family of learning algorithms and is used to give theoretical bounds on their performance. The idea is that we don‚Äôt know exactly how well an algorithm will work in practice (the true "risk") because we don't know the true distribution of data that the algorithm will work on but as an alternative we can measure its performance on a known set of training data. We assumed that our samples come from this distribution and use our dataset as an approximation. If we compute the loss using the data points in our dataset, it‚Äôs called empirical risk. It is ‚Äúempirical‚Äù and not ‚Äútrue‚Äù because we are using a dataset that‚Äôs a subset of the whole population.  Confusion Matrix The confusion matrix is a matrix used to determine the performance of the classification models for a given set of test data. It can only be determined if the true values for test data are known. The matrix itself can be easily understood, but the related terminologies may be confusing. Since it shows the errors in the model performance in the form of a matrix, hence also known as an error matrix.  The above table has the following cases:    True Negative: Model has given prediction No, and the real or actual value was also  No.    True Positive: The model has predicted yes, and the actual value was also true.   False Negative: The model has predicted no, but the actual value was Yes, it is also  called as Type-II error.             False Positive: The model has predicted Yes, but the actual value was No. It is also  called a Type-I error.  Mean Squared Error evaluates the proximity of a regression line to a group of data points. It is a risk function that corresponds to the predicted squared error loss value.  R-square R¬≤ is nothing more than a measure of how strongly two variables are correlated. It is the square of the correlation coefficient between ùë• and ùë¶.  Stratified train-test split. Some classification problems do not have a balanced number of examples for each class label. As such, it is desirable to split the dataset into train and test sets in a way that preserves the same proportions of examples in each class as observed in the original dataset. This is called a stratified train-test split.  Cross validation Cross validation is a technique used in machine learning to evaluate the performance of a model on unseen data. It involves dividing the available data into multiple folds or subsets, using one of these folds as a validation set, and training the model on the remaining folds. This process is repeated multiple times, each time using a different fold as the validation set. Finally, the results from each validation step are averaged to produce a more robust estimate of the model‚Äôs performance. Validation In this method, we perform training on the 50% of the given data-set and rest 50% is used for the testing purpose. The major drawback of this method is that we perform training on the 50% of the dataset, it may possible that the remaining 50% of the data contains some important information which we are leaving while training our model i.e higher bias. LOOCV (Leave One Out Cross Validation) In this method, we perform training on the whole data-set but leaves only one data-point of the available data-set and then iterates for each data-point. It has some advantages as well as disadvantages also. An advantage of using this method is that we make use of all data points and hence it is low bias. The major drawback of this method is that it leads to higher variation in the testing model as we are testing against one data point. If the data point is an outlier it can lead to higher variation. Another drawback is it takes a lot of execution time as it iterates over ‚Äòthe number of data points‚Äô times. K-Fold Cross Validation In this method, we split the data-set into k number of subsets(known as folds) then we perform          training on the all the subsets but leave one(k-1) subset for the evaluation of the trained model. In this method, we iterate k times with a different subset reserved for testing purpose each time.  