 Main Points  Forms of Supervised Learning  Supervised learning is the studying of the mapping functions that attempted to map  the input variable x to the output variable y, and estimate the function from labeled  training data. It can appear in several forms: regression problems include linear  regression and logistic regression; classification problems list as: support vector  machines, decision trees, random forest and neural networks; and ranking problems.  How Supervised Learning Algorithms Work   Hypothesis Space: the learning algorithm seeks a function on h where X is the  input space and Y is the output space, the function h is the element of some  space of possible functions H, often called the hypothesis space.   Finding a function: Start with the hypothesis function that it similar to the true  function behind the data, end up with the function as accurate as possible to the  main unknown function.   Loss function: the measure of accuracy   Empirical Risk: similar to loss function, can be calculated by averaging the results  of the loss function. The lower the empirical risk based on the training data, the  closer the function represents the true relationship between the pair of values.  Model Complexity  The effects of choosing model complexity:  When select higher complexity than necessary, it would be over-fitting the data.  When select lower complexity than necessary, it would be under-fitting the data.  Occam’s Razor is used as a heuristic guide in the development of theoretical models:  All other thins being equal, the simplest solution is the best.  Structural Risk Minimization  It seeks to prevent over-fitting by incorporating the penalty on the model complexity  that prefers simpler functions over more complex ones.  Partitioning Data for Training and Testing  Methods for splitting data:   random sub-sampling: partitions the data into random training and test sets in a  specified ratio   stratified sampling: divide the data into different sub-groups or strata, randomly  selects the samples proportionally from different strata   cross validation: evaluate models by partitioning the original sample into the  training set to train the model into equal sized sub-samples and leave one sub-  sample out for evaluating the model and train the model using the rest of the  sub-samples  Find the Best Hyper-parameters   Decide a possible range for hyper-parameter   Define a search grid within the specified range for hyper-parameter to evaluate  the model with them   Train a model using each hyper-parameter value from the search grid   Assess the performance on the validation set   Select the one with the best performance  Effects of Imbalanced Class Distribution  The problems can appear in machine learning is data where the total number of one  class of data is far less the total number of another class of data outcomes.  Solutions:  At the data level:   Over-sampling the data from minority class   Under-sampling the data from majority class  At the algorithmic level:   Adjusting the costs   Adjusting the decision threshold  Summary of Reading  Based on the learning of model evaluation metrics, there are several different  classifications metrics and regression metrics that contributed in the machine  learning process. In order to figure out the features of the metrics and prepare to  work with them in python, it is necessary to summarize the roles to compare the  differences among the metrics.  Confusion Matrix: the summary of prediction results on the classification problem,  the number of correct and incorrect predictions are generated with count values and  divided down by each class, and it is the approach to understand the types of errors  made by the model.  Receiver Operating Characteristics(ROC): depicts the trade-off between the true  positive rate and false positive rate. It is especially useful for domains with  imbalanced class distribution and unequal classification error costs.  Regression Metrics   Mean Squared Error: calculated as the mean/average of the squared differences  between predicted and expected target values in the datasets.   Root Mean Squared Error: an extension of the mean squared error, calculated  that the units of the RMSE are the same as the original units of the target value  that is being predicted.   Mean Absolute Error: calculated as the average of the absolute error values, it  does not provide more or less weight to different types of errors and instead the  scores increase linearly with increases in error.   Explained Variance: measured as the percentage of target variation that is  explained by the model. It is the square of the correlation between the target  values and the predicted target values.  Self-reflection  In order to complete the pass activity of the topic, it is necessary to understand  some additional aspects of cross validation in supervised learning.  The leave-one-out cross validation method follow the steps to evaluate the model:   Split the data set into a training set and a testing set, applying all but one  observation as part of the training set.   Build the model use only data from the training set.   Use the model to predict the response value of the one observation left out of  the model and calculate the Mean Squared Error.   Repeat the process for n times where n is the total number of observations in  the data set, leaving out the different observation from the training set each  time.  Pros & Cons of leave-one-out cross validation  Pros:  It offered a less biased measure of test mean squared error compared to use a single  test set as it repeatedly fit a model to data set that contains n-1 observations.  It tends not to overestimate the test mean squared error compared toe a single test  set.  Cons:  It can be a time-consuming process to use when n is large.  It can be a time-consuming process if the model is particularly complex and takes a  long time to fit to the data set.  