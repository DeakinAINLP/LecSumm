 Supervised learning is a type of machine learning where the algorithm learns from  labeled data. Typical problems that supervised learning is used in are regression problems such linear and logistic regression, or classification problems like neural networks.  Model complexity is important in supervised learning. A model that is too simple will not be able to capture the complexity of the data, while a model that is too complex may overfit the data and perform poorly on new, unseen data.  Classification matrices are used to evaluate the performance of a model in classification. The confusion matrix is the most common classification matrix, it shows the number of true positives, true negatives, false positives, and false negatives. Metrics such as accuracy, precision, recall, and F1-score can be  calculated to evaluate performance of the model.  Regression metrics are used to evaluate performance of a model in regression  problems. Common regression metrics include mean squared error, root mean  squared error, mean absolute error, and explained variance. These metrics are used  to evaluate how well a regression model fits the data and how well it fits to new data.  Partitioning data for training and testing is important for evaluation of a model to see  how well it will perform on non-training data. Data can be split with randomized  approaches such as sub-sampling where the data is divided randomly into training  and testing sets using a specified ratio. Cross validation is another approach, where  the data is divided into multiple parts, and each part is used for testing while the rest  is used for training and cycles through which part is the test part over each iteration.  