Lesson Overview – Fundamentals of supervised learning  Supervised machine learning is the focus of this topic’s learning.  In supervised learning, correct data label is provided, and relationship is known between the input and output; the best fitting function is then found basing on this relationship between the input and output.  The accuracy is measured using  the loss function, how effective has the function found been able to describe the relationship between the input and output by computing each true result and predicted result.  Supervised machine learning can appear in the form of a regression, classification and ranking problem.  The objective of machine  learning is to find a function with the lowest empirical risk; the function which has achieved the lowest average loss function but not increasing the complexity of the model.  Loss function can appear in the forms of square loss and absolute loss function, which can be used for regression, and 0-1 loss, logistic loss and Hinge loss functions which can be used for classification.  When selecting a function, it is also crucial to find one with a good generalisation fit rather than a high complexity fit which could cause over-fitting, or a low complexity fit which could cause under-fitting of data.  Additionally, when there are multiple functions with similar fit, it is a preference to choose one with fewest assumptions and least complexity, which is referred to structural risk.  There are several metrics which can be used to evaluate a model, these includes confusion matrix, ROC Curve and F-1 measure.  Confusion matrix is one of the most popular metrics providing a summary of prediction values on a classification problem, such matrix would show how successful the function has been with its predictions and the types of errors   made.  Receiver Operating Characteristics (ROC) is another metrics commonly used for classification problems, an ROC curve shows the relationships between the true positive rate and false positive rate.  Regression metrics is another measurement matrix used to measure the effectiveness in its prediction, the regression metrics measures how close the predictions are to the true target values by calculating the mean square error (MSE), Root Mean Square Error (RMSE) and Mean Absolute Error (MAE).  Furthermore, Explained variance (R2) is used to measure the percentage of target variation explained by the model, the highest the R-square value is, the better its performance.  Quality training data is required to ensure reliable result.  Training data should be of a substantial size, as free of noisy data (outlier) as possible, and when possible, multiple training/test splits should be performed.  There are three different ways in which data can be split, random sampling, stratified sampling and cross validation.  Radom sampling describes a sampling process where instead of a single split, random sub-sampling repeatedly separate data into random training and test sets in the pre-set ratio, each sub-sampling set is then trained.  Stratified sampling is when data is divided randomly, it is important to ensure that the class portion is proportional to avoid biases.  Cross validation is another popular method of partitioning, this method partitions the entire data set into equal sized samples and repeatedly leave one of these sub-samples set as test data, the result will be obtained through averaging the result from all iteration.   Cross validation is considered as the most reliable technique as this model is not simply being trained and tested using the same set of data and has a chance to be re-trained and re-tested using the entire data set.  Hyperparameters are external to the model which are required to be set before the learning can begin and cannot be estimated from the data, and these are often used to help estimate model parameters. Choosing the right hyperparameter can significantly determine the performance of a model.  There are three techniques to uncovering the appropriate hyperparameter, grid-search, random search and Bayesian optimisation.  