Key Learning:    Supervised  learning  is  a  type  of  machine  learning  where  the  algorithm  is  trained  using labelled data with known correct answers. There are various forms of supervised learning including regression, classification, and ranking problems. In supervised learning, the algorithm is trained to find a function that maps input to output accurately. The quality of the function is measured using a loss function, and the algorithm seeks to minimize the risk of the loss function through empirical risk minimization to find the solution to the learning problem.      The concept of model complexity in machine learning is about determining the appropriate level of complexity for a model to fit the given data. Over-fitting and under-fitting can occur when the model's complexity is either too high or too low, respectively, and it's important to strike a balance to achieve good generalization for accurate predictions on unseen data.   Occam's  Razor  is  used  as  a  heuristic  guide  to  develop  theoretical  models  in  machine learning, recommending the simplest solution with the least assumptions and complexity when multiple competing theories have similar fit.    Structural risk minimisation is a method in machine learning that incorporates a penalty on model complexity to prevent over-fitting, with the goal of minimizing both structural and empirical risk through a comprehensive definition of risk.    Classification  metrics  are  important  in  evaluating  the  performance  of  machine  learning models, and include the confusion matrix which summarizes the number of correct and incorrect predictions in a classification problem, as well as metrics like true positive rate, false  positive  rate,  ROC  curve,  and  F-1  measure,  which  provide  additional  insights  into model performance.    The  performance  of  a  regression  model  can  be  measured  using  metrics  such  as  Mean Square  Error  (MSE),  Root  Mean  Square  Error  (RMSE),  Mean  Absolute  Error  (MAE),  and Explained Variance (R-square), which indicate how close the predictions are to the actual values and how much of the target variation is explained by the model.    Partitioning data into training and testing sets is important for model selection to avoid overfitting. Random subsampling, stratified sampling, and cross-validation are commonly used methods for splitting data into training and testing sets, with cross-validation being the most popular. It involves partitioning the data into equal-sized sub-samples, leaving one sub-sample out for testing and training on the remaining sub-samples iteratively, and averaging the obtained accuracies to estimate model performance. In  machine  learning,  hyperparameters  are  parameters  set  before  the  learning  process begins  and  are  often  used  to  help  estimate  model  parameters.  To  find  the  best hyperparameters,  data  is  partitioned  into  separate  training  and  validation  sets,  and  a search  grid  is  defined  within  a  specified  range,  where  a  model  is  trained  for  each hyperparameter value from the search grid and assessed on a validation set to select the best  performing  hyperparameters.  Internal  cross-validation  can  also  be  used  within  a training set to select the best hyperparameters.      The imbalanced class problem can occur when the total number of instances of one class is  much  less  than  the  other,  causing  issues  for  machine  learning  algorithms.  Solutions include  resampling  data,  adjusting  costs  or  decision  thresholds,  and  using  evaluation metrics other than accuracy. It is important to avoid using information that is not available during the training process and to be cautious of overfitting on the test set.  