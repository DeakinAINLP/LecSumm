This topic provided an in-depth coverage of supervised learning and particularly regression problems. We started by exploring model complexity and decision boundaries including the definition of Occamâ€™s razor.  We looked at classification metrics such as confusion matrix and the F1 measure. We also looked at regression metrics and specifically mean square error and explained variance.  We learned about methods that we can use in order to partition our data for training. and testing with sub sampling and cross validation.  We also explored hyperparameters and how to find the best possible values and we covered the issues that arise from using imbalanced datasets.  The second part of the topic focused on the use of the Python programming language and how it can be used in order to partition data and preform supervised learning focusing on linear regression.  