Throughout  the  topic,  I  gained  a  deep  understanding  of  various  aspects  of  supervised learning, starting from its different forms to the concept of model complexity and Occam's razor. I learned about techniques like structural risk minimization and the importance of partitioning data for training and testing in supervised learning. Additionally, I explored the evaluation metrics used in both classification and regression tasks, and how to find the best  hyperparameters  for  a  given  model.  I  also  gained  an  understanding  of  how imbalanced  classes  can  impact  model  performance,  and  explored  various  Python packages for supervised learning. Throughout the topic, I implemented a linear regression model in sci-kit learning, and evaluated its performance on a dataset. I also explored the impact of data size on regression error, and learned about multivariate regression. Overall, this topic was a great learning experience that helped me build a strong foundation in supervised learning.  