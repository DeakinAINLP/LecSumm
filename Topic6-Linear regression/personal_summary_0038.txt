Most of the practical machine learning algorithms use supervised learning, which is giving the algorithm labelled data in order to train it. One of the advantages of supervised learning over unsupervised learning is that result is already known and testing the algorithm to determine whether it is usable or not is much easier. There are many different types of supervised learning, regression problems, which can be either linear or logistic , as well as classification problems for example, support vector machines, decision trees, random forest, and neural networks. Another form of supervised learning is ranking problems.  In order to measure how accurate our function is we use the loss function, which is used to compute how different the calculated result is from the actual result. Another method to gauge the quality of the function is defining a factor called empirical risk, which is calculated by getting the average results of the loss function and the lower the empirical risk, the more accurate the function is and the more it represents the true relationship between the values.  Choosing the right complexity of the model we use to fit the given data is important because in some cases, we may not be able to see whether a problem is linear or non-linear, and different models can affect the data differently, for example if we choose a higher complexity than we ween we would be over-fitting the data but if we choose a lower complexity we would be under-fitting the data. Based on Occamâ€™s razor which states that when there is more than one option that are all equal, we should choose the simplest one, we define a risk value called Structural Risk. Structural Risk refers to when the model is too complex for the amount of data.  The most common type of machine learning applications are classification problems which have many metrics that can be used to evaluate predictions for. A confusion matrix, also called a contingency table, shows the number of correct and incorrect predictions summarized with count values and are divided down by each class. Another metric is the Receiver Operating Characteristics curve which is created by plotting the true positive rate against the false positive rate at different threshold settings. The F-1 measure is another metric which is also very useful, it combines the Precision, which measures the proportion of true positives, and the Recall, which measures the proportion of true positives out of all actual positive cases in the data, into a single number.  Another type of machine learning applications are regression problems. Regression metrics measure how far the expected value is from the actual value. A few ways to measure the regression performance is by using the mean square error or explained variance. The mean square error is calculated by taking the average of the squared differences between the predicted values and the actual values for each data point. Explained variance measures the proportion of variance in the target variable that can be explained by the model.  In order to get a reliable estimate of how accurate a model is we need a large dataset because the variance will be low, and outliers will not be as effective. Using multiple testing splits allows us to use the same data over and over again in training and evaluating the model. There are three main methods used for splitting data, random subsampling, stratified sampling, and cross validation. Sub sampling involves repeatedly splitting data randomly into separate training and testing datasets. Stratified sampling is a probability sampling technique where the entire data is divided into subgroups and then the final sample is randomly selected from the different subgroups. Cross validation is a technique that partitions the data into multiple subsets, and uses one for testing the model and the rest for training it.    A hyperparameter is a parameter whose value is set before beginning to train the model. In order to find the best hyperparameter the data must be partitioned into training and validation sets. A validation set is a sample of data used to provide an unbiased evaluation of a model fit on the training dataset while tuning model hyperparameters. To split a sample into training and validation sets we can use the same techniques as the ones we used for the training and testing datasets.  A very common problem in machine learning is imbalanced classes, where the total number of one class of data is far less than the total number of another class of data. A few problems that can be caused by imbalanced classes are that since the test data contains only few samples from the minority class, even a dumb classifier that always classifies an instance to the majority class will get very high accuracy, and when doing random subsampling, it is possible that class proportion is not maintained in an individual partition. To solve this issue we have to approaches, either perform an act on the data itself, or improve the algorithm itself. For the data, we can either over-sample the data from minority lass, or we can under-sample the data from the majority class. For the algorithm we can either adjust the costs or adjust the decision threshold.    