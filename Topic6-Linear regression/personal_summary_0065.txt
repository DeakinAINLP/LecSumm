 In supervised learning, the data utilized to prepare the algorithm is already labeled with correct answers. In other words, you make an algorithm based on the known relationship between the input and output.  Supervised learning can appear in many forms such as:  ➢  Regression problems  ▪  Linear Regression (linear model) ▪  Logistic Regression (linear model)  ➢  Classification problems  ▪  Support Vector Machines (both linear and nonlinear) ▪  Decision Trees (nonlinear) ▪  Random Forest (nonlinear) ▪  Neutral networks: Perceptron and Multi-layer Perceptron (nonlinear)  ➢  Ranking problems  Occam’s Razor, a famous problem-solving principle, is used as a heuristic guide in the development of theoretical models. (All other things being equal, the simplest solution is the best.)  Structural risk minimisation looks for to avoid over-fitting by joining a punishment on the model complexity that favors easier functions over more complex ones.  The metrics simply select to evaluate your machine learning model are exceptionally vital. The choice of evaluation metrics influences how performance is measured and compared.  A confusion matrix is a outline of prediction results on a classification problem. The number of correct and inaccurate predictions are summarized with count values and isolated down by each class.  Receiver Operating Characteristics (ROC) curve has long been utilized in signal detection theory to depict the trade-off between the true positive rate and false positive rate over noisy channels.  Stratified sampling is a probability sampling technique in which we divide the whole data into different subgroups or strata, then randomly select the final subjects relatively from the different strata.  Another strategy for partitioning data which is even more popular among researchers is Cross-validation. Typically a technique to evaluate models by partitioning the initial sample into a training set to train the model, and a test set to evaluate it.  This implies the value of a hyperparameter in a model cannot be evaluated from data. They are often utilized in processes to help assess model parameters.  A validation set is a sample of data utilized to supply an unbiased assessment of a model fit on the training dataset while tuning model hyperparameters.  All the methods that we already discussed for model assessment are applicable for training/validation set splitting:  ➢  Random subsampling ➢  Stratified subsampling ➢  Cross-validation  Finally we practiced the python coding for supervised learning, fitting a regression line, multivariate regression, linear regression model from sci-kit learn and completed the pass task activity and quiz to complete this module.  