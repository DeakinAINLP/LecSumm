 Ans:  Supervised Learning technique is used by most of the machine learning applications where data is already there that is the input & output, it just creates the relationship between them with the help of algorithms.  ➢  These learnings can appear in many forms like regression problems,  classification problems, Ranking problems etc.  ➢  Usage of hypothesis space in order to find a function in different dimensions. Loss function that is helpful in understanding how accurately the function h can or map input function X to target Y.  ➢  Examples of Loss function, square loss, absolute loss, logistic loss, hinge  loss etc.  ➢  Empirical risk which is responsible to lower the risk to minimum value , it is generally based on training data , the closer the function represents the relationship between the values.  ➢  The rate of complexity of a model, it’s usage in machine learning , how  much cost will it involve & when it is usable. ➢  Generalization is a prediction of unseen dataset. ➢  Occam’s Razor states that when multiple competing theories are equal in other respects, the principle recommends selecting the theory that shows fewest assumptions & less complexity.  ➢  Structural risk minimization is a risk developed in Occum’s razor theory  which helps in choosing the simple functions , it simply helps in reducing the risks.  ➢  Confusion matrix ,also known as , contingency tables which is table layout that allows visualization of performance of an algorithm , typically supervised one.  ➢  The confusion matrix is created based on True positive rate & false  positive rate.  ➢  ROC curve used in signal detection theory to differentiate between true  positive & false positive rates.  ➢  Regression metrics & ways to measure the same such as mean square  error & explained Variance.  ➢  Partitioning data for training & testing , where we use three methods for segregating the data i.e. random subsampling, stratified sampling, cross validation.  ➢  Hyperparameter is a sort of parameter that comes into effect before the start of learning process. It converts data into two sets one is training & other one is validation sets.  ➢  Three possible ways to navigate the hyperparameter space one is Grid_Search, Random Search & lastly Bayesian optimization.  ➢  The imabalanced effect of classes where one set of data is different or less than the other one which can be controlled using ML algorithms.  ➢  This is controllable at data level by doing either over-sampling or under-sampling & at algorithimic level by adjusting the cost & the decision threshold.  ➢  Pythong packages for supervised learning for linear regression ➢  Multivariate regression is a technique that estimates a single regression  model with more than one outcome variable.  ➢  Evaluation of model to identify the discrepancy between the true value  & predicted values using heatmap.  