 Types of Supervised Learning :  ▪  Regression problems  o  Linear Regression (linear model) o  Logistic Regression (linear model)  ▪  Classification problems  o  Support Vector Machines (both linear and nonlinear) o  Decision Trees (nonlinear) o  Random Forest (nonlinear) o  Neural Networks: Perceptron and Multi-layer Perceptron (nonlinear)  ▪  Ranking problems  Structural risk minimization: A technique used to prevent overfitting by applying a penalty to the model complexity that prefers simple functions over complex ones.  Classification metrics:    Confusion Matrix: The number of correct and incorrect predictions are summarized  with count values and divided down by each class.  o  Recall: The fraction of true positive samples that have been predicted  positive over the total amount of positive samples.  o  FPR: The fraction of false predicted positive samples over the total amount of  negative samples  o  Precision: It is calculated as the ratio of true positives to the sum of true  positives and false positives    ROC curve: The ROC curve is created by plotting the true positive rate (TPR) against  the false positive rate (FPR) at various threshold settings.    F1-Measure: Measure is a metric that combines both Precision and Recall in a single  number.  Regression Metrics:  o  Mean Square Error (MSE) o  Root Mean Square Error (RMSE) o  Mean Absolute Error (MAE) o  R-squared: R-square is measured as the percentage of target variation that is  explained by the model.    Methods of Sampling for splitting data into training and test sets:  o  Random sub-sampling (self-explanatory) o  Stratified sampling: Stratified sampling is a probability sampling technique in which  we divide the entire data into different subgroups or strata, then randomly select the final subjects proportionally from the different strata.  o  Cross-Validation: The process is to partition training data into equal sized sub-  samples, then iteratively leave one sub-sample out for the test set, train on the rest of the sub-samples.  o  Internal cross validation: Technique used to find the best hyperparameters by testing on validation samples instead of the test set samples.  