Supervised learning can appear in many forms:  ▪  Regression problems  o  Linear Regression (linear model) o  Logistic Regression (linear model)  ▪  Classification problems  o  Support Vector Machines (both linear and nonlinear) o  Decision Trees (nonlinear) o  Random Forest (nonlinear) o  Neural Networks: Perceptron and Multi-layer Perceptron (nonlinear)  ▪  Ranking problems  Is it possible to generate classification output from regression output? How? What about generated regression value from a classification model?  Some examples of hypothesis space are: space of all linear functions in dimensions space of all polynomial functions up to degree .  Finding a function- using loss function.  The loss function measures accuracy by describing the relationship between input and target.    Empirical risk- similar to the loss function    Occam’s razor a famous solving principle- All other thing being equal, the simplest  solution is the best    Selecting the theory that introduces the fewest assumptions and has the least  complexity    Structural risk minimisation- prevent over-fitting by incorporating a penalty on the  model complexity that prefers simpler functions over more complex ones    Classification metrics, evaluate your machine learning models   Confusion matrix also known as contingency tables, a way to understand the types of  errors made by a model  Confused matrix for classification problem  Confused matrix for two classes    ROC Curve, Receiver operating characteristics is used in signal detection theory to depict the trade off between true positive rate and false positive rate over noisy channels.    Regression metric   Methods for splitting data- random subsampling, stratified sampling and cross  validation    Stratified sampling is a probability sampling technique in which we divide the entire data into different subgroups or strata, then randomly select the final subjects proportionally from the different strata    Cross validation- This is a technique to evaluate models by partitioning the original  sample into a training set to train the model, and a test set to evaluate it.    Hyperparameter- a parameter set before the learning process begins   Imbalance classes where total number of one class outweighs the other, ie positive outcomes far less than total negative outcomes.    Two solutions- resampling(changing sampling sizes) at data levels or algorithmics  level (adjust cost or decision threshold).  What needs to be done for the solution task  1.  Load the dataset from “sampleData.csv”.  Create training and test datasets using random splitting (70-30)%. Print the train and test data. Create a linear regression model and report the model performance. (The last feature is the target variable) 2.  Create training and test dataset using leave-one-out based on Subject ID. Print the train and test dataset for the first iteration only.  Create a linear regression model and compare the performance with Q-1. Explain your findings.     