Topic five covered a basis of supervised learning and model complexity, specifically focusing on linear regression. We  began  with  the  fundamentals  behind  supervised  learning  explored  methods  of  evaluation  including  the  loss function among others. We then looked at model complexity and how it can better lead to accurate predictions but can also result in overfitting if applied poorly. After this, we touched on various metrics that can be further used to evaluate a regression model, the idea of a train/test split, the concept of hyperparameters and how to mitigate the effects  of  an  imbalanced  class.  Finally,  we  applied  these  techniques  within  Python  to  create  regression  lines  and evaluate their performance.  