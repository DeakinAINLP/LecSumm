Tristen Clifton 221211319 SIT307 (Topic 5)  Summarize the main points that is covered in this topic.  In this topic’s module we covered the concepts of supervised learning. Supervised learning is used for the following problems:  Regression problems, such as Linear Regression and Logistic Regression.  Classification problems such as Support Vector Machines, Decision Trees, Random Forest and Neural Networks.  Ranking problems.  In typical supervised learning algorithms, you have two sets of data, The input data and the output data. In supervised learning the algorithm is also given data that represents the expected output. This allows the algorithm to learn the behaviour of the data and be able to predict a result given just input data after it has been trained.  A drawback of supervised learning is it often will produce an incorrect answer given an input. We use various metrics to evaluate how effective an algorithm is. The rate or precision at which an algorithm can determine the correct output is known as accuracy.  An important consideration when training data is model overfitting, when training data is given, that data may be noisy. This means that some data may not perfectly represent the relationship and may result in an inaccurate decision boundary. To solve this in some cases we may underfit the data, so it is better at predicting the trend of the data rather than have an exact fit to the training data. This results in the data being more flexible with future sets as it isn’t expecting an exact clone of the training data.  Structural risk minimisation tries to prevent over-fitting by applying a penalty on the model complexity so that it will prefer simpler functions.  When it comes to evaluation, Accuracy is not everything. Sometimes data sets may be unbalanced and may result in a higher accuracy simply due to imbalance. Therefore, we use other performance metrics such as confusion matrixes to better represent the true positive ratio for all classifications rather than just the average rate of success.  Regression is how far the expected value is from the actual value, using this method we can determine the performance of a algorithm.  Provide summary of your reading list – external resources, websites, book chapters, code libraries, etc.     https://www.statology.org/leave-one-out-cross-validation/  https://www.geeksforgeeks.org/split-pandas-dataframe-by-rows/  Reflect on the knowledge that you have gained by reading contents of this topic with respect to machine learning.  I have already studied supervised learning in other subjects, however the new content for me was putting it into practice using python. It was also the first time I evaluated the performance of the algorithms. So, I learned how little accuracy represented the true performance of an algorithm.  Attempt the quiz given in topicly content (5.18) and add screenshot of your score (>85% is considered completion of the task) in this report.     