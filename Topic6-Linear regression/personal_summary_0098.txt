Supervised learning – Data used to train the algorithm is already labelled with correct answers. It is the task of estimating a function from labelled training data.  ▪  Regression problems  o  Linear Regression (linear model)  o  Logistic Regression (linear model)  ▪  Classification problems  o  Support Vector Machines (both linear and nonlinear)  o  Decision Trees (nonlinear)  o  Random Forest (nonlinear)  o  Neural Networks: Perceptron and Multi-layer Perceptron (nonlinear)  Loss function – Used to measure the difference between the predicted output and ground truth. By minimizing the loss function, the model learns to make better predictions and becomes more accurate in its task.  Structural Risk – The risk of overfitting a model. Overfitting occurs when a model becomes too complex and fits the noise in the dataset rather than the underlying patterns.  Confusion matrix – A table summarizing the performance of a machine learning algorithm by comparing the ground truth to predicted results.  Data partitioning – The process of splitting datasets in training data and testing data.    Sub-sampling   Stratified sampling   Cross validation  Hyperparameters – A parameter whose value is set before the learning process begins.  