 This topic in the Machine Learning unit we introduced to supervised learning, we learnt:  -  -  Supervised learning is the process training a model with both the inputs and outputs with the  goal of finding the relationship between the input and the output.  Elements of the supervised learning include the hypothesis function, which is the potential  function  that  could  explain  the  input  /  output  relationship,  and  the  loss  function,  which  reflects how accurately the hypothesis function was able to describe the relationship.  -  Overfitting which is the process of increasing the complexity of the model with the goal of  exactly fitting the model with the testing data. This process has the down side of producing  poor results with new data. A similar issue could be seen with underfitting as well.  -  Confusion matrix is a method to summarize the model’s accuracy classifying the classes in the  data. It constitutes a matrix with rows and columns equal to the number of classes, rows are  for prediction, and columns are for true values. Each element (i,j) presents a percentage of  number of times the model predicted the class i as class j, Ideally high percentages diagonal  elements and small elsewhere.  -  Available  data  is  split  into  training  set  to  train  the  model  and  testing  set  to  test  the  performance of the model. Common methods for splitting include:  o  Random  subsampling:  The  data  is  repeatedly  split  randomly  between  training  and  testing while maintaining a specified ratio.  o  Stratified sampling: Splits the data into subgroups and then constructs the sets from  the subgroups proportionally to the classes’ proportions in the data.  o  Cross validation: The data is split into equal length subsets. Then, one subset is chosen  for model testing while the rest are used for training. This process is repeated until all  the subsets are chosen as testing sets while calculating the accuracy. The accuracies  are then averaged to calculate the model’s total accuracy.  -  Hyperparameters  are  model  parameters  that  are  set  before  the  training  the  model.  A  validation process is made to tune those parameters. In this process, the model is tested with  independent data that wasn’t involved in either the training and testing stage.  -  Having imbalanced training data could lead to biased outputs toward the majority classes. To  solve this issue, we can either oversample the minority classes or under-sample the majority  classes, or in the algorithm level,  we can either adject the costs or the decision thresholds.  