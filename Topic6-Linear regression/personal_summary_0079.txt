 This topic, we have gone through Supervised Learning Techniques, and we came  about some of the algorithms which come within this type of Machine Learning. To recap, in supervised machine learning we used label data to train and test our model. The data used to train the algorithm is already labelled with correct answers or simply with a predefined input and output pairs. From this coma one would develop a mapping function. So, it can also be said that supervised learning is the task of estimating a function from labelled training data. It can solve two classes of problems, namely regression and classification problems.  In this topic we've also learned some mathematical concept related to supervised  machine learning. One of the concepts used in machine learning is called a hypothesis space (represented by h) which is essentially a range of all possible functions from a set, denoted as capital H. We have also learned the about the loss function which is pretty much a measure of accuracy. This measure allows us to describe the difference between our actual and predicted output values, which are then used to compute and adjust the weights of the function itself (please keep in mind that the weights or coefficients in discussion relate to a linear function). Like the loss function we can define a factor called Empirical Risk. Our goal while creating our function h, is to reduce this empirical risk. We compute this risk by averaging the results of the loss function. The lower this risk is based on the training data the closer we can define our function as to the truest relationship between the input and output values within a training data set.  While creating our function, we also consider the concept of model complexity. This  basically implies how complex should our model be regarding the dataset or concept at hand. Sometimes, we may not always be able to visualise our training data in high dimensions, and hence we might not figure out whether our regression problem at hand is linear or nonlinear by nature. It is only there for the question arises that to what degree must the model be complex. If we choose a highly complex model for our data, chances are that the models would experience overfitting. Likewise, if we choose a model much simpler, we were experience and underfitting of the model. This also brings us to a famous problem- solving principle called the Occam’s Razor, which is paraphrased as “the simplest solution is always the best”. This also brings us to another concept, called the ‘Structural Risk Minimization’, which seeks to prevent overfitting by incorporating a penalty on the model. That way, we would prefer simpler functions over more complex counterparts. It is simply the summation of empirical risk and the product between the penalty parameter and the complexity of the hypothesis function.  We then came to learn about some of the evaluation metrics used in machine learning models. In fact, there are two types of metrics used: namely they are Classification Metrics and Regression metrics. Classification metrics can help us in evaluating our classification model. One of the classification metrics mentioned is called confusion matrix, which is a summary of prediction results on a classification problem. From this metric, we can drive derive some other metrics which can be proven useful in evaluation. This includes accuracy, sensitivity, false positive rate, ROC Curve, and F1 Measure. Regression metrics, on    the other hand, the classification metrics counterpart for Regression problems. Some of the popular metrics used are as follows: Mean Squared Error (MSE) or Explained Variance. In supervised learning, data happens to be partitioned into training and testing  purposes. There are known to be three types of methods used to split data up: Random Subsampling, Stratified Sampling, and Cross Validation. Before having our data trained into the model, we can also set up hyperparameters for our mentioned model. A hyper parameter is a parameter whose value is set before the learning process. For finding the best hyper parameters, one can optionally divide the original data set into three parts: Training Data, Testing Data and Validation Data. Hyper parameters can also be optimised and navigate it from three different methods: they are Grid Search, Random Search, anmd Bayesian Optimization Coefficient. Again, the original data set can be divided from the three above mentioned methods.  One final concept we came across in this topic is the effect of imbalanced classes.  This is a problem in machine learning where datasets can have different number of instances for different classes of data. On class of instances can have significantly more instances than the other, which can lead to problems like overfitting and bias.  