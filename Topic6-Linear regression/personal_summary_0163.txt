In this topic we have learned about  Forms of Supervised Learning  Regression problems  Linear Regression (linear model)  Logistic Regression (linear model)  Classification problems  Support Vector Machines (both linear and nonlinear)  Decision Trees (nonlinear)  Random Forest (nonlinear)  Neural Networks: Perceptron and Multi-layer Perceptron (nonlinear)  Model complexity and Occam's razor: Occamâ€™s Razor, a famous problem-solving principle, is used as a heuristic guide in the development of theoretical models.  Structural risk minimisation seeks to prevent over-fitting by incorporating a penalty on the model complexity that prefers simpler functions over more complex ones. So the general idea is to minimise both Structural Riskand Empirical Risk.  Classification metrics  The metrics that you choose to evaluate your machine learning model are very important. The choice of evaluation metrics influences how performance is measured and compared.  The most common type of machine learning applications are classification problems. There are myriad metrics that can be used to evaluate predictions for these types of problems.  Confusion Matrix  A confusion matrix is a summary of prediction results on a classification problem. The number of correct and incorrect predictions are summarized with count values and divided down by each class. Confusion matrices are a way to understand the types of errors made by a model. Confusion matrices are also called contingency tables.  Partitioning data for training and testing  A single training set may be affected by some outlier instances (i.e. noisy observations).  To get a reliable estimate of model performance (accuracy), we need a large test set. Why? Because variance of such an estimate is low.  However, we know that the larger the size of the training set, the more accurately the model can be learnt.  Multiple training/test splits allow us to re-use same data for both training and evaluation in different splits.       