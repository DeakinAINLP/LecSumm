In  the  topic  five  online  class  we  mainly  learnt  about  some  key  concepts  important  for  supervised learning. We first talked about what supervised machine learning is, differentiate  supervised learning from unsupervised learning and benefits of supervised learning.  Then we discussed forms of supervised learning including regression problems, classification  problems  and  ranking  problems.  Our  lecturer  showed  some  illustrations  of  two  regression  problems and one classification problem, where we looked to find relationships among feature  variables. Here, we learnt that we can successfully find a linear boundary and sometimes we  have  to  search  for  a  more  complex  boundary.  Then  we  took  a  closer  look  at  a  supervised  learning example and discussed how a supervised learning algorithm works. Under this topic  we learnt what hypothesis space and hypothesis function mean, how to measure the quality of  a  function  using  the  “loss  function”,  some  familiar  loss  functions  including  square  loss,  absolute loss and 0-1 loss. We also discussed what empirical risk means. After that, we moved  into the concept of model complexity, where we learnt about the concepts over fitting and under  fitting, Occam’s Razor, a famous problem-solving principle, which is used as a guide in the  development of theoretical models and structural risk minimization.  In  the  second  half  of  the  online  class,  we  learnt  about  model  evaluation  metrics  including  classification  and  regression  metrics.  Under  classification  metrics  we  concentrated  on  Confusion Matrix, ROC curve and F-1 Measure and their related evaluation metrics. Next, we  went through data partitioning methods for training and testing including random subsampling  stratified sampling and cross validation. After that, we talked about what a hyperparameter is,  why do we need to have hyperparameters and how to find the best hyperparameter for a specific  model. Finally, we discussed the effect and issues of imbalanced classes.  In the programming part of this unit, we explored Python packages for supervised learning. We  learned how to fit a linear regression model to a regression dataset, the behaviour of the linear  regression model, fitting a regression line, some multivariate regression examples, fitting the  multivariate regression using sci-kit learn package, how to evaluate our model and finally, how  to check the effect of data size on prediction performance.  