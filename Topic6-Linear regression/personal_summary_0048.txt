This topic we learned about the fundamentals of supervised learning.   Supervised learning in general gets labelled training data and estimating a function or to make actions based on the data. It involves training using the dataset and learns from examples. It reduces its parameters and intern reduces the diﬀerence between the predicted outputs and the true outputs. Supervise learning is used in many applications.   There are many forms of supervise learning such as linear regression, and logistic regression, which are both linear models which they classify as regression problems, and we have support Victor machines, decision, trees, random forest, neural networks, which classify under classiﬁcation problems.   In supervised learning, we have what's called the concept of model complexity. Model complexity, basically means how complex the model should be based on the given data. There are many things when it comes to the complexity of the models, such as when choosing a higher complexity, the necessary we may encounter over ﬁtting, if we choose lower complexity, we maybe under ﬁtting.   “All other things being equal, the simplest solution is the best” is Occam's razor, which is used as a guide in the development of theoretical models. Essence, the best theory to choose is of the theory that introduces the least amount of assumptions and the least amount of complexity.   Classiﬁcation metrics are commonly used in the ﬁeld of supervised learning evaluates the performance and accuracy of the classiﬁcation model, include accuracy, precision recall, F1, score, speciﬁcity, Confusion Matrix etc.   Simply put confusion matrix show a tabular version of the number of true positives and true negatives, false positives and false negatives. It is used to classify various metrics.   Using regression models, we must use regression metrics to evaluate of the performance and accuracy of these models, would provide valuable insights as to how close the estimate is to the actual value. 2 of these we will be focusing on are the mean squared error and R^2, which is the coeﬃcient of determination.   For supervised learning to occur we must partition the data for training and testing. This involves Sub-Sampling, Stratiﬁed sampling and cross-validation.    