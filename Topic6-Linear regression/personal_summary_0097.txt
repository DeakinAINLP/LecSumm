  Summary/Reflection of the main points during topic 5:  Supervised Learning:  Involves labelled data for training.  - -  Goal: Learn a mapping from inputs to outputs -  Examples: Regression, Classification, and Ranking  Regression vs Classification vs Ranking:  -  Regression: Predicting continuous output values -  Classification: Predicting discrete output classes -  Ranking: Ordering instances based on preference or relevance     Supervised Learning Algorithms (Space, Function, Risk):  Space: Set of possible functions for learning (hypothesis space) Function: A specific model to map inputs to outputs  - - -  Risk: Measure of prediction error (expected loss) for a given hypothesis  Model Complexity (Pros vs Cons):  Pros: More complex models can capture intricate patterns  - -  Cons: Increased risk of overfitting, higher computational costs, and decreased interpretability  Occam's Razor in ML/AI:  Simpler models are preferred when they perform equally well.  - -  Helps prevent overfitting and improve generalization. -  Encourages the selection of models with fewer parameters.   Metrics:  -  Confusion Matrix: Tabulates true positives, false positives, true negatives, and false  negatives.  -  ROC Curve: Plots true positive rate against false positive rate at various thresholds - F1 Measure: Harmonic mean of precision and recall, useful for imbalanced classes -  MSE: Mean squared error, measures average squared difference between predictions and  actual values.  -  R2: Coefficient of determination, measures the proportion of explained variance in the data.   Data Partitioning:  Splitting data into training, validation, and test sets Training set: Used to fit the model.  - - -  Validation set: Used to tune hyperparameters and assess model performance. -  Test set: Used for final evaluation of model generalization.  Hyperparameters and Finding the Best Ones:  -  Hyperparameters: Configurable settings that influence model learning. -  Methods for tuning: Grid search, Random search, and Bayesian optimization -  Cross-validation: Technique used to estimate model performance on unseen data.  Imbalanced Classes and Their Effects:  - - -  Imbalanced classes: One class significantly outnumbers the others. Effects: May cause poor model performance, especially for the minority class Solutions: Oversampling, under sampling, or using advanced techniques like SMOTE   Linear Regression vs Multivariate Regression:  - Linear Regression: Predicts a single output variable based on one or more input variables. -  Multivariate Regression: Predicts multiple output variables simultaneously based on one or  more input variables.  Evaluating a Model:  -  Metrics: Quantitative measures of model performance (e.g., accuracy, precision, recall, F1  score, MSE, R2)  -  Cross-validation: Estimating model performance using multiple data splits. -  Bias-variance trade-off: Balancing model complexity to minimize both bias (underfitting) and  variance (overfitting)  Data Size and Regression Error:  - - -  Larger datasets generally lead to better model performance. Insufficient data may cause overfitting or underfitting. Learning curve: A plot that shows the relationship between data size and regression error, useful for understanding model performance and estimating the benefits of adding more data.  