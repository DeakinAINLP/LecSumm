Summary:  5.2:  Supervised learning involves estimating a mapping function, from input to output variables via labelled training data.  It is broken into regression, classification and ranking problems. The many forms of these include linear and non-linear bounding problems.  5.3:  Supervised learning seeks to find a function that can transform input into desired output. It begins with a hypothesis function, that is thought to be similar to a true function on the data.  A loss function is a measure of accuracy. It measures the distance between the produced and expected output. Empirical risk is obtained by averaging the results of the loss function. The lower this value, the close the function is to the true function.  5.4/ 5.5/ 5.6:  Complexity of models presents a trade-off in value. Choosing higher complexity may lead to overfitting, lower, underfitting. A good fit means good generalization, that is, application beyond our training dataset.  In general, when other factors fail to make it obvious which model is best, the one with fewest assumptions and least complexity is preferred.  Structural risk is a way to impose a penalty on functions that are more complex. Minimising this along with empirical risk is desirable.  5.7:  Classification problems are the most common application of ML.  A confusion matrix summarises prediction results for a classification problem. The sum of correct and incorrect values are listed, divided by class. They can help understand errors made by models.  Along the diagonal is the intersection of the truth and prediction for each class, with a proportion of values here in relation to outside the diagonal representing accuracy. Metrics, like the rate can be derived from the analysis of these true positives and false positives.  Receiver Operating Characteristics (ROC) curve depicts the trade off between true positive rate and true negative rate. In some cases a false positive may be acceptable, in others, less so. This graph can help shape the model.  5.8:  Regression measures the distance between the expected and actual value. Metrics for this include the mean square error, and root mean square error, the lower, the better.  Explained variance (R2) is the square of the correlation between the target and predicted values, expressed as a percentage, the higher the better.  5.9  Datasets need to be large and partitioned by some method to provide ample training sets for the model.  Random sub-sampling repetitively parts the data into training and test sets based on a ratio. Stratified sampling divides the entire set into subgroups (strata), from which random selections are made. Cross-validation parts the original set into training set and test set for evaluation. Subsamples are determined, then individually excluded from training, but used in testing.  5.10/ 5.11:  A hyperparameter is parameter, which has a value set prior to training. A validation set is used to evaluate a model and tune these hyperparameters.  Imbalance in classes can lead to errors, methods exist to correct for this at the data and algorithm level.  