Topic 5 – Summary    As previously mentioned, supervised learning is where the data have labels, and we are  trying to find a function which will correctly map a given data point to its corresponding  cluster    Supervised learning can be in the form of regression (linear) or classification problems  (non- linear)      We also the note the existence of the loss function which measures how accurately does  the function describe the relationship between X and the target Y    The factor empirical risk is being minimised throughout the whole process    Model complexity refers to preventing over-fitting and under-fitting and finding a best  possible fit for good generalisation    Emerging from Occam’s razor, we define a new risk value labelled Structural risk which is  used to mitigate over-fitting by placing a penalty on the model complexity which is biased  towards simpler functions rather than more complex ones.      A confusion matrix is a summarised version of prediction results on a given classification  problem.    For two classes, we would have the following confusion matrix:  From the above we can derive several mathematical functions such as accuracy, the True  Positive Rate (Recall) and also the False Positive Rate (FPR):    The ROC curve is used to showcase the trade-off between the true positive rate and the  false positive rate over noisy channels. This is shown below:        When it comes to regression metrics, we have:  1.  Mean Square Error – measures the proximity of the predictions  2.  Explained Variance – also known as R2, this metric is evaluated as a percentage of  target variation    To  split  date  into  training  and  testing,  there  prevails  several  methods  including  sub-  sampling, stratified sampling, cross-validation amongst others       A  hyperparameter,  which  is  a  configuration  variable  to  predict  the  behaviour  and  performance  of  a  machine  learning  model,  is  useful  since  they  affect  the  model’s  architecture, generalisation ability and learning process.    Imbalanced  classes  are  very  common  in  practice  where  total  number  of  positive  outcomes outweighs the negative outcomes proportion and we can either perform re-  sampling and/or adjust the costs and decision threshold.  Reflection  This topic’s focus has been on supervised learning and exploring around the base of it first and  then how to evaluate the performance of the mathematical model, also calculate to what degree  the predictions are being made accurately and put a value on the error scale so that we can built  better predictive models.         