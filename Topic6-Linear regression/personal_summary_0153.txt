Supervised learning is based on using a labelled training data to es8mate values. Therefore, through direct mapping between feature vectors to the output that is the target variable, an approxima8on can be obtained. There are mainly three types of supervised learning that is regression  problems  (linear  regression,  logis8c  regression),  classiﬁca8on  problems  (supper vector machines, decision trees, random forest, neural networks) and ranking problems.  The objec8ve of a supervised learning algorithms is to ﬁnd a func8on as close to an unknown func8on to discover the exis8ng rela8onship between x and y, in other words the input and output  variables.  The  hypothesis  space  consists  of  a  range  of  possible  func8ons  for  a hypothesis func8on. This func8on is selected based on its similarity to the true data. The next method is to ﬁnd a func8on h that correlated x to y, the input variable to the output variable. To understand how accurately the func8on measures the rela8onship between x and y, the loss func8on is introduced and applied to the training instance x. A factor called empirical risk averages the results of a loss func8on and measures the rela8onship between x and y based on the training data.  A complex model is typically a model in high dimensions. Visualizing a complex data to iden8fy the regression problem may not always be direct. Choosing a higher complexity can yield to overﬁIng  the  data,  lower  complexity  can  lead  to  underﬁIng  the  data,  therefore  it  is important to ﬁnd a possible ﬁr for good generaliza8on. Generaliza8on is the predic8on on unseen data that is data not part of the training set.  Occam’s razor addresses the problem of choosing a hypothesis when there is already other exis8ng hypothesis with a similar ﬁt and introduced the fewest assump8ons and has the least complexity. Based on this, structural risk is introduced which aims to prevent overﬁIng by imposing a penalty on model complexity. So generally, it seeks to minimize the structural and empirical risk.  The  evalua8on  of  a  predic8on  model  includes  a  confusion  matrix  which  is  a  summary  of predic8on  problem  based  on  classiﬁca8on  problem,  the  ROC  curve  which  is  used  in  signal detec8on theory to classify the tradeoﬀ between the true posi8ve and false posi8ve rate over noise and F-1 Measure which is a combina8on of Precision and Recall.  Regression metrics is also introduced to evaluate the accuracy of the expected value from the actual  value  through  mean  square  error  (MSE)  and  explained  variance  which  can  also  be known as R-square, explained variance and the coeﬃcient of determina8on.  Par88oning  data  is  important  in  geIng  a  reliable  es8mate  on  model  performance  and methods  include  random  subsampling,  stra8ﬁed  sampling,  and  cross-valida8on.  Random subsampling  par88ons  data  repeatedly  into  random  training  and  test  datasets.  Stra8ﬁed sampling divides the en8re data into diﬀerent subgroups and randomly select the ﬁnal data in  propor8on  from  the  diﬀerent  subgroups.  Cross-valida8on  par88ons  the  original  dataset into  a  training  set  to  train  the  predic8on  model  and  later  a  test  set  to  evaluate  the performance of the data.  These methods can also be used for assessing the model.  A hyperparameter is a parameter whose value is determined before the training process. In order  to  iden8fy  the  parameter  values,  the  training  data  is  par88oned  into  training  and valida8on  groups.  The  valida8on  set  then  evaluated  the  model  and  modiﬁed  the  model’s hyperparameters.  