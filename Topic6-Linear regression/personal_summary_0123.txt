 Topic -5 gave the details of the basics of supervised learning. Some of the important points  are listed below:  1.  Supervised learning is a type of machine learning where the data used to train the algorithm  is  already  labeled  with  the  correct  answers.  This  means  that  a  mapping  function  is  developed from the input variable to the output variable based on the known relationship  between the two [1].  2.  Supervised learning can take many forms such as regression, classification, and ranking  problems, and can be solved using linear or nonlinear models such as Linear Regression,  Logistic  Regression,  Support  Vector  Machines,  Decision  Trees,  Random  Forest,  Perceptron, and Multi-layer Perceptron [2].  3.  Choosing  the  right  complexity  of  the  model  to  fit  the  data  is  a  challenge  in  machine  learning.  The  complexity  of  the  model  affects  the  fit  of  the  data.  If  the  model  is  too  complex, it may over-fit the data, while if it is too simple, it may under-fit the data [3].  4.  Structural Risk Minimization is a method for preventing over-fitting in machine learning.  It  seeks  to  minimize  the  risk  by  incorporating  a  penalty  on  the  model  complexity  that  prefers simpler functions over more complex ones. The risk is defined as the combination  of the loss function for all training points and the complexity of the proposed model as a  penalty [4].  5.  Classification metrics are used to evaluate the performance of a classification model. Some  of the commonly used metrics are [5]:    a.  Confusion Matrix: A confusion matrix is a table used to evaluate the performance  of a classification algorithm. It displays the number of true positive, false positive,  true negative, and false negative predictions made by the model.  b.  ROC  Curve:  The  receiver  operating  characteristic  (ROC)  curve  is  a  graphical  representation of the performance of a binary classifier. It plots the true positive  rate against the false positive rate at various classification thresholds.  c.  F1-Measure: The F1-measure is a composite metric that balances the precision and  recall of a classifier. It is the harmonic mean of precision and recall and is a good  metric to use when the classes are imbalanced or when the cost of false positives  and false negatives are different.  6.  Regression metrics are used to evaluate the performance of a regression model. Some of  the commonly used regression metrics are [6]:  a.  Mean  Squared  Error  (MSE):  Mean  Squared  Error  is  the  average  of  the  squared  differences between the predicted values and the actual values. It is a measure of  the overall accuracy of the model and a commonly used loss function for regression  problems.  b.  R-Squared: R-Squared is a statistical measure of how well the regression line fits  the data. It ranges from 0 to 1, with 1 indicating a perfect fit and 0 indicating a poor  fit.  7.  Partitioning data for training and testing is a crucial step in the machine learning process.  It involves dividing a dataset into two subsets: a training set and a testing set. The training  set  is  used  to  train  the  model,  while  the  testing  set  is  used  to  evaluate  the  model's  performance.  8.  There are several methods for partitioning data, including:  a.  random subsampling,  b.  stratified sampling, and  c.  cross-validation.  9.  Hyperparameters are parameters in a machine learning model that are set before training  the model and are not learned from the data during the training process [7].  10. Hyperparameters are needed because many machine learning models have a large number  of  parameters  that  can  be  adjusted  to  improve  performance,  but  it  is  not  possible  to  determine the optimal values for all of these parameters from the training data alone [8].  11. Imbalanced  classes  refer  to  a  situation  where  the  number  of  samples  in  one  class  is  significantly different from the number of samples in another class. This can lead to several  problems  in  machine  learning,  including:  Bias  towards  the  majority  class,  Unreliable  performance metrics, Overfitting to the majority class.  