Topic 5 Supervised Learning  Forms of Supervised Learning  ● Forms of Supervised Learning The majority of practical machine learning  applications use supervised learning.  ● Training data for supervised learning is arranged in the following form: For  each data point, there is an output. This means there is a significant advantage over unsupervised learning because you already know what you're going to get.  Supervised learning algorithm  ■ You can calculate the empirical risk by averaging the results of the loss  function.  ■ We just need to minimize the risk of loss  Classification metrics  ● The metrics that you choose to evaluate your machine learning model are  very important.  ● One of the reasons for using a confusion matrix is that accuracy is not a  reliable metric for the real performance of a classifier.  ● Therefore, we can define other evaluation metrics based on a confusion  matrix: True Positive Rate (TPR) or Recall or Sensitivity.  ● Reporting all these metrics in a machine learning classifier can shed some  light on the overall performance of the classifier.  ● Receiver Operating Characteristics (ROC) curve has long been used in  signal detection theory to depict the trade-off between the true positive rate and false positive rate over noisy channels.  Partitioning data for training and testing  ● partitioning data for training and testing You have covered a lot of ground on  how to assess a trained model.  ● Cross-validation Another method for partitioning data which is even more  popular among researchers is Cross-validation.  ● This is a technique to evaluate models by partitioning the original sample into  a training set to train the model, and a test set to evaluate it.  ● In k-fold cross-validation, the original sample is randomly partitioned into  equal-size sub-samples.  Finding the best hyperparameters  ● Finding the best hyperparameters In machine learning, a hyperparameter is a  parameter whose value is set before the learning process begins.  ● Next, we train a model using each hyperparameter value from the search grid and assess its performance on a validation set (separated from the training set).  ● A grid search will build a model on each possible value for the  hyperparameter.  ● Let us examine how internal cross-validation works.  Effect of imbalanced classes  ● Effect of imbalanced classes One problem that can occur in machine learning  is datasets where the total number of one class of data (i.e. positive outcomes) is far less than the total number of another class of data (i.e. negative) outcomes.  ● As you know most machine learning algorithms work best when the number of  instances of each class is roughly equal.  ● Issues of imbalanced classes Now, let us have a close look at possible issues  of imbalanced classes.  ● During the training process, you must not use any information that is not  available during the training process.  