Learning report  Topic 5: Fundamentals of supervised learning  Learning objective:  -  Differentiate supervised learning from unsupervised learning - -  Estimate the performance of different supervised learning models Implement model selection and compute relevant evaluation measures  Learning summary  -  Forms of Supervised Learning: The majority of practical machine learning applications use supervised learning.   In supervised learning, the data used ttrain the algorithm is already labeled with correct answers.  Supervised learning can appear in many forms:  Regression problems     Linear Regression (linear model) Logistic Regression (linear model)  Classification problems    Support Vector Machines (both linear and nonlinear)   Decision Trees (nonlinear)   Random Forest (nonlinear)   Neural Networks: Perceptron and Multi-layer Perceptron (nonlinear)  Ranking problems  -  A supervised learning algorithm: twsets of data the input and the output. The output set is  obtained by applying the function tthe input set. This means for each element in the input set there is a corresponding element in the output set. You are trying tfigure out the relationship between the pairs of numbers. The relationship between the twis the function.  Hypothesis space: We will name a hypothesis function, h, as an element of a range of possible functions H, usually called the hypothesis space. We’ll select a hypothesis function that we think is similar tthe true function behind the data.  Finding a function: In supervised learning, given the training data, the learning algorithm  seeks a function on h: X->Y where X is the input space and Y is the output space. Loss function: a method of evaluating how well your algorithm models the dataset. The loss function is used tcompute the error between the actual result of  yi and what  calculated as yi.  Empirical risk: Similar tthe loss function, Empirical risk measures its performance on a known set of training data. The lower the empirical risk based on the training data, the closer the function represents the true relationship between the pair of values xi and yi. The concept of model complexity: is a measure of how accurately a machine learning model can predict unseen data, as well as how much data the model needs tsee in order tmake good predictions.  -  -  Model complexity and Occam's razor: Occam’s Razor, a famous problem-solving principle, is used as a heuristic guide in the development of theoretical models. This principle is often paraphrased as: All other things being equal, the simplest solution is the best.   In other words, when multiple competing theories are equal in other respects, the principle recommends selecting the theory that introduces the fewest assumptions and has the least complexity.  -  Structural risk minimization: Structural risk minimization seeks tprevent over-fitting by incorporating a penalty on the model complexity that prefers simpler functions over more complex ones.  -  Classification metrics: The choice of evaluation metrics influences how performance is measured  and compared. The most common type of machine learning applications are classification problems. There are myriad metrics that can be used tevaluate predictions for these types of problems.  Confusion Matrix: A confusion matrix is a summary of prediction results on a  classification problem. The number of correct and incorrect predictions are summarized with count values and divided down by each class. Confusion matrices are a way tunderstand the types of errors made by a model. Confusion matrices are alscalled contingency tables.  One of the reasons for using a confusion matrix is that, accuracy is not a reliable metric for the real performance of a classifier. If the data set is unbalanced it will yield misleading results.   It could represent the positive class as class 1 and the negative class as class 0. For the acronyms used in the table (i.e., TP), the second letter (e.g., letter P in TP) says what we predicted and the first letter (e.g., letter T in TP) says whether it was true or false. In this case the accuracy defines as:               ROC Curve: Receiver Operating Characteristics (ROC) curve has long been used in signal  detection theory tdepict the trade-off between the true positive rate and false positive rate over noisy channels. Recent years have seen an increase in the use of ROC graphs in the machine learning community. ROC curve is especially useful for domains with imbalanced class distribution and unequal classification error costs.  F-1 Measure: Another useful metric could be the combination  of Precision and Recall.  F1-measure is a metric that combines both Precision and Recall in a single number.  F1-measure is defined as:  -  Regression Metrics: Metrics for regression involve calculating an error score tsummarize the  predictive skill of a model. There are several measurements tmeasure regression performance Mean Square Error: Tmeasure how close the predictions are tthe true target values,  Mean Square Error (MSE) is a popular measure.  Explained Variance (R2): R-square is measured as the percentage of target variation that is explained by the model. For linear regression with bias term, R-square is the square of the correlation between the target values and the predicted target values. Unlike the other introduced metrics, the higher the R-square of a model, the better its performance.  -  Partitioning data for training and testing:  There are 3 methods for splitting data: Sub-sampling: Instead of using a single split, a more reliable estimate of model performance can be obtained by random sub-sampling. Random sub-sampling repeatedly partitions the data intrandom training and test sets in a specified ratio.  Stratified Sampling: Stratified sampling is a probability sampling technique in which we divide the entire data intdifferent subgroups or strata, then randomly select the final subjects proportionally from the different strata. When using randomly selecting training (or validation) sets, class proportions may differ between training and test splits.             This is how it works:  Cross-validation: Another method for partitioning data which is even more popular among researchers is Cross-validation. This is a technique tevaluate models by partitioning the original sample inta training set ttrain the model, and a test set tevaluate it.  -  Finding the best hyperparameters: In machine learning, a hyperparameter is a parameter whose value is set before the learning process begins. This means the value of a hyperparameter in a model cannot be estimated from data. They are often used in processes thelp estimate model parameters.  Hyperparameters can often be set using heuristics Often they are tuned for a given predictive modelling problem. Tsearch for the best hyperparameters, we need tpartition training data intseparate training and validation sets.  A validation set is a sample of data used tprovide an unbiased evaluation of a  model fit on the training dataset while tuning model hyperparameters.                     -  Effect of imbalanced classes: One problem that can occur in machine learning is datasets where the total number of one class of data (i.e. positive outcomes) is far less than the total number of another class of data (i.e. negative) outcomes.  This problem is very common in practice and can be detected in various disciplines  including fraud detection, anomaly detection, medical diagnosis, etc.       