1.1  Supervised Learning In supervised learning, the data used to train the algorithm is already labeled with correct answers. Supervised learning is the task of estimating a function from labelled training data.  1.2  Supervised learning algorithm Hypothesis space A selected function is considered to be similar to the real function behind the dataã€‚ Finding a function In supervised learning, given the training data, the learning algorithm seeks a function. Loss function The loss function is actually a measure of accuracy that calculates the error between the actual results. Empirical risk Empirical risk is similar to the loss function, and can be calculated by averaging the results of the loss function.  1.3  Model complexity Choosing a higher complexity than necessary will result in over-fitting the data, and a lower level of complexity than necessary will result in under-fitting the data. The best fit needs to be used to obtain a good generalization.  1.4  Occam's razor When  multiple  competing  theories  are  equal  in  other  respects,  the  theory  that  introduces  the fewest assumptions and has the lowest complexity should be selected.  1.5  Structural risk minimization Based on Occam's razor principle, a risk value, called structural risk, is defined, aiming to prevent overfitting by penalizing model complexity.  1.6  Classification metrics Confusion Matrix The confusion matrix is a summary of the predictions for a classification problem. Summarizing the number of correct and incorrect predictions in terms of count values and dividing them by each category  is  one  way  to  understand  the  type  of  errors  a  model  produces,  also  known  as  a contingency table. ROC Curve ROC  curve  is  especially  useful  for  domains  with  imbalanced  class  distribution  and  unequal classification error costs. F-1 Measure F-1 Measure is a metric that combines both Precision and Recall in a single number.  1.7  How to measure regression performance Mean Square Error Mean Square Error (MSE) Root Mean Square Error (RMSE) Mean Absolute Error (MAE) Explained Variance R-square is measured as the percentage of target variation that is explained by the model. The higher the R-square of a model, the better its performance.  1.8  Partitioning data for training and testing Sub-sampling Random  sub-sampling  repeatedly  partitions  the  data  into  random  training  and  test  sets  in  a specified ratio. Stratified Sampling Divide the entire data into different subgroups or strata, then randomly select the final subjects proportionally from the different strata. Cross-validation Partitioning the original sample into a training set to train the model, and a test set to evaluate the model.  1.9  Hyperparameters Hyperparameter is a parameter whose value is set before the learning process begins.  1.10 Effect of imbalanced classes When faced with the imbalanced classes, resampling is usually performed at the data level and adjustments are made at the algorithm level..  