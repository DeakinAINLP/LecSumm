This topic started off with an introduction to the scope of supervised learning and understanding the concept of model complexity involving the determination of how complex a machine learning model should be, the drawbacks of implementing a complex model and the scenarios where a compled model is necessary.  Other than that, I was able to understand structural risk minimisation which seeks to prevent over-fitting by incorporating a penalty on the model complexity that favours simpler functions over more complex ones. Diving into partitioning of data for the purpose of training and testing machine learning models, I learnt that to achieve a reliable model, we need to incorporate a large train set so as to minimize the variance in the data and to achieve this, there are three different methods od data splitting: - random subsampling - stratified sampling - cross validation.  