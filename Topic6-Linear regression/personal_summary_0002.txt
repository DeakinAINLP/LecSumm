topic 5 covered we initially covered supervised learning and it's forms we learnt that supervised learning is a form of ML that learns from labelled data and makes predictions based on it's learning from new unseen data that shares a attribute format with the learning data. supervised learning can be categorised as either classification predicts belonging to some class or regression predicts a value from a continuous set next model complexity was covered as the name suggests, model complexity refers to the how complex a model is , and how well it can fit the data. Occam's razor principle states that simpler models should be preferred over more complex ones if they have similar performance structural risk minimisation principle that aims to find a balance between model complexity and accuracy classification metrics help us to evaluate how well a classification model performs based on a dataset regression metrics the equivalent to above but for regression models partitioning data this is the splitting of a dataset between training and testing. finding the best hyperparameters by tweaking values in the model, you can potentially improve it. this can be done arbitrarily using brute force or following preexisting optimisation methods. imbalanced classes when one class has significantly more samples than another class in a dataset it can result in poor performance of the model on the minority class. 