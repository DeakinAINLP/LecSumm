Topic 4 Learning Summary Report  Name: Viola Birech  Assignment: Task 3.1P  Institution: Deakin University  Date: 18/04/2023  1         Topic 4 Learning Summary  Summary Report and Reflections  In topic 4 of my machine learning class, I had the opportunity to study an essential  topic in machine learning, dimensionality reduction. As a crucial aspect of data pre-  processing, dimensionality reduction aims to reduce the number of features in a dataset while  retaining the most critical information. We started by examining the concept of  dimensionality in data and how it can impact the accuracy of machine learning models.  From the class, I learnt that one of the main challenges in modelling high-dimensional  data is the curse of dimensionality. The curse of dimensionality refers to the difficulty in  analysing and modelling high-dimensional data due to the exponential increase in the number  of possible configurations. During the class, we explored the impact of the curse of  dimensionality on various machine learning algorithms and how it can lead to overfitting or  underfitting. This was a great learning experience as I see these concepts being very helpful  in my future career in data.  We also explored the various techniques used to solve the curse of dimensionality.  We learned about eigenvalues and eigenvectors and how they are used to find the principal  components of a dataset. I got to learn more about these concepts while doing the concepts  while doing the problem-solving task 4.18 and this was very critical in my understanding. We  also explored singular value decomposition (SVD), a technique that factorizes a matrix into  singular vectors and values, which can be used to reduce the dimensionality of data.  Furthermore, we delved into one of the most widely used dimensionality reduction  techniques, principal component analysis (PCA). We learned how PCA works by finding the  principal components of a dataset that capture the maximum amount of variance. We also  discussed how to implement PCA and how it can be used in facial image analysis. The  2   exciting part for this concept was being able to actually practically use PCA in an actual  example in the problem-solving task and being able to implement the concept.  We also examined other dimensionality reduction techniques, including t-distributed  stochastic neighbour embedding (t-SNE), which can be used for visualizing high-dimensional  data in a lower-dimensional space. We discussed the strengths and weaknesses of these  techniques and how to choose the most appropriate method based on the specific  requirements of the problem.  The course provided us with various practical exercises and examples to enhance our  understanding of dimensionality reduction. We had a Python practical on independent and  correlated data, where we applied PCA to reduce the dimensionality of the data. We also had  a video tutorial on visualizing correlated and uncorrelated data, where we learned how to use  Python libraries to create effective data visualizations.  Overall, topic 4 of the machine learning class was an insightful and practical study on  the crucial concept of dimensionality reduction in machine learning. I strongly believe that  the knowledge gained from this topic will be very essential for me, as it provides a solid  foundation for modelling high-dimensional data accurately. I am eagerly looking forward to  topic 5 of this class to learn and implement more machine learning concepts.  Summary of Reading List  The fourth topic of the machine learning course incorporated a range of resources for  utilization which were all similar to the previous topicsâ€™ resources. I found these resources  very helpful to my understanding of the content studied. These readings consist of textbooks  such as, Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow and Python  Machine Learning  3     Other additional resources are the various code libraries, including NumPy, pandas,  and scikit-learn which can be heavily utilized to learn and practicalize the lessons learnt.  Research papers and articles from journals are also crucial resources to enhance investigation  on current research areas in the field of machine learning. Online platforms like Kaggle and  DataCamp are also critical in utilization as supplementary materials for practice exercises and  tutorials.  Quiz Score  4      