In topic 4 , we began learning about the dimensionality of data, why we reduce it, principal component analysis, and how to implement it with python. These sections included:  -  We learnt about the dimensionality of data, including typical dimensions of data, such as:  Text data (news websites) Image data (photos)  o o o  Genomic data (data derived from genes)  -  -  -  -  The curse of dimensionality, which is that when the number of dimensions increases, the number of regions will grow exponentially. Furthermore, we also learnt about the concentration effect, and the formula that it uses, which can reduce the utility of the measure to discriminate between near and far neighbors.  Solving the curse of dimensionality by using dimensionality reduction  Eigenvalues and eigenvectors, which are used in the analysis of linear transformation. We also learnt how to find eigenvalues and eigenvectors within a matrix.  Singular value decomposition (SVD), which is a type of method that decomposes a matrix into three separate matricies  (X = USVT, where:  X = n * d matrix  o o  U = n * d orthogonal matrix o o  V = d*d orthogonal matrix  S = d * d diagonal matrix (with elements)  -  Preliminaries, and the variances across variables, such as:  o  Variance: average squared deviation of its n values around the mean of the specified variable o Covariances: measure of how changes in one variable are associated in a second variable. o Covariance matrix: matrix containing variances of all variables. o PCA: Decorrelation: rigidly rotate the axes of t- dimensional axes to a new set of axes (principal axes)  -  -  -  The formulation of PCA and deriving principle, and how to formulate it with Eigen Value decomposition (compute data covariance, perform EVD, reduce dimension data). Furthermore, we also learnt about minimum error formulation with PCA, which is an alternative formulation of PCA, which is based on projection error minimization.  The several methods of implementing PCA, such as Singular Value Decomposition (SVD), and how to use SVD for PCA.  Other dimensionality reduction techniques, such as Independent component analysis (ICA), which is separating into independent, non-Gaussian components.  