The "Curse of Dimensionality" and its effects on machine learning models, as the method for resolving this problem, we discussed about the Principal Component Analysis (PCA) and Singular Value Decomposition (SVD). Principal Component Analysis (PCA) - A common dimensionality reduction method called principal component analysis (PCA) identifies the eigenvectors of the covariance matrix with the highest eigenvalues as the principal components of a dataset. PCA can decrease the dimensionality of the data while keeping the majority of its original information by projecting the data onto a lower-dimensional space defined by the principal components. (Wikipedia Contributors, 2019) Singular Value Decomposition (SVD) - A matrix is divided into its singular values and eigenvectors using the Singular Value Decomposition (SVD) method. Applications for SVD include recommender systems, natural language processing, and image processing. (Wikipedia Contributors, 2023) Also, we discussed about the implementation of PCA and t-Distributed Stochastic Neighbor Embedding (t-SNE), were also introduced.  