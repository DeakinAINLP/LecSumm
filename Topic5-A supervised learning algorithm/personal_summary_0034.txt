 The key points covered in topic four are:  1. Issues related to data with high dimensions i.e., large number of features.  A significant number of machine learning tasks have very high dimensions e.g., facial or image recognition, self-driving cars.  2.  Curse of dimensionality and how as dimension increases, the data becomes sparse and the common distance measures become less useful in high dimensions.  The solution is to use methods to reduce the dimensionality.  3.  PCA separates the information or variances in the original datasets into principal components.  The principal components are uncorrelated with each other. This way, any redundant information in the dataset (due to correlation) is eliminated.  4.  Finding eigenvalues and eigenvectors which are used to find the principal components. 5.  Other methods of dimensionality reduction such as ICA, t-SNE and uMap.  