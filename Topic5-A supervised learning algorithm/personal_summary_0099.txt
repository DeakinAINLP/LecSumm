This topic focused on the Curse of Data Dimensionality and a strategy to solve that curse.  The Curse of Data Dimensionality  The Cuse of Data Dimensionality refers to the issues that arise when using machine learning algorithms with data will many features and therefore many dimensions.  As features are mapped across more and more dimensions, the data becomes more sparse, meaning that finding similarities and clustering like data becomes more difficult.  Additionally, given that humans cannot visualise data above 3 dimensions, working with multi dimensional data means that we cannot visualise the results of the algorithms to verify or analyse the results.  Principal Component Analysis (PCA)  Principal Component Analysis involve analysing data features to look for related or correlated data that is redundant and can be removed from a dataset. The aim of PCA is to reduce the dimensionality of the data by finding new Principal Components (linear combinations of the original data) which capture as much of the variance or detail of the original data as possible. The result of PCA are new data points which are the most important when representing the meaning of the original data, but are no longer correlated in order to make analysis more efficient. However, there is a trade off between the number of dimensions that can be reduced and keeping true to the original data.  