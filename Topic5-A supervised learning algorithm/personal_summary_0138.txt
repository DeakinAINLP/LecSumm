The major topics that were covered during topic 3 includes the curse of dimensionality, solving the curse of dimensionality, the concept of eigenvalues and eigenvectors, Singular Value Decomposition method, Principal component Analysis for dimensionality reduction and its implementation, the use of PCA in image analysis and also using python to implement the above mentioned methods. The primary reference source was the unit site contents along with the external video links and articles provided.  The initial phase introduced me to dimensionality in data, the problems caused by it due to which we call it a curse, and how to resolve the curse using dimensionality reduction were learnt. Then, I got a chance to revise some mathematical concepts including that of eigenvalue and eigenvectors. Then I gained a solid understanding of Single Value Decomposition (SVD), which helps us to split a matrix into a product three other matrices. Next, I gained knowledge related to some preliminaries such as the variance across each variable, covariance among variables and the covariance matrix. Then, I was introduced to a new topic named Principal component analysis which is a popular technique used for analysing large datasets containing a high number of feature variables and hence increasing the interpretability of the data while preserving the maximum amount of information. Later, got an overview of using PCA in facial image analysis and other dimensionality reduction techniques like Independent component analysis(ICA), Nonlinear dimensionality reduction technique and uMap. In the final phase, I acquired knowledge on implementation of PCA using python programming in which examples like 1D case, 2D case correlated and 2D case uncorrelated data were studied along with curse of dimensionality and using PCA to remove correlation in data, some inbuilt functions which can be used for PCA in python and t-SNE.       