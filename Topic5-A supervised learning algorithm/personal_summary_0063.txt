Topic 4 – Dimensionality Reduction  Dimensionality in Data Data types    Text data  Image data   Genomic data  Cures of Dimensionality What is it?    Applied when machine learning algorithms become more high advanced in way where they  require more dimensions.    When dimensionality increases, the volume of the space increases so fast that the available data  becomes sparse (spread out and diverse)   Cause clustering algorithms with problems  Official dictation    As the number of dimensions increases, the number of regions grows exponentially.   Clustering in algorithms like K nearest neighbours may be futile due to the large amounts of  dimensions.  Solving the Curse    Reducing the variables required could help create a less dimensional model. This is known as  dimension reduction.   Eigenvalues and Eigenvectors What are they?    Used in the analysis of linear transformation.    Solving system of linear equations Image processing: extract the more relevant parts of an image and reduce the dimensionality of the image to make it easier to process.  Singular value Decomposition [1]    Decomposing matrix into 3 different matrices   A factorisation of real/complex matrix; an expansion of the original data in a coordinate system;  covariance matrix is diagonal.  Preliminaries [1] What is it?    Take n data point in ‘d’ dimensions (which may or may not be related), then summarise them by  a new set of uncorrelated axes    These are called principal components/axes   Linear combinations of original d dimensions   K components are the variance among the data points as possible  Variance for each variable    Data in the form of cloud of points in a multi-dimensional space (1 axis for each variable)   Centroid is defined by the means of each variable   Variance of variable ‘j’ is the mean squared deviation of its n values around the mean of that  variable    Covariance measures change in one variable are aligned with updates in a second variable.  Covariance matrix [2]    Variances of all variables on the diagonal and co-variances among all pairs of variables in the off-  diagonal entries  Implementation of PCA What are they? [3]    A PCA plot converts the correlations among all of the features in a 2-D graph format   Features which are closely clustered together, would mean they have nice correlation (similar to  KNN)  Cases of implementing PCA    When the number of data points is less than the number of dimensions (n < d)    Given n * d matrix Y , the singular Value decomposition is given as:  Using SVD for PCA [3]  Example of using PCA in facial image analysis  Other Dimension reduction techniques Independent component analysis (ICA)  Separating multi-variate signal into independent, non-Gaussian components     Used to separate signals that are mixed together (e.g complex sound or image signals)  