 Summary: Through my study of Topic 4 I learnt by reading the content, watching the videos, taking notes and working through the activities. Evidence can be seen below.  Activity 4.1:  1.  Overview:  a.  solving the curse of dimensionality b.  eigenvalues and eigenvectors c.  principal Component Analysis (PCA) d.  Python programming : implementing PCA.  Activity 4.2: Dimensionality in Data  Activity 4.3:    Curse of Dimensionality  “In high dimensional spaces, most of the training data resides in the corners of the hypercube defining the feature space.”    Concentration effect  o  Consider PCA (principal component analysis) o o  Presence of HUBS.  ISOMAP (isometric mapping)  Activity 4.4:  1.  Solving the Curse 2.  Dimensionality reduction 3.  We will be focussing on linear dimensionality reduction problems only  Activity 4.5:  1.  Eigenvalues and Eigenvectors. Consider linear transformation, determinants, linear  systems and change of basis can be points of confusion.  Activity 4.6: Singular value decomposition SVD  Activity 4.7:  1.  Preliminaries  a.  Variance across each variable b.  Covariances among variables c.  Covariance Matrix d.  PCA: decorrelation  2.  Interesting how sum of squared distance works so well. The video was quite helpful.  Linear combination.  Activity 4.8: Formulation of PCA and deriving principal component.  PCA via Eigen Value Decomposition (EVD) PCA: Minimum Error Formulation  Activity 4.9: Implementation of PCA. Using SVD for PCA  Activity 4.10: PCA in facial image analysis I imagine the reduction of dimensionality would also be valuable in self driving cars as they would need to compute surroundings with large number of inputs.  Activity 4.11: Independent component analysis (ICA)  Activity 4.12:  Setup:  Activity 4.13: Python Practical: independent and correlated data             Activity 4.14: Visualisation of correlated and uncorrelated data       Activity 4.15: Curse of Dimensionality  Activity 4.16: PCA using Inbuilt Functions in Python      Publicly available datasets can be found at: UCI Machine Learning Repository   Activity 4.17: Optional: t-Distributed Stochastic Neighbour Embedding  