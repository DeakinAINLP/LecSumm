I have learned and implemented various dimensionality reduction techniques In this topic, I got familied with the concept and need of dimensionality reduction. This dimensionality reduction technique is mainly used for breaking the large data into different dimensions and visualizing the reduced data. At the end I have implemented T-sne ( T- distributed stochastic neighbour embedding) to visualize the data. I have also learned how to find the eigenvalues and eigen vectors of 3x3 matrices.  Learning slides summary:- I have learned various dimensionality reduction processes using the slides. I got familiar with  the need of data pre- processing, evaluation and model selection in the machine learning pipeline. I have learned about the principal component analysis, ensemble learning and various other clustering tools.  I have also attempted the quiz and the result is attached below  COMPARISION BETWEEN t-SNE and PCA t-SNE and PCA has their own advantages and dis-advantages as compare to each other, Itâ€™s the user choice to choose one of them as per their needs.    The Performance of PCA is slightly better and its cheap when compare to t-SNE   T-SNE stand out when it comes to visualization, It can produce low-dimensional embedding  that save the local structure of data.    Both PCA and t-SNE are capable of decreasing the data's dimensionality, although they do it in distinct ways. In contrast to t-SNE, which seeks to maintain the local structure of the data in a lower-dimensional space, PCA selects a linear subspace that captures the most variation in the data.    T-SNE produces non-linear transformation of the original data where as PCA produces the  linear combination of the original data which is easy to interpret   