In this topic, we focused on how we can reduce data dimensionality so that we can apply ML algorithms. We also understood the concepts and implementation of PCA and T- SNE during this topic.  Practically applying PCA and t-SNE algorithms to test and understand the differences and when to apply them based on the dataset was best highlight of this topic.  The Curse of Data Dimensionality  The Curse of Dimensionality calls for Dimensionality Reduction. Dimensionality reduction refers to the process of converting a set of data having vast dimensions into data with fewer dimensions while still making sure that it conveys similar information concisely. The Curse of Dimensionality arises when  we are analysing high-dimensional data. As the number of features increases in a dataset, the amount of data to process and produce statistically results increases exponentially. This curse leads to various problems such as overfitting, where model fits the noise in the data instead of signals which makes it complicated to generate new data and leads to time and computational complexity as well. To overcome this curse various techniques can be used such as feature selection, dimensionality reduction and regularization. PCA and T-SNE can be used to reduce the dimensions while still preserving the data information. Regularization techniques such as Lasso and Ridge regression can also be used to reduce the complexity of the model and prevent overfitting.  PCA(Principal Component Analysis)  PCA is a linear method that aims to identify the direction in data that contains the most variation. It projects the data onto these directions, called principal components, which are orthogonal to each other. The first principal component captures the most variation, followed by the second, and so on. By keeping only, the top principal components, PCA can reduce the dimensionality of the data while preserving most of the variability. This way it helps us reduce the dimensions and make data more readable and with less complexity.  PCA is mainly used to for dimensionality reduction for analysis or modelling. PCA is also faster and more computationally efficient than t-SNE, but t-SNE is better at preserving the relationships between the data points.  t-SNE  t-SNE is a non-linear method that aims to preserve the distances between data-points in a low dimensional space in a pairwise manner. It works by creating a probability distribution over pairs of high-dimensional points and a probability distribution over pairs of corresponding low-dimensional points. The algorithm then minimizes the divergence between these two distributions, resulting in a low-dimensional representation of the data that preserves the local structure of the high- dimensional space.  