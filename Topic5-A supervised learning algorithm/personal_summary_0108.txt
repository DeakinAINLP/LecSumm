 Points covered in topic 3 and 4:  Implementation of principle component analysis in python    How to solve the curse dimensionality   About the usage of eigen values and eigen vectors in machine learning   About principle component analysis    About ICA   Nonlinear dimensionality reduction techniques   Usage of tsne analysis in the python   Correlation of data   Usage of PCA to remove the correlation of data  3.Is there any correlation between these three components?  No, it doesn't appear that there is a correlation between the three components, according to the correlation matrix you gave. The matrix's off-diagonal members are all very close to zero, indicating that there is little to no linear relationship between the components when they are paired off.  It's important to keep in mind that a correlation coefficient of exactly zero does not imply that there is no relationship between two variables; rather, it simply indicates that there is no linear relationship. The variables may still be related in additional ways, such as non-linear or complicated correlations. The correlation matrix, however, indicates that the three principal components are actually independent of one another in this instance.  5. Report the comparison between the results obtained using t-SNE and PCA.  Dimensionality reduction methods that are frequently employed for data visualisation include PCA and t-SNE. Although they have certain commonalities, they differ in how they visualise the results and reduce the number of dimensions in the data.  By maximising the variance explained by each component, PCA aims to discover the key underlying components of the data. With the diabetes dataset, PCA allowed us to condense the initial 10-dimensional dataset to 3 principle components, which together accounted for more than 51% of the overall variance in the data. The resulting 3D plot revealed the data's first three primary components and provided some insight into how the information is dispersed along them.  On the other hand, t-SNE is a nonlinear method that seeks to keep the data's local structure while projecting it onto a smaller-dimensional space. The resulting graphic, which may be seen in two or three dimensions, illustrates how similar data points are to one another in the original high-dimensional space. The diabetes dataset's t-SNE plot showed that the data points were distributed pretty evenly throughout the plot, with no obvious clusters or trends.     It's vital to remember that each technique has its own advantages and disadvantages when comparing the findings of t-SNE and PCA. Although PCA is a linear method, it may not be able to capture nonlinear relationships between variables despite being computationally efficient and simple to understand. While t-SNE may be more difficult to comprehend than other nonlinear techniques, it may be more effective at capturing complex correlations between variables.  The choice of technique will depend on the specific qualities of the data and the current research objective, however both PCA and t-SNE can be valuable tools for visualising high- dimensional datasets. It's wise to compare the outcomes of various approaches and to utilise visualisations as a jumping-off point for additional data exploration and analysis.  Sources used:   GitHub   Greeks of Greek   Stack over flow   Lecture slides   Workshop materials        