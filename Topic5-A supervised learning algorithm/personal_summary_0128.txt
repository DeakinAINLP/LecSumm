Name: Shilpa Sharma Student ID: S222315366 Class: SIT720  Task 4.1  1.Summarise the main points that is covered in this topic. Ans:  ➢  Data analyzing in different dimensions like text, image & genomic. ➢  Curse of dimensionality generally takes place when ML algorithms are  used in high-dimensional data, which says when dimensionality increases the volume of the space increases.  ➢  The curse resolution was done by using the dimensionality reduction method, this simply converts all the large dimensions into fewer ones.  ➢  EigenValues & Eigenvectors are useful for calculating the linear  transformations.  ➢  Singular value decomposition method that can be used to distribute a  single matrix into three other matrices.  ➢  Covariances in variable that shows how changes in one variable effect  the changes in second variable  ➢  PCA, the selection is done in a way that the first axis has highest  variance, then the second has next highest variance where the last one in the row must have low variance.  ➢  Formulation of PCA & deriving principal components that involves  plenty of steps to calculate the derivance.  ➢  Usage of PCA in facial image analysis by calculating the covariance  matrix, eigen vector etc.  ➢  Other dimensionality reduction techniques are independent  component analysis, Non-linear dimensionality reduction technique & umap which is a new technique.  ➢  Python practical for un-correlated &correlated data, visualisation ➢  Implementation of PCA to remove data correlation. ➢  PCA using Inbuilt python functions. ➢  Distributed stochastic neighbor embedding which helps in minimizing the joint probabilities between low-dimensional & high-dimensional data.  