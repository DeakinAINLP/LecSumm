 The topics that were covered during topic 4 are solving the curse of dimensionality, eigenvalues and eigenvectors, principal component analysis(PCA). Then, implementation of PCA using python.  I referred to the unit site contents for learning the topics that were covered in topic 4 along with the external video links provided.  The learning journey started with the basics of understanding the dimensionality in Data with examples like Text data, Image data and Genomic data. Then, I acquired knowledge about the curse of dimensionality when machine learning algorithms are applied to highly dimensional data and then how to solve this curse by Dimensionality Reduction which is a process of converting a set of data having vast dimensions into data with fewer dimensions. I gained an idea on how to compute the eigenvalues and eigenvectors of a matrix. Then, I gathered knowledge about Singular value decomposition(SVD) which is a method of decomposing a matrix into three other matrices. Then, learnt about formulation of PCA and deriving principal components, how to perform PCA using Eigen value decomposition. Later, got an overview of example of using PCA in facial image analysis and other dimensionality reduction techniques like ICA(Independent component analysis), Nonlinear dimensionality reduction technique and uMap. Finally, I acquired knowledge on implementation of PCA using python program in which in which examples like 1D case, 2Dcase correlated and 2D case uncorrelated data were discussed along with curse of dimensionality and Using PCA to remove correlation in data, some inbuilt functions which can be used for PCA in python and t-SNE(t-Distributed Stochastic Neighbor Embedding).  