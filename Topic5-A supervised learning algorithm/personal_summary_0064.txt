In this topic we learnt about dimensionality reduction, what the need for reducing the dimensionality of the data is while applying ML algorithms, PCA(Principal Component Analysis), deriving different principal components and ways to implement PCA, practical application of dimensionality reduction and learning the in built functions for PCA in python.  In dimensionality reduction thereâ€™s two broad categories of techniques: Feature Extraction and Feature Selection. Feature Extraction includes PCA, ICA ( Independent Component Analysis ), and t-SNE, among others and involves creating a new variable that capture the most important information from the original values, while Feature Selection involves selecting a subset of the original values based on their relevance.  It is a great technique that can simplify datasets, improve computational efficiency, and even enhance accuracy and interpretability. However, it is important to understand the weaknesses (i.e, the trade-offs involved, the nature of the impact on accuracy and interpretability) of each technique as well, so that we can choose the best one for the desired outcome.   