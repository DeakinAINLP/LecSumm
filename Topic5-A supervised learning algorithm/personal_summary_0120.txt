 Curse of dimensionality When we want to analyse the dataset, but it is highly dimensional, we cannot plot the data due to the volume of space, so the available data become sparse.  Eigenvalues and eigenvectors are commonly used in the analysis of linear transformations. An eigenvector is a non-zero vector that, when multiplied by a square matrix, results in a scalar multiple of itself. For example, given a square matrix A and a non-zero vector v, if there exists a scalar λ such that Av = λv, then v is an eigenvector of A with eigenvalue λ.  PCA and t-SNE  Suitable for feature extraction  PCA  A deterministic algorithm Sensitive to outliers A linear dimension reduction technique  Preserve the global structure of the data Preserve variance  t-SNE Suitable for visualization and exploratory data analysis. A non- deterministic algorithm Handle outliers A non-linear dimension reduction technique Preserve the local structure of the data Preserve distance using hyperparameters   