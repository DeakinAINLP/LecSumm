 Curse of Dimensionality refers to when there are so many features that it causes the model to become less accurate as more and more features are used; this occurs because the model becomes “confused” and cannot interpret the sparsity of the different features. This problem can be avoided by reducing the number of dimensions, “Dimensionality Reduction”, this is a process of removing dimensions whilst still making sure information is conveyed similarly as to where the dimensions aren’t removed.  Eigenvalues are a set of scalars in linear equations, they are used in machine learning to identify features of data sets, which can be used to perform dimensionality reduction.  Singular value decomposition is a method of decomposing a matrix into three other matrices, there are some constraints of the matrix, the purpose of SVD is to reduce the number of values in a dataset.  Principal Component Analysis is a form of analysis that simplifies high dimensional data without losing trends and patterns.  