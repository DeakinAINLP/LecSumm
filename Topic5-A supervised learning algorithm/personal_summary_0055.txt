 This topic we first learnt about the concept of dimensionality. Dimensionality is the idea that when another feature/characteristic is added to a dataset, it adds another dimension when plotting the points. This means that since data can only be drawn in a space of up to 3 dimensions, if any other dimensions or features are added to the data set, the data can no longer be represented in 3D space visually. However the main problem of a dataset with high dimensionality, is that as the dimensions increase, the volume of the space increases so quickly that data points become sparse as there are a lot of possible combinations not represented. This also means that distances between data points in the same cluster become negligible relative to the rest of the space. This is called the Curse of Dimensionality.  We then learnt about Eigenvalues, Eigenvectors and Singular Value Decomposition. These are useful in dimension reduction to lessen the effects of high dimensional data sets. Single Value Decomposition (SVD) is useful in dimension reduction as it is a way of only retaining important columns(features) in the U and V matrices, based on the amount of variation caused by each column. Eigenvalues and Eigenvectors are used in generating the SVD matrices and also in performing PCA (Principal Component Analysis).  PCA is a dimension reduction method that selects dimensions that have the greatest variance. This means that dimensions that have low variance can be removed from the dataset and most of the information regarding the data points and how similar/close to each other they are, is retained as high variance dimensions are kept in the data set. We learnt the theory behind this method and how to perform PCA on a data set and then learnt how to program it in Python.  Reflection  This was a lot of information to go through in this module. I struggled with the Eigenvalue and SVD parts of the content but I now think I have a decent understanding of it. PCA was a super interesting concept to go through as it seems to be such a useful tool in lowering the amount of dimensions in a dataset so itâ€™s easier to work with. I can see how it can be used in analysing big data sets and how I could use it in my own workplace when I have large datasets to deal with.   