  Curse of dimensionality is caused by high dimensional data  The more dimensions, the more spread out the data is and the more sparse it becomes  Dimensionality reduction is used to counter curse of dimensionality It reduces the number of dimensions while preserving variance   Eigenvalues and eigenvectors are used to analyse linear transformations singular value decomposition decomposes a matrix into three other matrices  PCA takes correlated data and puts it on uncorrelated axes   The uncorrelated axes are known as principle components  Reflection: I learned a lot of new things this topic. I learned about dimensionality and how it can be analysed. I learned how higher dimension data is formed and why it is important to analyse it correctly. I learned about PCA and eigenvalues and eigenvectors. I also learned how to work with dimensionality and PCA in python.  