The need of neural networks in some machine learning problems:  linear models may not be sufficient when the underlying functions or decision boundaries are extremely nonlinear support vector machines can construct nonlinear functions but use fixed feature transformation  In a neural network system:    a typical neural network (machine) has an input layer;      it has one or many hidden layers; it has combiners (sum functions); it has nonlinear activation functions; it has an output layer.  A perceptron is a linear classifier (binary) and is a single layer neural network. A multi-layer perceptron is called a neural network.  It is not always possible to separate the data points class label with a single line. For AND and OR logical gates or functions, it is possible to classify them with a single line. But XOR function is not linearly separable.  a multilayer perceptron (MLP) can represent the XOR problem.  For complex, non-linear decision surfaces, we need a multi-layer perceptron network. A more complex activation function allows the network to combine the inputs in more complex ways and in turn provides a richer capability in the functions they can model.  Feedforward neural network is an Artificial Neural Network (ANN) where connections between units do not form a cycle. In this network, the information moves in only one direction, forward, from the input nodes, through the hidden nodes (if any) and to the output nodes. There are no cycles or loops in the network.  A multi-layer feed-forward Neural Network (NN) is also known as a Multi-layer Perceptron (MLP  A deep learning model is designed to continually analyse data with a logic structure similar to how a human would draw conclusions. To achieve this, deep learning uses a layered structure of algorithms similar to ANNs.  