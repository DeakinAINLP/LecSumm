 This topic was all about machine learning models for non-linearly separable problems. We first learnt about perceptrons and how they were inspired by biology. These are the basis of Artificial Neural Networks or ANN’s. A perceptron is a single layer neural network with binary classification behaviour.  These perceptrons are great at solving linearly separable problems however they struggle with non-linearly separable problems. Perceptrons can take in multiple inputs, each with their associated weights to influence the perceptrons output and pass those inputs through an activation function to produce an output.  The idea of an MLP or Multi Layer Perceptron is to combine multiple perceptrons together to create a model that is capable of solving non-linearly separable problems. These contain an input layer, hidden layers and an output layer.  Depending on the data and the initial performance of the model, some tuning of parameters might be necessary. Changing the activation function, learning rate, solver function and max iterations can all have an impact on the model’s performance.  We then learnt how to create an MLP and a perceptron classifier in python using two different datasets.  Reflection  I had never written any code on making a perceptron before or an MLP. This was very new to me but I can see how powerful it can be especially when the dataset is understood and hyperparameters can be tuned.  I had some issues initially where my import statement for the fetch_lfw_people dataset wasn’t working, saying it didn’t exist. Turned out to just be taking a long time for it to download and nothing was actually wrong with the code. The first run of the model had very poor performance according to the classification report so it was good to see the performance metrics increase when making edits to the parameters of the model.   