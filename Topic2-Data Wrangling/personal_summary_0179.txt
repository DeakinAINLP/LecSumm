 Main points summary  -  A typical neural network consists of:  o  an input layer o  one or many hidden layers o  sum functions o  nonlinear activation functions o  an output layer  -  A perceptron is a linear classifier (binary) and is a single layer neural network, using the Heaviside step function (sign function) as the activation function. A perceptron receives as input a number of features with corresponding weights and a bias term. A sum function will calculate a value, which later goes through the activation function and is presented as the output. A multi-layer perceptron is called a neural network, and is necessary when the data points in a problem are not linearly separable.  -  Backpropagation is an algorithm used for training feedforward artificial neural  networks.  -  Convolutional Networks (CNN) is a common Deep Learning architecture, and  consist of three basic concepts: o  Sparse interactions o  Parameter sharing windows o  Translation invariance  -  An Autoencoder is a neural network which can handle many hidden layers in its  structure, with the aim of learning a representation for a set of data, typically for the purpose of dimensionality reduction.  