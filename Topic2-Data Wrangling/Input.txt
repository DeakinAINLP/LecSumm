In a CNN every network layer acts as a detection filter for the presence of specific features or patterns present in the original data. The first layers in a CNN detect large features that can be recognized and interpreted relatively easily. As you can see the patch which has been shown in red (figure below) are found for interpreting the right side batch of images. Using other categories of images with this filter may not give proper results. In other words, each image filter patch is for finding a specific part of a pattern or texture. Figure. Layers 1 and 2, source (Olah n.d.) You can see the same concept rules in layers 3, 4 and 5. Remember you need a large set of data for feeding these deep networks, otherwise the results can be useless. Figure. Layer 3, source (Olah n.d.) Figure. Layers 4 and 5, source (Olah n.d.) So what has helped deep learning to boost the field: The ability of modelling Larger models with new training techniques: Dropout, Maxout, Maxnorm, ReLU,… Large ImageNet dataset 1.2 million training samples 1000 categories Using fast graphical processing units (GPU) Capable of 1 trillion operations per second! These 3 factors are the most important solutions to the many challenges deep learning was facing at first. They have allowed deep learning to be practically useful. View transcript SPEAKER 1: In this tutorial, we're going to show you some basic applications of CNN. So what kind of data are we usually dealing with in deep learning, or in this case, CNN? So one of the most famous ones is CIFAR 10, which is a dataset made out of 50,000 training images and 10,000 test images. The categories or classes in this dataset is made out of truck, sheep, horse, many other things. Also there is another dataset called ImageNet which has the millions of images. So as we have said before, our data is pretty important and in deep learning applications. Now let's jump into the CNN layers and see how they're working. Consider this patch. We call these philtres, or CNN weights, which are particularly for this type of data. For example, this one is particularly made for this type of data. So if this type of data comes in, the maximum response will be returned. So these patches are designed to pass this type of patterns. If anything else comes in, the return signal would be low. So we call this layer the low level features. As you can see in the next layer, more details-- such as tyres, birds, and people-- are available. So it means this layer has more meaningful features. We call this level mid-level layers, with more meaningful features. So finally, these last layers are the high-level layers of features, which you can see the pattern and the patches inside them. For example, consider this. That looks to be a bicycle. So as you can see, you can detect some sort of pattern for this-- for the wheels of the bicycle. So this was an illustration of different layers of CNN, but let us remind you again, you should have a good amount of data while working with many layers of structures, such as CNN, unless you're in danger of overfitting based on your data. Activity This video tutorial will provide some visualization of the CNN layers. Please discuss your understanding in the discussion forum. This is an additional video, hosted on YouTube. References Autoencoder An Autoencoder is a neural network which can handle many hidden layers in its structure. The aim of an Autoencoder is to learn a representation (encoding) for a set of data, typically for the purpose of dimensionality reduction. This type of neural network is trained to attempt to copy its input to its output. Internally, it has a hidden layer Z{"version":"1.1","math":"\(Z\)"} that describes a code used to represent the input. Recently, the Autoencoder concept has become more widely used for learning generative models of data. Figure. Simple structure of Autoencoder Consider the above figure as a simple illustration of Autoencoder. The aim is pretty simple. We would like to reconstruct the x=[x1,…,xN]T{"version":"1.1","math":"\({x} = [x_1,\dots,x_N]^T\)"} input features, in the output r=[r1,r2,…,rN]T{"version":"1.1","math":"\({r} = [r_1,r_2,\dots,r_N]^T\)"} with the help of a hidden layer (it could be many hidden layers, consider only one for now) Z=[Z1,...,ZK]T=fθ(x){"version":"1.1","math":"\({Z} = [Z_1,...,Z_K]^T = f_{\theta}({x})\)"}. If we can successfully do this task, then we can extract the hidden layer Z{"version":"1.1","math":"\(Z\)"} and take this as a more compact and meaningful vector which is able to reconstruct the exact data. An Autoencoder learns to compress data from the input layer into a short code, and then uncompress that code into something that closely matches the original data. This forces the Autoencoder to engage in dimensionality reduction, for example by learning how to ignore noise. As you may have guessed, the loss function of the Autoencoder should find the difference between the input and the output, since basically we are aiming for outputs that are the same as inputs. So a loss function J{"version":"1.1","math":"\(\mathcal{J}\)"} computes a scalar J(x,r){"version":"1.1","math":"\(\mathcal{J}({x},{r})\)"} to measure how good a reconstruction r{"version":"1.1","math":"\(r\)"} of a given input is x{"version":"1.1","math":"\(x\)"}: J(x,r)=∑n−1N(xn−rn)2{"version":"1.1","math":"\(\mathcal{J}({x},{r}) = \sum_{n-1}^{N} (x_n - r_n)^2\)"} Obviously we would like to minimize this error as the learning objective: minθ,ϕJ(x,r){"version":"1.1","math":"\(\min_{\theta,\phi} \mathcal{J}({x},{r})\)"} Autoencoders are another way of feature learning. The solution is trivial, which means the solution or example are ridiculously simple and of little interest, unless there are constraints (such as sparsity) on the number of nodes in the hidden layers. A linear Autoencoder with K<N{"version":"1.1","math":"\(% <! K<N %>\)"} acts as a PCA which we covered in topics 3 and 4. It is non-linearity that makes it powerful. If you have a look at the figure below, you can detect the layer h3{"version":"1.1","math":"\(h_3\)"}. Figure. Illustration of Deep Autoencoder. After the learning procedure, we can use this hidden layer of codes to reconstruct the original feature vector. However, this hidden layer which is an encoded version of inputs, is much smaller and more meaningful. So, rather than using the whole large feature vector (v{"version":"1.1","math":"\(v\)"}), h3{"version":"1.1","math":"\(h_3\)"} or the encoded hidden layer could be used. Activity In this video, You will explore the backpropagation algorithm, which is used for training MLPs. As you learnt in the previous lesson, the basic concept of training MLPs is a stochastic gradient-descent rule. Based on the gradient-descent rule we have already shown, you can write the updating formula for wjk{"version":"1.1","math":"\(w_{jk}\)"}. In the video you will also go through the algorithm. The input is the training data. You will initialise the weights at the start and update them until the stopping criteria (which could be accuracy or number of iterations or the amount of change) is met. View transcript SPEAKER 1: In this tutorial, we're going to explain to you the backpropagation algorithm, which is used for training MLPs. Consider this neural network. These are the inputs. This is the hidden layer and this is the output layer. If you remember the gradient descent from the previous section, the basic concept of training MLP is a stochastic gradient descent rule. If you remember, our aim is to minimise instantaneous approximation for current training sample, xd and xy. So this is our error of function. y hat k is our approximated output for input data. And yk is the true value of the output for that data. Let us first show you how to update the weights of the hidden layer to output layer, wjko. Based on the gradient descent rule we have already shown you, we can write the updating formula for wjk. It is wjko can be updated as wjk minus eta partial derivative of Etw, with respect to wjko. This is the basic formulation of gradient descent for finding the minimum value of this error function based on or with respect to these weights, which are wjk. We also define another value called y bar k, which is the unsigmoided argument value at output node k. If you remember in MLP, before returning the final value in the output layer, we will use a sigmoid function on the outputs. So consider this yk as the value before using the sigmoid on that. Now, the only question remains is how to find this value. Let us expand this value. So the partial derivative of Et with respect to wjk is equal to the partial derivative of Et with respect to y bar k multiplied by partial derivative of y bar k with respect to wjk. We call this the chain rule. So as you can see, we can simply cancel these two values and we still have the partial derivative of Et with respect to wjk. OK. So as we have said before, the y bar k is wjkzj. If you look at here, if you have these z values in here, and if you multiply them by this weight function, this is the output values before using the sigmoid. So if you know y bar k is the summation of wjkzj, now if you take the derivative with respect to wjk, the output would be zj, which as you can see, this is the value of this particular derivative. The next one, again, you're using the chain rule for the first one. You're writing the partial derivative of Et with respect to y bar k is equal to the partial derivative of Et with respect to y hat k multiplied by the partial derivative of y hat k with respect to y bar k. Now, this one is just a sigmoid function. If you remember, the derivative of a sigmoid function is one minus the sigmoid function multiplied by sigmoid function. So this is only 1 minus y hat k multiplied in y hat k. Also, the value of this one is pretty simple to calculate because we have this error function here. And if you take the derivative with respect to y hat k, this two will come here. Add it to this 1 over 2 and the minus will be added in here too. So it's minus yk minus y hat k. Now, we have to sum all these variables together to find the final update formula. We can call this 2 delta ko, which is 1 minus y hat k multiplied by y hat k. And this one is minus yk minus y hat k. So these two are making this delta k. And also, we have 1zj in here. So the updating rule for the weights from the hidden layer to the output layer is wjko, it should be updated as wjko plus eta, the delta which we found in here, and the zj. So this is a simple formula for updating the weights from hidden layer to the output layer. So we learned how can we update the wjk weights, the weights between the hidden layer to the output layer? But we need to update wij's too, which are the weights from input layer to the hidden layer. Let's see how can we do this. So for updating wijh, again, we're writing the error function. Also, we are defining zj as the sigmoid function over z bar j. And z bar j is exactly the same concept as y bar k. So it's the unsigmoided value of zj, which is simply the multiplication of xi and to the wijh. And there is a summation from i1 to im. So based on the gradient descent rule, the updating formula should be something like this. wij should be updated as wij minus eta, partial derivative of etw with respect to wijh. OK. Again, we need to find this value. So we're using the chain rule again. The chain rule says, if you can write this value as partial derivative of Et with respect to z bar j multiplied by the partial derivative of z bar j with respect to wij. So this one is simple xi. And the reason is z bar j is this. So if you take the derivative with respect to wij, what remains is only xi. Again, we can expand this one way by chain rule, and we can write the partial derivatives of Et with respect to z bar j equals the partial derivative of eta with respect to zj times the partial derivative of zj with respect to z bar j. So as we have said before, this value is simply the derivative of a sigmoid function, which is 1 minus the function multiplied in the function. Which is zj 1 minus zj. But what about this one? For finding the partial derivatives of Et with respect to zj, we're using the chain rule again. But there is a difference in here. As you can see, you can say the partial derivatives of Et with respect to y bar k multiplied by the partial derivative of y bar k with respect to zj. But in here, we didn't have the k in this formula, so we're adding the k. So we're obliged to consider all the k's. K equals 1 to k. So now, we have a summation over this value. So knowing here, for finding this quantity, you're saying the partial derivative of y bar k with respect to zj, if you consider the y bar k, it was just this one and the y bar k was this value. And the partial derivative of this with respect to zj is only wjk. So this quantity is wjk. And this one is also, we calculated before, and it's minus delta ko. If you remember, we calculated this for updating the weights from the hidden layer to the output layer. So now, we can write the partial derivatives of Et with respect to z bar j is minus delta jh, which is equal to minus zj, 1 minus zj, which is this value. And also, this summation, which is the summation from k equals 1 to k, wjk, delta ko. So finally, we can write the updating formula of wij2. And it's like wij should be updated as wij plus eta, delta jh xi. And the xi was from here. So this is the way we're using back propagation in the training MLP. Now that we have learned how to update the weights in detail, it's a good time to go through the algorithm. As we said, the input is the training data. And we are initializing the weights at the start. And until the stopping criteria is met, which could be accuracy or number of iterations or the amount of change, we are having a loop, a for loop. And we're saying for each training sample, compute the values of the hidden nodes, z and y hat, which is the hidden layer and the output layer. Then, we compute the output error like this, delta ko, as we have calculated in the previous slides. Also, we are computing the hidden error term for the weights from the input layer to the hidden layer, which is something like this. Now, we can update the weights based on this one. For the hidden layer to the output layer weights, we are updating like this. wjk should be updated as wjk plus eta delta k hj. And for the weights from input layer to the hidden layer. You're saying wij should be updated as wij plus eta, delta jh xi. And as the final value, we are returning the weights. Then when a new point comes in, you're just multiplying in the weights and finding the z and then you're finding the y. And then, we can return the final label or the value of the new training sample. So this was an explanation of how backpropagation algorithm works in MLP training. Activity Convolutional Neural Networks The architecture of a Convolutional Neural Network (CNN or ConvNet) is modelled after the mammalian visual cortex, the part of the brain where visual input is processed. Within the visual cortex, specific neurons fire only when particular phenomena are in the field of vision. For example, one neuron might fire only when you are looking at a left-sloping diagonal line and another only when a horizontal line is in view. Our brains process images in layers of increasing complexity. The first layer distinguishes basic attributes like lines and curves. At higher levels, the brain recognizes that a configuration of edges and colours is, for instance, a house or a bird. Consider the figure below. Focusing on the regions of the image is the main attribute. As you can see in the figure, this network does not appear to be fully connected (it’s not going to use all the pixels) and is dealing with local regions which result in sparsity and locality. Figure. How a CNN works on different regions. CNNs are made of three basic concepts: Sparse interactions: Sparse weights within a smaller kernel (e.g., 3×3{"version":"1.1","math":"\(3 \times 3\)"},5×5{"version":"1.1","math":"\(5 \times 5\)"}) instead of the whole input. This helps reduce the number of parameters. The term kernel in CNN generally refers to an operator applied to the entirety of the image such that it transforms the information encoded in the pixels (see the figure above). Parameter sharing: A kernel uses the same set of weights while applying to different locations (sliding windows). Translation invariance: Invariance means that you can recognize an object as an object, even when its appearance varies in some way. This is generally a good thing, because it allows abstraction of an object’s identity or category from the specifics of the visual input. For example it will recognise the object even with different relative positions of the viewer/camera and the object (see figure below). Figure. Translation invariance LeNe5 The very first CNN called LeNe5 was introduced by Yann LeCun. The LeNet5 architecture was fundamental. In particular the insight that image features are distributed across the entire image and that convolutions with learnable parameters are an effective way to extract similar features at multiple locations with few parameters. The following figures illustrate the structure of LeNet5. Figure. LeNet5 structure. Figure. General LeNet5 structure. Source: (O’Shea & Nash 2015)  In the figure above the CNN architecture is comprised of just five layers. As O’Shea & Nash (2015) highlight, the basic functionality of the example CNN above can be divided into 4{"version":"1.1","math":"\(4\)"}  key areas: As found in other forms of ANN, the input layer will hold the pixel values of the image. In the previous figure, you see a picture of a number 0{"version":"1.1","math":"\(0\)"}as an input to the CNN. The convolutional layer will determine the output of neurons which are connected to local regions of the input through the calculation of the scalar product between their weights and the region connected to the input volume. The rectified linear unit (commonly shortened to ReLu) aims to introduce to LeNet5, an elementwise activation function such as sigmoid to the output of the activation produced by the previous layer. The pooling layer will then simply perform downsampling along the spatial dimensionality of the given input, further reducing the number of parameters within that activation. The fully-connected layers will then perform the same duties found in standard ANNs and attempt to produce class scores from the activations, to be used for classification. ReLu may be used between these layers to improve performance. Through this simple method of transformation, CNNs are able to transform the original input layer-by-layer using convolutional and downsampling techniques to produce class scores for classification and regression purposes. To conclude, LeNet5 features can be summarized as: a convolutional neural network that uses a sequence of 3 layers: convolution, pooling, non-linearity uses convolution to extract spatial features subsamples using spatial average of maps nonlinearity in the form of tanh{"version":"1.1","math":"\(tanh\)"} orsigmoids{"version":"1.1","math":"\(sigmoids\)"} basically an MLP as final classifier uses a sparse connection matrix between layers to avoid large computational cost Overall this network was the origin of many recent architectures and a true inspiration for many people in the field. Activity If you are interested, please go through the following video tutorial to get more information on CNNs This is an additional video, hosted on YouTube. Step-1: Import require library for deep learning model import tensorflow as tf import tensorflow_datasets as tfds Step-2: Load a dataset (ds_train, ds_test), ds_info = tfds.load(     'mnist',     split=['train', 'test'],     shuffle_files=True,     as_supervised=True,     with_info=True, ) Step-3: Normalise dataset def normalize_img(image, label):   """Normalizes images: `uint8` -> `float32`."""   return tf.cast(image, tf.float32) / 255., label Step-4: Train and Test data spliting ds_train = ds_train.map(     normalize_img, num_parallel_calls=tf.data.AUTOTUNE) ds_train = ds_train.cache() ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples) ds_train = ds_train.batch(128) ds_train = ds_train.prefetch(tf.data.AUTOTUNE) ds_test = ds_test.map(     normalize_img, num_parallel_calls=tf.data.AUTOTUNE) ds_test = ds_test.batch(128) ds_test = ds_test.cache() ds_test = ds_test.prefetch(tf.data.AUTOTUNE) Step-5: Create and train the model model = tf.keras.models.Sequential([   tf.keras.layers.Flatten(input_shape=(28, 28)),   tf.keras.layers.Dense(128, activation='relu'),   tf.keras.layers.Dense(64, activation='relu'),   tf.keras.layers.Dense(10,activation='softmax') ]) model.compile(     optimizer=tf.keras.optimizers.SGD(0.001),     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),     metrics=[tf.keras.metrics.SparseCategoricalAccuracy()], ) model.fit(     ds_train,     epochs=10,     validation_data=ds_test, ) Introduction to Deep Learning A deep learning model is designed to continually analyze data with a logic structure similar to how a human would draw conclusions. To achieve this, deep learning uses a layered structure of algorithms similar to ANNs. Deep learning methods are advanced neural networks. They have been successful in learning many real world tasks (e.g. handwritten digit recognition, image recognition). Some of the common Deep learning architectures are: Convolutional Networks Autoencoders Deep Belief Networks Boltzmann Machines Restricted Boltzmann Machines Deep Boltzmann Machines Deep Neural Networks In the next section we are going to cover basic concepts of Convolutional Networks (CNN) as it is one of the most important deep learning architectures. Activity Motivation and inspiration Our brain has networks of inter-connected neurons and a highly-parallel architecture. Development of Artificial Neural Networks(ANNs) is motivated by biological neural systems. Is there a necessity for neural networks in some machine learning problems? First we need to answer the question of what is different about Neural Networks? linear models may not be sufficient when the underlying functions or decision boundaries are extremely nonlinear support vector machines can construct nonlinear functions but use fixed feature transformations, which depends on the kernel function. For example, while you are using linear kernel, obviously your model output will be a linear model. What if you are not sure about the kernels or perhaps you prefer to learn these features from the data itself? Neural Networks allow the feature transformations to be learnt from data. Historical approaches In machine learning, two groups of ANN researchers are working on this problem: one group uses ANN to study and model the brain the other group uses the brain as the motivation to design ANNs as effective learning machines, which might not result in a true model of the brain In this course we will follow the second group’s approach. Neurons There are billions of neurons in your brain. Estimates range from 50 billion to 500 billion. (Woodford 2018) Figure. Neuron structure Brain function The brain is occupied with various tasks as we go about our day. For example approximately: 15% devoted to low-level vision tasks; 15% to image and action recognition; 15% to objects detection and tracking; 15% to speech recognition and pronunciation; 10% to reinforcement learning (orbitofrontal cortex and part of medial prefrontal cortex); Remaining perform miscellaneous tasks. Let’s have a look at the physical distribution of tasks in the brain (below). Figure. Structure of the brain. source:(Shakirov 2016) The brain takes physical or mental stimuli as input, processes it and, if necessary, produces an output. For example, perhaps you see a dog. Your brain processes that visual and auditory input and, depending on your past experiences, produces a desire to pat the dog or run away etc. Motivation for multilayer perceptron Is it always possible to separate the data points based on their class label with a single line? Consider the AND and OR logical gates or functions. As you can see in the figure, we can show that both of these problems are linearly separable in 1{"version":"1.1","math":"\(1\)"} and 0{"version":"1.1","math":"\(0\)"} class labels: Figure. Linearly separable problems. We can easily find a line to divide based on the class labels. But what about the XOR problem? This problem is not linearly separable. As you can see in the next figure (below), it is impossible to separate the data points based on their class labels with a single line. Figure. XOR - Nonlinear problem These kinds of problems were a motivation to develop a new neural network, but this time with a layer in the middle to handle these cases. Later it was proven that a multilayer perceptron (MLP) can represent the XOR problem. Figure. Multilayer perceptron representing the XOR problem Activity Multilayer perceptron A perceptron is quite weak in what it can represent. For complex, non-linear decision surfaces, we need a multi-layer network. If you remember the sign{"version":"1.1","math":"\(sign\)"} function in a perceptron, we are had a−1,1{"version":"1.1","math":"\(-1,1\)"}  (binary) output but choosing a more complex activation function allows the network to combine the inputs in more complex ways and in turn provides a richer capability in the functions they can model. Non-linear functions like the logistic, (also called the sigmoid function), output a value between 0{"version":"1.1","math":"\(0\)"} and 1{"version":"1.1","math":"\(1\)"} with an s-shaped distribution. Choice of node in a multi-layer network should be continuous but it should be a continuous meaningful function such as the sigmoid function. It may sound complicated but it’s quite simple; like a perceptron we have a function, but this time it is a sigmoid function σ(Z)=(1+e−Z)−1{"version":"1.1","math":"\(\sigma(Z) = (1+e^{-Z})^{-1}\)"} and y=σ(wTx){"version":"1.1","math":"\(y=\sigma({w}^T{x})\)"} instead of the sign function such as y=sign(wTx){"version":"1.1","math":"\(y = sign({w}^T{x})\)"}. Check the following figure for summarizing the points we have proposed. In this figure we have also calculated the first derivative of the sigmoid function. dσ(Z)dZ{"version":"1.1","math":"\(\frac{d\sigma(Z)}{dZ}\)"}.  Later this is useful to know! It could be good practice to calculate the derivative by yourself. Figure. sign{"version":"1.1","math":"\(sign\)"} function or a sigmoid{"version":"1.1","math":"\(sigmoid\)"} function.  Feedforward neural networks A feedforward neural network is an Artificial Neural Network (ANN) where connections between units do not form a cycle. In this network, the information moves in only one direction, forward, from the input nodes, through the hidden nodes (if any) and to the output nodes. There are no cycles or loops in the network. A multi-layer feed-forward Neural Network (NN) is also known as a Multi-layer Perceptron (MLP). The term MLP is really an accurate name because the model comprises multiple layers of logistic regression like models (with continuous non-linearities) rather than multiple perceptrons (with discontinuous non-linearities). Although this may not be a good choice, we will continue using the term MLP! Notes on the MLP Consider a two-layer network: input layer, hidden layer and output layer (see figure below). Figure. Two-layer neural network. There are some really important facts about this network you should consider: the output is a vector there are two kinds of weights here: input → hidden hidden → output wijh{"version":"1.1","math":"\(w_{ij}^{h}\)"} from ith{"version":"1.1","math":"\(i^{th}\)"} input → jth{"version":"1.1","math":"\(j^{th}\)"} hidden wijo{"version":"1.1","math":"\(w_{ij}^{o}\)"} from jth{"version":"1.1","math":"\(j^{th}\)"} hidden → kth{"version":"1.1","math":"\(k^{th}\)"} output the input layer does no computation - it only relays the input vector it can have more than one hidden layer another interesting feature is that it does not have to be fully connected. Though it looks to be a simple structure and mode, later we can see how powerful it is. The figure below shows one of the early applications of ANNs in image processing and self-driving cars! The output of this ANN, as you would expect, is the degree of steering in a particular direction. Figure. Early stages of ANNs: Using ANN for computer vision applications. MLP Formulation Now we explore the formulations behind the MLP. Consider the ANN from you before. Figure. Two-layer neural network. Given input xt{"version":"1.1","math":"\(x_t\)"} and desired output yt,  t=1,…,n{"version":"1.1","math":"\({y}_t, \ \ t=1,\dots,n\)"} the aim is to find the network weights w{"version":"1.1","math":"\(w\)"} so that the predicted values will be as close as possible to the real ones. y^t≈yt{"version":"1.1","math":"\(\hat{y}_t \approx{y}_t\)"}  In other words, we would like to minimise the error which is the difference of the predicted value compared to the real true value of the output. We are stating the above as an optimisation problem: find w{"version":"1.1","math":"\(w\)"}to minimise the error function: Figure: An example of gradient-descent minimization In this case, we will use gradient-descent for minimisation. E(w){"version":"1.1","math":"\(E({w})\)"} is not convex, rather it is a complex function with potentially many local minima. For solving this problem, we will use an algorithm called Backpropagation. Before we go through Backpropagation, let’s first remind you of the important concepts about Gradient-based Optimization Detour: Gradient-based Optimization Gradient-based optimisation methods are operated with the search directions defined by the gradient of the function at the current point. Consider the following figure as a convex function. Figure. Example of a convex function. At a point in 2{"version":"1.1","math":"\(2\)"}D such as x=(x1,x2){"version":"1.1","math":"\({x} = (x_1,x_2)\)"}, the gradient vector of the function  f(x){"version":"1.1","math":"\(f({x})\)"},  w.r.t x{"version":"1.1","math":"\(x\) "} is: ∇f(x)=(∂f∂x1,∂f∂x2){"version":"1.1","math":"\(\nabla f({x}) = \Big(\frac{\partial f}{\partial x_1},\frac{\partial f}{\partial x_2} \Big)\)"}  ∇f(x){"version":"1.1","math":"\(\nabla f({x})\)"} represents the direction that produces the steepest increase in f{"version":"1.1","math":"\(f\)"}.  Similarly −∇f(x){"version":"1.1","math":"\(-\nabla f({x})\)"} is the direction of the steepest decrease in f{"version":"1.1","math":"\(f\)"}. So to minimise a function such as f(x){"version":"1.1","math":"\(f({x})\)"}, we should use gradient-descent using the following steps: Initialise random x0{"version":"1.1","math":"\({x}_0\)"} Slide down the surface of f{"version":"1.1","math":"\(f\)"} in the direction of the steepest decrease: xt+1=xt−η×∇f(xt){"version":"1.1","math":"\({x}_{t+1} = {x}_t - \eta \times \nabla f({x}_t)\)"} Based on previous explanations on maximising the function f{"version":"1.1","math":"\(f\)"}, you can use a similar method to maximise f(x){"version":"1.1","math":"\(f({x})\)"} ie. use gradient-ascent as: xt+1=xt+η×∇f(xt){"version":"1.1","math":"\({x}_{t+1} = {x}_t + \eta \times \nabla f({x}_t)\)"} By finding the true direction towards the optimal point and the magnitude of the movement towards it, gradient-descent finds the optimal point. It is a very useful approach even in ANNs. The following figure illustrates an example of the gradient-descent method on the sample convex function. Figure. How Gradient-Descent works from x0{"version":"1.1","math":"\(x_0\)"} to minimum point x∗{"version":"1.1","math":"\({x}^*\)"} If we incorporate this idea in the error function we had before, we can minimise the error value between the true output and the predicted one in each iteration. Remember that we defined E(w){"version":"1.1","math":"\(E({w})\)"} the error function, as: Et(w)=12∑k=1K(ytk−y^tk)2{"version":"1.1","math":"\(E_t({w}) = \frac{1}{2} \sum_{k=1}^{K} (y_{tk} - \hat{y}_{tk})^2\)"}  Based on the gradient-descent, for minimising this function we need an update rule (where t{"version":"1.1","math":"\(t\)"} denotes the current training sample) which is:  wi←wi−η∂Et(w)∂wi{"version":"1.1","math":"\(w_i \leftarrow w_i - \eta \frac{\partial E_{t} ({w})}{\partial {w}_i}\)"} So instead of minimising E(w){"version":"1.1","math":"\(E({w})\)"}, the Stochastic Gradient-Descent (SGD) minimises the instantaneous approximation E(w){"version":"1.1","math":"\(E({w})\)"} of  using only the t−{"version":"1.1","math":"\(t-\)"}th instance. SGD is cheap to perform and guaranteed to reach a local minimum in a stochastic sense. Now that you have an understanding of gradient-descent, it is time to move to the Backpropagation algorithm. Activity Neural system basics With the brain in mind, let’s introduce the major players in a neural network system: a typical neural network (machine) has an input layer; it has one or many hidden layers; it has combiners (sum functions); it has nonlinear activation functions; it has an output layer. Carefully pay attention to the important terms such as input layer, output layer and hidden layers. The following figure is shows two examples of simple neural network structures. Figure. Simple diagram of neural networks. As you can see, there is always an input layer which is responsible for taking the input features. In the example on the left we can see that the input layer has 3 dimensions. The output layer has 2 dimensions. It has only one hidden later with size of 4. In the example on the right, we have another bigger neural network with 3 input dimensions, 2 hidden layers with size of 4 and one single dimension output which could be a binary value such as 0 or 1. Complexity Figure. Diagram of a more complex neural network. We can have more complex, bigger neural networks because neural networks are compatible with high dimensional inputs and multi-label classification. As you can see in the figure above, the diagram shows a complex neural network with 3 hidden layers and one high dimensional input layer with a 3 dimensional output layer. Remember having a more complex neural network can result in over-fitting if you are not providing enough training data. Activity The article Neural networks by Chris Woodford explains the similarities between the human brain and artificial neural networks. It's written for a broader audience, so is very easy to read. After reading the article, share your insights about the future of ANNs in the discussion forum. Reference Other resources for Deep learning This was a very brief introduction to deep learning. This a growing field that will greatly affect our future. For those of you who are interested, here are some useful resources: Books Deep learning textbook (Goodfellow et. al., 2016) Deep learning: an overview (Jurgen, 2015) Deep learning (Michael Nielsen, 2016) A statistical view of deep learning (Shakir Mohamed, 2015) Courses/Tutorials Hugo Youtube channel Colah’s blog: very nice visualizations for easier and better understanding. Karpathy’s blog: deep learning in web browsers. Tools Tensorflow (Google) Keras Theano (Montreal – Bengio et. al.) Lasange, Keras Caffe(Berkeley) Torch(Facebook) Perceptron is a linear classifier (binary) and is a single layer neural network. A multi-layer perceptron is called a neural network. The following figure is a simple illustration of a perceptron. Figure. Illustration of perceptron structure As you can see we are dealing with x1,…,xM{"version":"1.1","math":"\(x_1,\dots,x_M\)"} features with w1,…,wM{"version":"1.1","math":"\(w_1,\dots,w_M\)"} corresponding weights. Like regression or many other machine learning problems, we do have a bias term too w0{"version":"1.1","math":"\(w_0\)"}.  A sum function will calculate a value, which later will be presented as the output y^{"version":"1.1","math":"\(\hat{y}\)"}.  Given input vector x=(x1,…,xM){"version":"1.1","math":"\({x} = (x_1,\dots,x_M)\)"} of M{"version":"1.1","math":"\(M\)"} dimensions and weight vector w=(w0,…,wM){"version":"1.1","math":"\({w} = (w_0,\dots,w_M)\)"}. The perceptron produces output of y^=sign[v(x,w)]{"version":"1.1","math":"\(\hat{y} = sign[v({x},{w})]\)"} where v(x,w){"version":"1.1","math":"\(v({x}, {w})\)"} is the linear combiner of: v(x,w)=∑i=1Mwixi+w0{"version":"1.1","math":"\(\begin{align} \\ v({x},{w}) = \sum_{i=1}^{M}w_ix_i+w_0\\ \\ \end{align}\)"} Also there is a better matrix notation, let x0=1{"version":"1.1","math":"\(x_0 = 1\)"} and x=(x1,…,xM){"version":"1.1","math":"\({x} = (x_1,\dots,x_M)\)"} then:  v(x,w)=wTx=xTwy^(x,w)=sign[wTx]{"version":"1.1","math":"\(\begin{align} \\ v({x},{w}) = {w}^T{x} = {x}^T{w}\\ \\ \hat{y}({x},{w}) = sign[{w}^T{x}]\\ \\ \end{align}\)"} In summary, a perceptron is a simple neural network used for binary classification. It has only one layer with a single node. Now lets visualize a 2−{"version":"1.1","math":"\(2-\)"}dimensional example. In the following figure we are explaining the problem that the preceptron tries to solve. Figure. Illustration of perceptron problem. Given weight w{"version":"1.1","math":"\(w\)"}, the perceptron linearly divides input space into two regions: All x{"version":"1.1","math":"\(x\)"}'s such that y^(x,w)=1{"version":"1.1","math":"\(\hat{y}({x},{w}) = 1\)"} or v(x,w)≥0{"version":"1.1","math":"\(v({x},{w}) \geq 0\)"}(the above region of the hyperplane line) All x{"version":"1.1","math":"\(x\)"}'s such thaty^(x,w)=−1{"version":"1.1","math":"\(\hat{y}({x},{w}) = -1\)"} or v(x,w)<0{"version":"1.1","math":"\(v({x},{w}) < 0 %\)"} (the below region of the hyperplane line) This corresponds to the two sides of the hyperplane defined by the equation: v(x,w)=∑i=1Mwixi+w0=0{"version":"1.1","math":"\(\begin{align} \\ v({x},{w}) = \sum_{i=1}^{M}w_ix_i+w_0 = 0\\ \\ \end{align}\)"} Note that |v(x,w)|{"version":"1.1","math":"\(\vert v({x},{w})\vert\)"} is proportional to the distance from x{"version":"1.1","math":"\(x\)"} to the hyperplane or how far a point is from the hyperplane line. If it is close to the boundary hyperplane (or in this case the line), we are probably less confident about the decision we are making. But if it is far enough from the line, we are more confident. We call the hyperplane H(w){"version":"1.1","math":"\(\mathcal{H}({w})\)"}, so we can define the distance of a point from the hyperplane as: dist(x,H(w))=|∑i=1Mwixi+w0|∑i=1Mwi2=|v(x,w)|∑i=1Mwi2{"version":"1.1","math":"\(\begin{align} \\ dist({x},\mathcal{H}({w})) & = \frac{|\sum_{i=1}^{M}w_ix_i+w_0|}{\sqrt{\sum_{i=1}^{M}w_i^2}} \\ \\ & = \frac{|v({x},{w})|}{\sqrt{\sum_{i=1}^{M}w_i^2}}\\ \\ \end{align} %\)"} Which is the perpendicular distance of the point to the line (see the figure below). Which is the perpendicular distance of the point to the line (see the figure below). Figure. Distance of a point x{"version":"1.1","math":"\(x\)"} to H(w){"version":"1.1","math":"\(\mathcal{H}({w})\)"} Thus the sign of v(x,w){"version":"1.1","math":"\(v({x},{w})\)"} indicates on which side of hyperplane H(w){"version":"1.1","math":"\(\mathcal{H}({w})\)"} is x{"version":"1.1","math":"\(x\)"}.  While the magnitude |v(x,w)|{"version":"1.1","math":"\(\vert v({x},{w})\vert\)"} indicates how far away x{"version":"1.1","math":"\(x\)"} is from H(x,w){"version":"1.1","math":"\(\mathcal{H}({x},{w})\)"}. Now, let us remind you the definition of linearly separable, if you have a look at the next figure (below), two sets C1{"version":"1.1","math":"\(C_1\)"} and C2{"version":"1.1","math":"\(C_2\)"} are called linearly separable if there exists a hyperplane H(x,w){"version":"1.1","math":"\(\mathcal{H}({x},{w})\)"}  that separates them. Figure. Linearly separable. Thus, in a perceptron we would like to find the weight vector w{"version":"1.1","math":"\(w\)"} so that the perceptron correctly classify 2{"version":"1.1","math":"\(2\)"} classes, given sample training data. Training data D={(xt,yt)},  t=1,…,n{"version":"1.1","math":"\(D = \{({x}_t,y_t)\},\ \ t=1,\dots,n\)"} wherext=(xt1,…,xtM){"version":"1.1","math":"\({x}_t = (x_{t1},\dots,x_{tM})\)"} is the input vector at time t{"version":"1.1","math":"\(t\)"} andyt=(+/−)1{"version":"1.1","math":"\(y_t = (+/-) 1\)"} is the desired output (see figure below). It appears to be a simple classification problem. For now we will assume that the data is linearly separable. Figure. An example of perceptron problem. Now, let’s see the perceptron algorithm for solving this problem. The steps of the algorithm are as follows: initialize  w=0{"version":"1.1","math":"\({w} = 0\)"} Retrieve next input xt{"version":"1.1","math":"\(x_t\)"}and desired output yt{"version":"1.1","math":"\(y_t\)"} Compute actual output y^t=sign[xt,w]{"version":"1.1","math":"\(\hat{y}_t = sign[{x}_t,{w}]\)"}  Compute output error e=yt−y^t{"version":"1.1","math":"\(e = y_t - \hat{y}_t\)"} Update weight, for all wi←wi+Δwi{"version":"1.1","math":"\(w_i \leftarrow w_i +\Delta w_i\)"}, with Δwi=ηetxti{"version":"1.1","math":"\(\Delta w_i = \eta e_t x_{ti}\)"}. Note that 0≤η≤1{"version":"1.1","math":"\(0 \leq \eta \leq 1\)"} is the learning rate. Repeat from step 2  until convergence It visits each data point in a loop and at each iteration it updates the w{"version":"1.1","math":"\(w\)"}.  But what if w{"version":"1.1","math":"\(w\)"} converges to some values. Then no update if y^t=yt{"version":"1.1","math":"\(\hat{y}_t = y_{t}\)"}, e.g., the current weight w{"version":"1.1","math":"\(w\)"} already correctly classify current sample x(t){"version":"1.1","math":"\({x}(t)\)"}. Once again let us remind you that if training instances are drawn from two linearly separate sets C1{"version":"1.1","math":"\(C_1\)"} andC2{"version":"1.1","math":"\(C_2\)"},  then the perceptron learning rule will converge after finite iterations. However, there is no guarantee for convergence if C1{"version":"1.1","math":"\(C_1\)"} and C2{"version":"1.1","math":"\(C_2\)"} are not linearly separable! Figure. Linearly separable. View transcript SPEAKER 1: In this tutorial we're going to see an example of learning perceptron. Perceptron is a linear classifier and it's also used in supervised learning. Perceptron is usually used to classify the data into two parts, therefore it's also known as linear binary classifier. Let's see the example. Consider the current weights as -1, 2, 1. So the hyperplane with these weights-- which we could come up with that initially-- is something like this, which is 2x1 plus x2 minus 1, which is based on these weights. Now a new point comes in, and it lies in here. And right now we need to update this line. So the first thing to do is finding the weight of x and w, which we put this point into this hyperplane, which is 2 times 1 over 2, plus 1 times 1 minus 1, which is equal to 1. Again, for finding the y-hat x and w, we're using the sine function, and the sine of 1 is 1. So this is what we approximated for this point, and this is the real value of the output for this point. So the difference of our approximation with the real value is -2, which is -1 minus 1, which equals to -2. Now based on this, we're going to update the weights. So wi equals wi minus 2, eta xi. If we let the eta to be 1, this formula yields the yi minus 2xi. So we should find each weight-- w0, wy, and w2-- based on this formula. So for w0 it's -1 minus 2. X0 is 1, so it will result in -3. w1 is 2 minus 2x1, and x1 is, as you can see, 1 over 2, so it's 1. w2 equals 1 minus 2x2, and x2 is 1, so it would result in -1. So here is our new hyperplane based on the new training point. So this was an example of learning a perceptron. As can see, by adding a new training point we are updating the hyperplane, and we are finding a new hyperplane. So we should keep doing this for every single point in our training sample so we can finally come up with a hyperplane or line. Activity Python Programming In this section, you will first look at how to implement the humble perceptron. We will use this to fit a linearly separable dataset. When the dataset is not linearly separable, this model fails, as we will see from our experiment. Perceptron and MLP in Python We then use some example code to construct a Multilayer Perceptron Network. We begin by importing the necessary libraries: Code example #1 import numpy as np import pandas as pd import matplotlib.pyplot as plt Visualization Helper (optional) We define a function that will help us with plotting a decision boundary. Please note that this will work only for 2D data. As noted above, this section is optional. Code example #2 # Helper function to plot a decision boundary. # If you don't fully understand this function don't worry, it just generates the contour plot below. def plot_decision_boundary(pred_func, X, y):     # Set min and max values and give it some padding     x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5     y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5     h = 0.01     # Generate a grid of points with distance h between them     xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))     # Predict the function value for the whole gid     Z = pred_func(np.c_[xx.ravel(), yy.ravel()])     Z = Z.reshape(xx.shape)     # Plot the contour and training examples     plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.5)     plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral, s=42) Let’s start by reading in the first set of data from the data folder as: “data1.csv”. We then print out the first few lines to see what the data looks like: Please download the data1.csv dataset, rename and store in a suitable location. Code example #3 If you increase the hidden layer size, you will notice the change in the decision boundary. What is an ideal value of number of hidden nodes for this data? When does the model start to overfit? Activity Make sure that you have experimented with all the individual Python coding examples that we have in this lesson. Feel free to share your feedback and experiences in the discussion forum. If you are having any technical issues with the Python coding examples, you may use the troubleshooting forum for assistance. SEE ALSO 