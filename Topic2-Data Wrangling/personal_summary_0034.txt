Nonlinear models (Neural Networks and Deep Learning)  1.  Main Points Covered this Topic  This topic was all about the nonlinear machine learning models: Neural Networks and Deep Learning. The following points were covered:  Artificial Neural Networks Motivation:  Linear models may not be sufficient for extremely complex problems  (decision boundaries are extremely nonlinear)  SVMs can construct nonlinear functions, but only with fixed  transformations (based on the kernel)  When it is unclear what kernel function should be used, and it is  preferable to learn these features from the data itself  System components:  o Input layer Hidden layer(s) Combiners Nonlinear activation functions Output layer  Complexity  Depends on number of layers and number of neurons in each layer Depends on how the layers are connected (i.e., dense, sparse)  Perceptron  Binary (classifier) that has only a single layer o  Inputs are fed into network and the weighted sum is calculated (based on weights associated with each of the inputs. This weighted sum is then fed into an activation function which produces the output  Uses a sign function as the activation function A multi-layer perceptron is called a neural network  Multi-layer perceptron:  For data that is not linearly-separable, a more complex architecture than  the perceptron is required (i.e., more layers are required)  Use a sigmoid (logistic) function as the activation function, which outputs a value between 0 and 1 with a s-shaped distribution:  Feedforward neural network:  ùúé(ùëß) = 1 1 +   ùëí‚àíùëß  Artificial Neural Network (ANN) where connections between units do  not form a cycle o Information moves only in the forward direction through the network A multi-layer feed-forward Neural Network is a Multi-layer Perceptron  (MLP)  The output of an MLP (with multiple output nodes) is a vector The aim of the network is to find weights such that the predicted values  are as close as possible to the actual values  This makes the MLP an optimisation problem, as the error (difference  between predicted and actual output) as small as possible  Stochastic gradient-descent is used to reduce the error  Back propagation:  The error calculated at the output layer (the difference between the actual and the predicted output) is fed back through the network  The error gradient is computed for each neuron by taking the derivative of the error with respect to the neuron‚Äôs output. The gradient indicates how much a change in the output affects the final output of the network  The weights of each neuron are updated from the final layer, working back through the network. Gradient-descent is typically used for this process  Deep Learning  Typically deeper and more complex than simple MLP and . Also includes architectures such as the Convolutional Neural Network, Autoencoders, Boltzmann Machines and Deep Neural Networks (amongst others)  Used in real-world tasks such as image and hand-written digit  recognition Convolutional Neural Networks  Modelled after the mammalian visual cortex (part of the brain where  visual input is processed)  Brains process images in layers of increasing complexity (i.e., primary layers may only interpret lines and curves, whereas later layers may recognize forms such as houses or animals) CNNs are made up of three basic concepts:  Sparse interactions ‚Äì sparse weights within a smaller kernel. The kernel refers to an operation applied across the entire image that performs a transformation  Parameter sharing ‚Äì the kernel uses the same set of weights  across the whole image  Translation invariance ‚Äì Images can rotate, translate, shear, etc,  and will still be recognizable  CNNs typically involve:  Convolutions ‚Äì applies kernels (filters) Activation (rectified linear unit) Pooling (reduces dimensions while retaining important features) Fully-connected layers ‚Äì responsible for making predictions based on the high-level abstract features learned by the convolutional layers Activation (softmax)  Autoencoder  A neural network that can handle many hidden layers in its structure Aim is to learn a representation for a set of data, typically for  dimensionality reduction  Widely used for learning generative models of data o  Input data is mapped to a lower-dimensional latent space, and then a decoder network attempts to reconstruct the original input from the representation  Goal is to minimize the reconstruction error Autoencoder is forced to engage in dimensionality reduction as the input data is compressed into representations in latent space  