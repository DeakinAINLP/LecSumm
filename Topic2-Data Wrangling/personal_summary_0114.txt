This topic mainly talks about neural networks and deep learning. At first, it talks about what problems neural networks are used to solve. To illustrate, it compares neural networks with our brains. It demonstrates what the neural networks by presenting a simple graph and how complex it can be as well. Then it gives us an illustration of perceptron which is a single-layer neural network for linear separation. After that, it illuminates why should we have multi-layer perceptron(MLP). Subsequently, it elaborates on the formulation of MLP and its practical purposes. Gradient-based optimisation methods are also mentioned since it can optimally find a minimum. After that, it demonstrates the backpropagation algorithm used to train MLPs via video. At last, it talks about the corresponding Python implementation of it. After finishing introducing MLP, it starts to introduce Deep learning, in which it mentions several deep learning architectures, but it focuses mainly on talking about convolutional networks (CNN). To begin with, it formulates the concept of CNNs, which is followed by talking about LeNet5. It then introduces in detail about the application of CNN. The mechanism of Autoencoder is also elaborated on. Finally, it illustrates the python implementation of deep learning. In this study, I gained much insight into the amazing effects of neural networks on non-linear classification problems. To help me understand relevant concepts of neural networks, I references provided videos and some books.  