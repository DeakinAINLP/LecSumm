Nonlinear models (neural networks and deep learning)  Motivation and inspiration  Our brain has highly parallel architecture and networks of interconnected neurones. The biological brain systems are the driving force behind the development of artificial neural networks (ANNs). Are neural networks required in all machine learning problems? We must first respond to the enquiry of what distinguishes neural networks.  When the underlying functions or decision boundaries are highly nonlinear, linear models might not be adequate. Although they use fixed feature transformations, which depend on the kernel function, vector machines can create nonlinear functions. For instance, if you choose a linear kernel, your model output will unavoidably be a linear model.  Neural system basics  The basic components of a neural network (machine) include an input layer, one or more hidden layers, combiners (sum functions), nonlinear activation functions, and an output layer. Pay close attention to key phrases like "input layer," "output layer," and "hidden layers."  Perceptron algorithm  One of the earliest algorithms created in the field of artificial intelligence is the Perceptron algorithm, a kind of linear classifier. In order to assess whether an input belongs to one class or another, a supervised learning algorithm is used. The method operates by receiving a single input, aggregating it (weighted total), and only returning 1 if the weighted sum is greater than a predetermined threshold. Otherwise, it returns 0. To distinguish it from a multilayer Perceptron, a more complex neural network, the Perceptron algorithm is also known as the single-layer Perceptron.  Multilayer Perceptron  Consider the AND and OR logical gates or functions. As you can see in the figure, we can show that both of these problems are linearly separable in 1 and 0 class labels:  A feedforward artificial neural network (ANN) called a multilayer perceptron (MLP) has many layers of nodes. It is a fully linked network, which means that each node connects to every other node in the layer below with a specific weight. A minimum of three layers of nodes make up an MLP: the input layer, the hidden layer, and the output layer. Every node is a neurone that employs a nonlinear activation function, with the exception of the input nodes. When MLPs just have one hidden layer, they are commonly referred to as "vanilla" neural networks.  MLPs differ from single-layer Perceptrons in that they can discriminate between data that is not linearly separable. Backpropagation, a supervised learning method based on the chain rule, is used to train them.  Backpropagation  Feedforward artificial neural networks or other parameterized networks with differentiable nodes can be trained using the backpropagation algorithm. It is also referred to as the reverse method of automatic differentiation and is an effective way to apply the chain rule to these networks. For a single input-output example, backpropagation efficiently calculates the gradient of a loss function with respect to the network weights, computing the gradient one layer at a time and iterating backwards from the last layer to prevent redundant computations of intermediate terms in the chain rule.  Deep Learning  Deep learning is a branch of machine learning that uses multiple-layered artificial neural networks to gradually extract higher-level features from unprocessed input data. The system's foundation is representation learning, which enables it to automatically find the representations required for feature identification or classification from raw data. Unsupervised, semi-supervised, or supervised deep learning are all possible.  Computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection, and board game programmes are just a few of the areas where deep learning has been used. It has achieved outcomes on par with, and in some cases even better than, those of human experts.  Convolutional Neural Networks  A common type of artificial neural network used to analyse visual imagery is the convolutional neural network (CNN). Convolutional neural networks (CNNs) replace general matrix multiplication in at least one of their layers. They are employed in image recognition and processing applications like image classification, picture segmentation, and object detection since they are especially made to process pixel data.  An input layer, hidden layers, and an output layer make up a CNN. One or more convolutional layers that carry out convolutions using a set of filters are included in the hidden layers. These filters are used to extract pertinent features from various input regions. These elements are merged and constructed into more complicated patterns as the network advances through the layers, enabling it to acquire increasingly abstract representations of the input.  Many different applications, such as computer vision, audio recognition, natural language processing, and even financial time series analysis, have had success using CNNs.    