Nonlinear models (neural networks and deep learning)  Model learning outcomes –  I certify that I have successfully learned and understood the following topics:  1.  Neural networks 2.  Perceptron and multilayer perceptron 3.  Deep learning  Summary and reflection –  The  pages  below  contain  the  handwritten  summary  referring  to  the  given  learning  resources.  It includes all the important points of the topic 10 module.  In this module, we learned about the motivation and inspiration behind the new trends of machine learning. Then we were introduced to neural systems and basics and how it gets connected with all of  this.  Then  we  familiarized  ourselves  with  the  perceptron  algorithm.  Then  we  learnt  about  the motivation for multilayer perceptron and about the multilayer perceptron itself. After we learnt the backpropagation  algorithm.  Then  we  were  introduced  to  deep  learning  and  convolutional  neural networks. Then we learnt how to apply CNN and autoencoder.  When  we  started  topic  10,  I  was  not  familiar  with  any  of  these  concepts  at  all.  So,  it  was  very interesting  and  exciting  to  learn  about  a  new  side  of  machine  learning  which affects every  and  all aspects of it. And the practical part done with Python was a little bit confusing at first but was able to understand  all  the  necessary  commands  and  ways  of  implementation  by  referring  to  both  given resources and online resources.  Activities of topic 10  Activity 10.3  1.  Continual  Learning  and  Lifelong  AI:  ANNs  are  likely  to  evolve  to  support  continual learning,  enabling  them  to  learn  and  adapt  over  time  without  forgetting  previously learned  knowledge.  Lifelong  AI  systems  aim  to  develop  models  that  can  accumulate knowledge and build upon previous experiences, allowing ANNs to learn from new data while retaining existing knowledge. This will be crucial for real-world applications where models need to continually learn and adapt to dynamic environments.  2.  Explainability and Interpretability: As ANNs become more complex and are deployed in critical  domains  such  as  healthcare,  finance,  and  autonomous  systems,  there  is  a growing demand for explainable and interpretable AI. Researchers are actively working on  developing  methods  to  understand  and  interpret  the  decision-making  processes  of ANNs.  Future  ANNs  are  expected  to  provide  more  transparent  explanations  for  their outputs, making them more trustworthy and accountable.  3.  Robustness and Adversarial Defense: ANNs are vulnerable to adversarial attacks, where carefully crafted inputs can lead to incorrect predictions or misbehavior. Enhancing the robustness of ANNs against such attacks is a critical area of research. Future ANNs may incorporate  mechanisms  to  detect  and  mitigate  adversarial  examples,  making  them more resilient to potential security threats.  4.  Integration of Multiple Modalities: ANNs have predominantly been applied to unimodal tasks  such  as  image  or  text  classification.  However,  future  ANNs  are  likely  to  integrate multiple  modalities  such  as  vision,  language,  and  audio  to  tackle  complex,  multimodal integration  will  enable  ANNs  to  have  a  more  comprehensive problems.  This understanding  of  the  data  and  perform  tasks  that  require  reasoning  across  different modalities.  5.  Hardware  Acceleration:  As  ANNs  become  more  computationally  intensive  and  require significant  processing  power,  there  will  be  a  continued  focus  on  developing  specialized for  neural  network  computations.  Hardware hardware  accelerators  optimized advancements  such  as  neuromorphic  chips  and  specialized  AI  processors  will  enable faster and more energy-efficient training and inference of ANNs.  It's important to note that the field of AI is rapidly evolving, and the future may hold further advancements  and  breakthroughs  that  we  cannot  currently  foresee.  These  insights  are based on existing trends and research up until September 2021.  Activity 10.5  The  motivation  for  using  a  multilayer  perceptron  is  to  leverage  its  ability  to  learn  complex nonlinear  relationships  in  data  by  incorporating  multiple  layers  of  neurons,  enabling  the model  to  capture  and  represent  more improve  predictive performance.  intricate  patterns  and  