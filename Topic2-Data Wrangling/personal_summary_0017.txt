Non Linear Models (Neural Networks & Deep Learning)  Ar#ﬁcial Neural Networks(ANNs) Two approaches:  1.  Study and Model the brain 2.  Use the brain as a founda?onal model and launching point but the result  will not necessarily aim to emulate the brain  What Is a Neural Network? It’s a technique for building a computer program that learns from data. It is based very loosely on how we think the human brain works. First, a collecHon of soIware “neurons” are created and connected together, allowing them to send messages to each other. Next, the network is asked to solve a problem, which it aNempts to do over and over, each Hme strengthening the connecHons that lead to success and diminishing those that lead to failure.  Mo#va#on: Neural networks are inspired by the structure and func?onality of biological brains, par?cularly the way neurons process and transmit informa?on. This mo?va?on highlights the importance of learning from nature and leveraging its principles to solve complex problems.  Structure: Neural networks consist of layers of interconnected nodes or ar?ﬁcial neurons. These neurons are organized into input, hidden, and output layers. Each neuron processes informa?on, applies an ac?va?on func?on, and transmits the result to the next layer. This hierarchical structure allows neural networks to learn and represent complex paIerns and rela?onships.  Learning process: Neural networks learn by adjus?ng the weights of connec?ons between neurons through a process called training. The training process involves using a labeled dataset and a learning algorithm, such as backpropaga?on, which minimizes the error between the network's predic?ons and the actual target values. This itera?ve process of weight adjustment enables the network to generalize and make accurate predic?ons on unseen data.  Applica#ons: Neural networks have a wide range of applica?ons, including image recogni?on, natural language processing, game playing, and recommenda?on systems. Their ability to learn from data and adapt to new situa?ons makes them a powerful tool for various domains.  Advantages: Neural networks can handle large amounts of data, tolerate noise, and adapt to changing condi?ons. They can also learn complex, non-linear rela?onships between inputs and outputs, which is crucial for solving many real- world problems.  Limita#ons: Neural networks can require signiﬁcant computa?onal resources and ?me for training, especially for large and complex models. They can be prone to overﬁNng if not properly regularized or if the training set is not representa?ve of the problem space. Addi?onally, the lack of interpretability can be a drawback in situa?ons where understanding the decision-making process is important.  Perceptron algorithm Perceptron is a linear classiﬁer (binary) and is a single layer neural network. A mulH-layer perceptron is called a neural network.  Neuroevolu#on of augmen#ng topologies (NEAT) i  MulHlayer Perceptron Ac#vity: Share  a single sentence that explains the mo#va#on for using mul,layer perceptron. The moHvaHon for using a mulHlayer perceptron is to create a ﬂexible and powerful neural network model capable of learning complex, non-linear relaHonships between inputs and outputs by stacking mulHple layers of interconnected arHﬁcial neurons.  Feedforward neural networks A feedforward neural network is an Ar3ﬁcial Neural Network (ANN) where connecHons between units do not form a cycle. In this network, the informaHon moves in only one direcHon, forward, from the input nodes, through the hidden nodes (if any) and to the output nodes. There are no cycles or loops in the network.  Backpropaga9on Algorithm -  used for eﬃciently compuHng gradients of the loss funcHon with respect to the weights and biases of a neural network, allowing the opHmizaHon of these parameters through gradient descent or related opHmizaHon methods during the training process.  Deep Learning Focuses on arHﬁcial neural networks with mulHple layers, also known as deep neural networks, which enable the automaHc extracHon of complex features and hierarchical representaHons from raw data, allowing the model to learn and perform tasks such as image and speech recogniHon, natural language processing, and decision-making with higher accuracy and eﬃciency compared to tradiHonal machine learning techniques.  Common Deep learning architectures are:  §  ConvoluHonal Networks §  Autoencoders §  Deep Belief Networks §  Boltzmann Machines §  Restricted Boltzmann Machines §  Deep Boltzmann Machines §  Deep Neural Networks  Convolu’onal Neural Networks - designed to process grid-like data, such as images, by incorporaHng convoluHonal layers that automaHcally and adapHvely learn spaHal hierarchies of features. CNNs consist of several layers, including convoluHonal, pooling, and fully connected layers, which enable the network to eﬃciently learn to recognize paNerns, textures, and objects in the input data while maintaining spaHal relaHonships and invariance to translaHon, scaling, and rotaHon.  CNNs are widely used in various applicaHons, such as image and video recogniHon, natural language processing, and even speech recogniHon.  LeNe5 The very ﬁrst CNN was introduced by Yann LeCun  The architecture can be summarized as follows:  Input layer: The input layer accepts grayscale images of size 32x32 pixels.    ConvoluHonal Layer (C1): The ﬁrst convoluHonal layer contains six 5x5 ﬁlters,  followed by a non-linear acHvaHon funcHon (typically the hyperbolic tangent or sigmoid).    Pooling Layer (S2): The ﬁrst pooling (subsampling) layer performs 2x2 average  pooling with a stride of 2, eﬀecHvely reducing the spaHal dimensions of the feature maps by half.    ConvoluHonal Layer (C3): The second convoluHonal layer contains 16 5x5 ﬁlters,  followed by a non-linear acHvaHon funcHon.    Pooling Layer (S4): The second pooling layer also performs 2x2 average pooling with  a stride of 2.    Fully Connected Layer (C5): The ﬁIh layer is a fully connected layer with 120 neurons, which connects to the ﬂaNened feature maps from the previous layer.   Fully Connected Layer (F6): The sixth layer is another fully connected layer with 84 neurons, followed by a non-linear acHvaHon funcHon.    Output layer: The ﬁnal layer is a fully connected layer with a number of neurons  equal to the number of classes in the classiﬁcaHon task (e.g., 10 for digit recogniHon).  Deep Learning Book - Chapter 9: ConvoluHonal Networks  Autoencoder An Autoencoder is a neural network which can handle many hidden layers in its structure. The aim of an Autoencoder is to learn a representaHon (encoding) for a set of data, typically for the purpose of dimensionality reduc3on. This type of neural network is trained to aNempt to copy its input to its output. Internally, it has a hidden layer  that describes a code used to represent the input. Recently, the Autoencoder concept has become more widely used for learning generaHve models of data.  