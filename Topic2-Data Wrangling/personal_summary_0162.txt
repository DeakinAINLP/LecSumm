Perceptron, Deep Learning, and their ties to neural networks were the primary topics this topic. A key idea in machine learning, the perceptron, was thoroughly explored. A collection of input features  and  accompanying  weights  are  used  to  train  a  straightforward  binary  classification algorithm to produce predictions. The Perceptron's main principle is to repeatedly change the weights until the model achieves the required classification accuracy.  The  introduction  of  Deep  Learning,  a  branch  of  machine  learning,  as  a  potent  method  for training  neural  networks  with  several  hidden  layers.  Neural  networks  can  learn  and  extract hierarchical data representations through deep learning, enabling them to tackle challenging patterns and tasks. The purpose of deep learning and its uses in a variety of fields, including image identification and natural language processing, were covered in detail. A neural network design  proposal  known  as the multi-layer perceptron (MLP) was  also  presented. MLPs  can recognise and understand complicated correlations in data because of their multi-layer structure of nodes (neurones) and linked weights.  The  subjects  covered  this  topic  provide  a  knowledge  of  the  Multi-layer  Perceptron,  the Perceptron algorithm, the concepts and goals of Deep Learning, and the importance of neural networks in general.  