This topic’s course content continued to cover non-linear models, specifically, neural networks and deep learning. Neural networks are a type of machine learning that takes its name from the brain, there are two main types of neural networks; neural networks that try and imitate the brain and neural networks that were originally based on the brain and are now focused on completing a specific task. A neural network is made up of the input layer, hidden layers, functions and output layer. The base unit of the a neural network is / was the perceptron. A perceptron is a discrete unit that takes multiple inputs, transforms them and provides an output. When multiple layers of perceptron’s are used to create an artificial neural network, known as a multilayer perceptron, the network can handle more complicated and abstract tasks. The values for the weights and activation functions used in the artificial neural network need to be update so the system can “learn” the tasks. Backpropagation is algorithm that determines the change to the weights.  Deep learning is a type of neural network that uses multiple hidden layers to perform complex tasks, and minimize the requirement of prior feature extraction by using more computational resources. There are many types of deep learning architectures such as Convolutional Neural networks, Autoencoders, Deep Belief Networks, Boltzmann Machines, and Restricted Boltzmann Machines. Convolutional Neural Networks are modeled after the visual cortex of mammals and frequently used for image processing tasks. We briefly touched on LeNet5 an specific implementation that uses convolutional, pooling, non- linearity and sparse connection matrices to reduce computational costs.  The last type of neural network architecture covered was the autoencoder. An Autoencoder is a model that encodes and decodes data using a neural network. Usually, the encoder and decoder are symmetrical / opposites. This setup has two interesting features, firstly the encoder transforms the data into less neurons than the input data, secondly by decoding this encoded information, if the output matches the input, we know that there was no data lost during conversion.  The unit site content also included examples of implementing Neural Networks and Deep Learning using Python.  