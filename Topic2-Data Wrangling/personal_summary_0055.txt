Inspired by the human brain, a neural network is a method in artificial intelligence that teaches computers to process data.  Deep learning uses interconnected nodes or neurons in a layered structure that resembles the human brain. It’s an adaptive system that learns from mistakes and continuously improves.  Complex neural networks are compatible with high dimensional inputs and multi-label classification.  Perceptron  A perceptron is a single-layer neural network. They consist of four main parts including input values, weights and bias, net sum and an activation function.  It operates by taking all the input values and multiplying them by their respective weights. These values are then added together to create a weighted sum. This weighted sum is then applied to the activation function, producing the perceptron's output.  As a simplified form of a single-layer neural network, perceptron’s play an important role in binary classification (it classifies data into two parts, hence binary).  Multilayer Perceptron  A perceptron is a single “neuron” that is a precursor to larger neural networks.  A row of neurons is called a “layer” – a network can have multiple layers.  Visible Input Layer: is the bottom layer that takes input from your dataset. These are not neurons as such but simply pass the input value through to the next layer.  Hidden layer: is below the input layer which is not directly exposed to the input. The simplest network structure is to have a single neuron in the hidden layer that directly outputs the value. Deep learning can refer to having many hidden layers in your neural network.  Output Layer: the final hidden layer is called the output layer which is responsible for outputting a value that corresponds to the format required for the problem.  Feed Forward Neural Network  This is a network in which nodes do not form loops – all information is passed in one forward direction from the input layer, through the hidden layer and finally to the output layer.  Backpropagation  Backpropagation is the method of fine-tuning the weights of a neural network based on the error rate obtained in the previous iteration. Proper tuning of these weights reduces error rates and makes the model reliable.  It’s a standard method for training artificial neural networks.    