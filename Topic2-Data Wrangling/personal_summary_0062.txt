 Motivation and inspiration  Our brain has a highly parallelized architecture with a network of interconnected neurons. The development of artificial neural networks (ANNs) is motivated by biological neural systems.  Do some machine learning problems require neural networks?  First, we need to answer the question of what makes neural networks different.  § §  If the underlying func0on or decision boundary is very nonlinear, the linear model may not be suﬃcient. Support vector machines can build nonlinear func’ons, but use ﬁxed feature  transforma0ons that rely on kernel func0ons. For example, if you are using a linear kernel, the model output will obviously be a linear model.  §  What if you don't know much about the kernel or want to learn these features from the data itself?  Neural networks allow you to learn  feature transforma0ons from your data.  Historical approach  In machine learning,  two  groups of ANN researchers are working on this problem.  § §  One group is using ANNs to study and model the brain. Another  group uses the brain as mo’va’on to design  ANNs as eﬀec0ve learning machines, but this may not be a true model of the brain.  This course follows the approach of the second group.  Neuron  There are billions of neurons in your brain. Estimates range from 50 billion to 500 billion. (Woodford, 2018)   Brain Func3ons  Shape. Neuron structuring  As we go through our day, our brains are spent on a variety of tasks. For example:  § § § § § §  15% is devoted to low-level visual tasks. 15% for image and ac’on recogni’on. 15% object detec0on and tracking. 15% for speech recogni’on and pronuncia’on. 10% reinforcement learning (orbitofrontal cortex and part of the medial prefrontal cortex). The rest perform various tasks.  Let's look at the physical distribution of tasks in the brain (below).   Shape. Brain structure. Source: (Shakirov 2016)  The brain takes a physical or mental stimulus as input, processes it, and produces output as needed. For example, let's say you see a dog. Your brain processes input from sight and hearing, and depending on past experiences, it creates desires such as stroking the dog, running away, etc.   Fundamentals of the nervous  system\  With the brain in mind,  let's introduce the key players in neural network systems.  § § § § §  A typical neural network (machine) has an input layer. There are one or more hidden layers. There is a combiner (sum func0on). It has a nonlinear ac0va0on func0on. There is an output layer.  Pay attention to important terms such as input layer, output layer, and hidden layer.    The following illustration   shows two examples of a simple neural network structure.  Shape.  Simple diagram of a neural network.  As you can see, there is always an input layer that is responsible for retrieving input features. In the example on the left, you can see that the input layer has three dimensions. The output layer has two dimensions. Only one of the sizes 4 is hidden later  .  The example on the right has three input dimensions,  two hidden layers of size  4, and  one single-dimensional output that is a binary value such as 0 or 1. There is another big neural network.  Miscellaneous  Shape. Diagram of a more complex neural network.  Neural networks are compatible with high-dimensional input and multi-label classification, allowing you to build more complex and large-scale neural networks. As you can see from the figure above, this diagram shows a complex neural network with three hidden layers,  one high-dimensional input layer, and a three-dimensional output layer  .  Note that if not enough training data is provided, using more complex neural networks can cause overfitting.       Perceptron algorithm    A perceptron is a linear classifier (binary) and a  single-layer neural network.  Multilayer perceptrons are called neural networks.    The following figure shows a simplified version of the perceptron.      Shape. IllustraDon of perceptron structure            Multilayer perceptron machine    Consider AND and OR logic gates or functions. As you can see from the figure, we can see that both of these problems are linearly separable as follows:  1 and 0 Class Labels:      Shape. Linearly separable problems.    You can easily find the lines you want to split based on the class label. But what about the XOR problem?   This problem is not linearly separable. As you can see in the following figure  (below),  it is impossible to separate  data points on a  single  line based on class labels.        Shape. XOR - Nonlinear QuesDons    This kind of problem  motivated us to develop new neural networks  , but this time there was a layer in the middle to handle these cases. Later, it was proved that multilayer perceptrons (MLPs)  can  represent XOR problems.    Shape.  MulDlayer perceptron represenDng XOR problem           Multilayer perceptron    Feedforward neural networks  Figure. (cid:0)(cid:0)(cid:0)(cid:0) funcDon or a (cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0) funcDon.  A feedforward neural network is an Artificial Neural Network  (ANN) where connections between units do not form a cycle. In this network, the information moves in only one direction, forward , from the input nodes, through the hidden nodes (if any) and to the output nodes. There are no cycles or loops in the network.  A multi-layer feed-forward Neural Network (NN) is also known as a Multi-layer Perceptron  (MLP). The term MLP is really an accurate name because the model comprises multiple layers of logistic regression like models (with continuous non- linearities) rather   than multiple perceptrons (with discontinuous non-linearities). Although this may not be a good choice, we will continue using the term MLP!  Notes on the MLP  Consider a two-layer network: input layer, hidden layer and output layer (see figure below).  Figure. Two-layer neural network.  There are some really important facts about this network you should consider:  § §  the output is a vector there are two kinds of weights here:  input → hidden o o  hidden → output §  (cid:0)(cid:0)(cid:0)ℎ from (cid:0)(cid:0)ℎ input → (cid:0)(cid:0)ℎ hidden §  (cid:0)(cid:0)(cid:0)(cid:0) from (cid:0)(cid:0)ℎ hidden → (cid:0)(cid:0)ℎ output § § §  another interes’ng feature is that it does not have to be fully connected.  the input layer does no computa’on - it only relays the input vector it can have more than one hidden layer  Though it looks to be a simple structure and mode, later we can see how powerful it is. The figure below shows one of the early applications of ANNs in image processing and self- driving cars! The output of this ANN, as you would expect, is the degree of steering in a particular direction.   Figure. Early stages of ANNs: Using ANN for computer vision applicaDons.  MLP Formula3on  Now we explore the formulations behind the MLP. Consider the ANN from you before.   Figure. Two-layer neural network.  Given input xi and desired output yi,  t=1,...,n the aim is to find the network weights w. so that the predicted values will be as close as possible to the real ones.  y^i≈yt  In other words, we would like to minimise the error which is the difference of the predicted value compared to the real true value of the output. We are stating the above as an optimisation problem: find w to minimise the error function:    Figure: An example of gradient-descent minimizaDon  In this case, we will use gradient-descent for minimisation. E(w) is not convex, rather it is a complex function with potentially many local minima. For solving this problem, we will use an algorithm called Backpropagation. Before we go through Backpropagation, let’s first remind you of the important concepts about Gradient-based Optimization  Detour: Gradient-based Op3miza3on  Gradient-based optimisation methods are operated with the search directions defined by the gradient of the function at the current point. Consider the following figure as a convex function.   Figure. Example of a convex funcDon.  At a point in 2D such asx=(x1,x2), the gradient vector of the function  f(x),  w.r.t x is:  ∇fx)=(∂f/∂t1,∂f∂x2)  ∇f(x) represents the direction that produces the steepest increase in f.  Similarly −∇f(x) is the direction of the steepest decrease in f. So to minimise a function such as f(x), we should use gradient-descent using the following steps:  1.  Ini’alise random x0 2.  Slide down the surface of (cid:0) in the direc’on of the steepest decrease:  xi+1=xt−n×∇f(xt)  Based on previous explanations on maximising the function f, you can use a similar method to maximise f(x) ie. use gradient-ascent as:  xi+1=xy+n×∇f(xt)   By finding the true direction towards the optimal point and the magnitude of the movement towards it, gradient-descent finds the optimal point. It is a very useful approach even in ANNs. The following figure illustrates an example of the gradient-descent method on the sample convex function.  Figure. How Gradient-Descent works from (cid:0)0 to minimum point (cid:0)∗  If we incorporate this idea in the error function we had before, we can minimise the error value between the true output and the predicted one in each iteration. Remember that we definedE (w) the error function, as:  Et(w)=1/2∑(ytk−yk)^2  Based on the gradient-descent, for minimising this function we need an update rule (where t denotes the current training sample) which is:     So instead of minimising E(w), the Stochastic Gradient-Descent (SGD) minimises the instantaneous approximation W (w) of  using only the t−th instance. SGD is cheap to perform and guaranteed to reach a local minimum in a stochastic sense.  Now that you have an understanding of gradient-descent, it is time to move to the Backpropagation algorithm.   Deep Learning Overview  Deep learning models are designed to continuously analyze data in a logical structure similar to how humans draw conclusions. To achieve this, deep learning uses a hierarchical structure of algorithms similar to ANNs.  The deep learning method is an advanced neural network. They have successfully learned many real-world tasks, such as handwritten number recognition and image recognition. Common deep learning architectures include:  § § § § § § §  Convolutional Network Autoencoder A network of deep beliefs Boltzmann Mashin Restricted Boltzmann Maschin Deep Boltzmammachin Deep Neural Networker  The following sections describe the basic concepts of one of  the most important deep learning architectures: convolutional networks (CNNs).   Convolutional neural networks  The architecture of convolutional neural networks (CNN or ConvNet) is  modeled after the mammalian visual cortex, the part of the brain where visual input is processed.  Within the visual cortex, certain neurons fire only if certain phenomena are in the field of view. For example, one neuron can only fire when looking at a diagonal line tilted to the left, while another can only fire when the horizon is in the field of view. Our brain processes images in layers of increasing complexity. The first layer distinguishes basic attributes such as straight lines and curves. At a higher level, the brain perceives the composition of edges and colors as, for example, a house or a bird.       Consider the diagram below. Focusing on the area of the image is the main attribute. As you can see from the diagram, this network does not appear to be fully connected (it does not use all pixels). It also deals with local areas that result in sparseness and locality.  Shape.  How CNNs work in diﬀerent regions.  CNNs consist of  three basic concepts:  §  §  §  Sparse interac,ons: sparse weights in smaller kernels (e.g. 3×3, 5×5) instead of the en0re input. This will help reduce the number of parameters.  The term kernel in   CNN generally refers to an operator applied to an en0re image to transform the informa0on encoded in a pixel (see ﬁgure above). )。 Parameter sharing:  The kernel uses the same set of weights when applied to diﬀerent loca0ons (sliding windows).  Transla,on immutability: Immutability means that an object can be recognized as an object, even if its appearance changes in some way. This is generally a good thing because it allows you to abstract the iden0ty or category of an object from the details of the visual input. For example, it recognizes an object even if the viewer/camera and the object are in a diﬀerent posi0on (see ﬁgure below).   LeNe5  Shape. TranslaDon immutability  The first CNN, called LeNe5, was introduced by  Yann LeCun.  The LeNet5 architecture was fundamental. In particular, it provides insight that image features are distributed throughout the image, and that convolution using learnable parameters is an effective way to extract similar features at multiple locations with fewer parameters. The following figure shows the structure of LeNet5.  Shape. LeNet5 structure.     Shape. General LeNet5 structure. Source: (O'Shea & Nash 2015)  In the diagram above, the CNN architecture consists of only five layers.  As O'Shea & Nash (2015) emphasizes, the basic functionality of the sample  CNN  above can be broken down as follows:  4  Important places:  1.  Like other forms of ANNs , the input layer holds the pixel values of the image. In the  previous ﬁgure, you can see a picture of the number 0CNN as input.  2.  The convolu’onal layer determines the output of neurons connected to the  local  region of the input through the calcula’on of the  scalar product between the weight of the neuron and the region connected to the input volume. A rec’ﬁed linear unit (commonly abbreviated as  ReLu)  uses a per-element ac’va’on func’on,  such as a sigmoid, on the output of ac’va’on produced by the previous layer to  LeNet5 It is intended to be introduced to .  3.  The pooling layer then simply performs downsampling along the spa’al dimension of the speciﬁed input, further reducing the number of parameters in its ac’va’on. 4.  The fully connected ’er performs the same role as a standard ANN  and aNempts to generate a class score from ac’va’on that is used for classiﬁca’on. ReLu may be used between these ’ers to improve performance. This simple transforma’on method allows CNNs  to transform the original input layer by layer using convolu’onal and downsampling techniques to generate class scores for classiﬁca’on and regression purposes.  In conclusion, the features of LeNet5 can be summarized as follows:  §  Convolu’onal neural network using a three-layer sequence  of convolu’on, pooling,  and nonlinearity  §  Use convolu’on to  extract spa’al features §  Subsample using spa’al averages from maps §  Nonlinearity  of the form h  or § §  To avoid high computa’onal costs, use a sparse connec’on matrix between layers.  MLP as essen’ally the ﬁnal classiﬁer  Overall, the network is the origin of many recent architectures and has been a real inspiration for many people in the field.   Applications of CNN  Let's look at some real-world examples.  One  of the CNNs applied is the CIFAR 10 dataset, which features 50,000 training images with  10,000 test images  .   Shape. CIFAR  10 dataset: 50,000 training images and 10,000  test images. Sauce (Karpathy, And)  In CNN, all network layers act as filters that detect  the presence of certain features or patterns in the original data.  The first layer of CNNs detects large features that are relatively easy to recognize and interpret. As you can see, the patch shown in red (shown below)  is found to interpret the image batch on the right. If you use images from other categories with this filter, you may not get the right results. In other words, each image filter patch is for finding a specific part of a pattern or texture.    Shape. Layers 1 and 2, Source (Olah nd)  The  same conceptual rule can be seen at layers 3, 4, and 5. Keep in mind that feeding these deep networks requires large data sets. Otherwise, the result may not be useful.  Shape. Layer 3, Source (Olah nd)  Shape. Layers 4 and 5, Source (Olah nd)  What helped deep learning develop this field:  §  §  Ability to model large models using new training techniques  :  o  Dropout, Max Out, Max Gnomes, ReLU, ...  ImageNet  data set at scale  o  1.2 million training sumpls    o  1000 categories  §  Using a High-Speed Graphical Processing  Unit (GPU)  o  1 trillion opera0ons per second!  These three elements are the most important solutions to many of the challenges that deep learning initially faced. These have made deep learning practical and useful.   Autoencoder    An autoencoder is a neural network that can handle many hidden layers in a structure .   The purpose of an autoencoder is to learn the representation  (encoding)  of a data set,    usually for dimensionality reduction purposes. This type of neural network is trained to try to copy inputs to outputs. Internally, it has a hidden layer z  to write code that is used to represent inputs. Recently, the concept of an autoencoder has become widely used for training models that generate data.        Shape. Simple conﬁguraDon of the autoencoder     If you have a look at the figure below, you can detect the layer ℎ3.    Figure. IllustraDon of Deep Autoencoder.  After the learning procedure, we can use this hidden layer of codes to reconstruct the original feature vector. However, this hidden layer which is an encoded version of inputs, is much smaller and more meaningful. So, rather than using the whole large feature vector (v), ℎ3 or the encoded hidden layer could be used.   