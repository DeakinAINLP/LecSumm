Neural system: The structure and operation of neural systems, which are the cornerstone of machine learning, are modelled after those of the human brain. They are made up of networked artificial neurones, which are also known as nodes or units and process and transmit  information.  A  hidden  layer  or  layers,  an  output  layer,  and  these  units  are arranged in layers. Each neurone takes in inputs, gives them weights, and then sends the weighted total through an activation function to create an output. Through a process known  as  training,  which  entails  presenting  input  data  and  contrasting  the  expected outputs with the desired outputs, neural systems learn by adjusting the weights.  Perceptron algorithm: A straightforward binary classification approach for supervised learning is the perceptron algorithm. It is based on the idea of a single perceptron, an artificial  neurone.  The  perceptron  generates  an  output  by  applying  an  activation function  to  several  input  features  multiplied  by  their  corresponding  weights.  The perceptron modifies its weights based on the discrepancy between the projected output and  the  actual  output  during  training.  The  algorithm  iterates  over  the  training  data repeatedly until it finds a set of weights that can accurately categorise the inputs.  Deep  Learning:  Deep  learning  is  a  branch  of  machine  learning  that  focuses  on developing  deep  neural  networks,  which  are  artificial  neural  networks  with  several layers. Due to its capacity to recognise intricate patterns and representations from vast volumes  of  data,  it  has  grown  in  popularity.  Deep  learning  techniques  gradually assemble numerous layers of coupled neurones to automatically uncover hierarchical representations.  Deep  neural  networks  may  learn  and  extract  increasingly  complex characteristics as the depth rises thanks to this method. Deep learning has excelled in a number of fields, including autonomous driving, audio and picture identification, and natural language processing.  Convolutional  Neural  Networks:  A  special  kind  of  deep  neural  network  called  a convolutional neural network (CNN) is made for processing structured grid-like data, such images and video. By employing specialised layers like convolutional layers and pooling layers, CNNs take use of the spatial relationship contained in the data. With the help of a set of learnable filters that convolutional layers apply to the input, the network can automatically recognise regional patterns and features.  The feature maps' spatial dimensions are downsampled using pooling layers but critical data is kept. CNNs have completely changed the way that tasks like image classification, object recognition, and picture segmentation are done, and they are now an essential part of computer vision systems.  Autoencoder: An technique for unsupervised learning called an autoencoder seeks to discover effective ways to represent or compress input data. It consists of an encoder network that converts the input data into a latent space or code, a lower-dimensional representation. The key components of the input are captured by this code. The original input is then reconstructed from the  code using a decoder network. The autoencoder learns to recognise significant patterns and decrease noise in the data by being trained to  minimise  the  difference  between  the  input  and  the  reconstructed  output. Dimensionality reduction, anomaly detection, and generative modelling are three areas where autoencoders are used.  4. Quiz      