a typical neural network consists of an input layer responsible for taking input features, one or many hidden layers, combiners (sum functions), nonlinear activation functions, and an output layer. The complex neural networks can be compatible with high-dimensional inputs and multi-label classification but may lead to overfitting if there is insufficient training data. In my honest opinion, I think ANNs will be adopted in multiple industries in the near future, eventually replacing a large scale of jobs as it will learn to perform tasks a lot more effectively than humans.  Perceptron algorithm  A perceptron is a simple type of neural network with one layer that can perform binary classification. It has input features, weights for each feature, a bias term, and a sum function to compute the output. The aim is to separate the input space into two regions by a hyperplane that depends on the weights. The perceptron algorithm starts with random weights and then adjusts them based on the input data and the desired output. The algorithm stops when the weights do not change for any input. The learning rate controls how much the weights change in each step.  As you know, we can always use a single line to classify data points. Share in the discussion forum, a single sentence that explains the motivation for using multilayer perceptron.  Multilayer perceptron is used to combat the flaws within a single layer perceptron, which are handling classification problems that aren’t linearly separable.  Multilayer perceptron  Multilayer perceptron works by using multiple perceptrons to solve a classification problem that is not linearly separable. It is designed to handle more complex classification problems which are non-linear. It uses a sigmoid function to allow the ANN to combine multiple inputs to handle much more complex problems. Information is directed in a single direction in which input data is taken, given a weight and computed through each perceptron, then outputted. Each layer contains logistic regression models which have no linearities, the weight formulation is given to limit the error of predicted and true output values.  Convolutional Neural Networks  The CNN design is based off of the neural network of a brain, inspired by the mammalian visual cortex, where visual information is processed in the brain. A CNN utilizes sparse interactions, parameter sharing as well as translation invariance. Sparse interactions are used to reduce parameter numbers. Parameter sharing lets the kernel use the same amount of weights while being applied to different spots. Translation invariance will allow for recognizing objects despite variations in appearance or relative positions. LeNet5 is the main CNN architecture and has 5 layers being the input, convolutional, rectified linear unit, pooling and fully-connected layers.  Autoencoder  Autoencoders are neural networks capable of handling multiple hidden layers, and they are trained to reconstruct their input data. The main objective is to learn a condensed and meaningful representation of the input through a hidden layer that serves as a code. By compressing the data into a compact code and then reconstructing it, autoencoders facilitate dimensionality reduction and the ability to ignore noise. The loss function measures the dissimilarity between the input and the output, and the goal is to minimize this error during training. Autoencoders are effective for feature learning due to their non- linear structure, allowing them to capture complex patterns. Deep autoencoders consist of multiple hidden layers, and the encoded hidden layer can be used to reconstruct the original data, providing a more concise and informative representation.  Provide summary of your reading list – external resources, websites, book chapters, code libraries, etc.  For particular module, I used a few different sources for the readings list. This included some research papers, YouTube videos and websites for information on the content of the module. For the code I used a few sites such as stack overflow, YouTube, module site and some things articles to explain how the code worked and provide some coding examples on how to write some of the code.  