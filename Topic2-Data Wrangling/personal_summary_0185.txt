Summarise the main points that were covered. Main points covered in topic 10 of the unit content:    Neural networks   Perceptron and multilayer perceptron   Deep learning  Reflection My reflection on the knowledge gained this topic from reading the unit contents for this topic with respect to machine learning.  This is a reflection and overview on the knowledge that I gained during topic 10 in regard to machine learning.  In topic 10 I was introduced to the topic of Neural Networks. Neural Networks were initially developed to create a learning system that was inspired by the biological brain’s neural systems. It is a supervised learning model, meaning that the model is trained on labelled training data samples. There are two groups of researchers in Machine Learning who are inspired by biological neural systems and each group has different approaches. The first group attempts to create a neural network that models the brain. Whereas the second system uses the brain as inspiration to design neural networks, however, the end result may not model the brain exactly.  The basic structure of a neural network comprises of an input layer, hidden layer/s, and output layer. A neural network design can be more or less complex, based on the amount of input layers, hidden layers, etc. Creating these bigger and more complex neural networks may suit multi-dimensional data inputs for example. Although when creating a highly complex neural network, there must be a lot of training data used, otherwise overfitting might become an issue.  I also learnt about Perceptron’s and Multilayer Perceptron’s. A Perceptron algorithm is a simple version of a neural network that is generally used for binary classification and linear regression. The perceptron takes one or more inputs with their weights and also a bias value. One example of implementing a simple perceptron algorithm is using it for linear classification, with a decision boundary separating the types of data so that the input data can be classified as one or the other (binary). A Multilayer Perceptron can be used when the data is not linearly separable. It has multiple hidden layers to allow for more complexity and flexibility so that it can then handle non-linear problems.  I gained knowledge on Deep Learning, a machine learning model that is based on the layer structure used in Neural Networks. The model is the advanced version of Neural Networks and contains three or more layers. Deep learning is the machine learning technique used in many modern AI applications such as image recognition, speech recognition, etc.  Convolutional Neural Networks (CNNs) were also discussed. In summary, CNNs are a Deep Learning Architecture that are commonly used for image analysis tasks, although it also has other applications within machine learning. The architecture contains three main layers, the Convolutional Layer, Pooling Layer, and the Fully-connected Layer. Similar to other Neural Networks, it also contains an input and output layer. In the example of image analysis, the input layer/s could take an image’s  