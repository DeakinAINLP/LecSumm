 Introduction to Topic 10  This topic we explore some fascinating related concepts:  neural networks perceptron and multilayer perceptron deep learning  1 1 1 1 3 5 8 11 16 16 16 17 20 20 20 21 22 22 22  10.2 Motivation and inspiration  Our brain has networks of inter-connected neurons and a highly-parallel architecture. Development of Artificial Neural Networks(ANNs) is motivated by biological neural systems.  Is there a necessity for neural networks in some machine learning problems? First we need to answer the question of what is different about Neural Networks?  ■ linear models may not be sufficient when the underlying functions or decision boundaries  are extremely nonlinear  ■ support vector machines can construct nonlinear functions but use fixed feature  transformations, which depends on the kernel function. For example, while you are using linear kernel, obviously your model output will be a linear model.  ■ What if you are not sure about the kernels or perhaps you prefer to learn these features from the data itself? Neural Networks allow the feature transformations to be learnt from data. Historical approaches  In machine learning, two groups of ANN researchers are working on this problem:  ■ one group uses ANN to study and model the brain ■ the other group uses the brain as the motivation to design ANNs as effective learning  machines, which might not result in a true model of the brain  In this course we will follow the second group’s approach.  Neurons  There are billions of neurons in your brain. Estimates range from 50 billion to 500 billion. (Woodford 2018)  Brain function  Figure. Neuron structure  The brain is occupied with various tasks as we go about our day. For example approximately:  ■ 15% devoted to low-level vision tasks; ■ 15% to image and action recognition; ■ 15% to objects detection and tracking; ■ 15% to speech recognition and pronunciation; ■ 10% to reinforcement learning (orbitofrontal cortex and part of medial prefrontal cortex); ■ Remaining perform miscellaneous tasks.  Let’s have a look at the physical distribution of tasks in the brain (below).  Figure. Structure of the brain. source:(Shakirov 2016)  The brain takes physical or mental stimuli as input, processes it and, if necessary, produces an output. For example, perhaps you see a dog. Your brain processes that visual and auditory input and, depending on your past experiences, produces a desire to pat the dog or run away etc.  10.3 Neural system basics  With the brain in mind, let’s introduce the major players in a neural network system:  ■ a typical neural network (machine) has an input layer; ■ it has one or many hidden layers; ■ it has combiners (sum functions); ■ it has nonlinear activation functions; ■ it has an output layer.  Carefully pay attention to the important terms such as input layer, output layer and hidden layers.  The following figure is shows two examples of simple neural network structures.  Figure. Simple diagram of neural networks.  As you can see, there is always an input layer which is responsible for taking the input features. In the example on the left we can see that the input layer has 3 dimensions. The output layer has 2 dimensions. It has only one hidden later with size of 4.  In the example on the right, we have another bigger neural network with 3 input dimensions, 2 hidden layers with size of 4 and one single dimension output which could be a binary value such as 0 or 1.  Complexity  Figure. Diagram of a more complex neural network.  We can have more complex, bigger neural networks because neural networks are compatible with high dimensional inputs and multi-label classification. As you can see in the figure above, the diagram shows a complex neural network with 3 hidden layers and one high dimensional input layer with a 3 dimensional output layer.  Remember having a more complex neural network can result in over-fitting if you are not providing enough training data.  Activity  The article Neural networks by Chris Woodford explains the similarities between the human brain and artificial neural networks. It's written for a broader audience, so is very easy to read.  After reading the article, share your insights about the future of ANNs in the discussion forum.  10.4 Perceptron algorithm  Perceptron is a linear classifier (binary) and is a single layer neural network. A multi-layer perceptron is called a neural network.  The following figure is a simple illustration of a perceptron.  Neuroevolution of augmenting topologies (NEAT) is one of the most interesting Neural-Network based methods. Check out the performance of a NEAT algorithm on one of the most popular games in the world!  10.5 Motivation for multilayer perceptron  Motivation for multilayer perceptron  Is it always possible to separate the data points based on their class label with a single line?  Consider the AND and OR logical gates or functions. As you can see in the figure, we can show that both of these problems are linearly separable in  1  and  0  class labels:  Figure. Linearly separable problems.  We can easily find a line to divide based on the class labels. But what about the XOR problem? This problem is not linearly separable. As you can see in the next figure (below), it is impossible to separate the data points based on their class labels with a single line.  Figure. XOR - Nonlinear problem  These kinds of problems were a motivation to develop a new neural network, but this time with a layer in the middle to handle these cases. Later it was proven that a multilayer perceptron (MLP) can represent the XOR problem.  Figure. Multilayer perceptron representing the XOR problem  10.6 Multilayer perceptron  Feedforward neural networks  A feedforward neural network is an Artificial Neural Network (ANN) where connections between units do not form a cycle. In this network, the information  moves in only one direction, forward, from the input nodes, through the hidden nodes (if any) and to the output nodes. There are no cycles or loops in the network.  A multi-layer feed-forward Neural Network (NN) is also known as a Multi-layer Perceptron (MLP). The term MLP is really an accurate name because the model comprises multiple layers of logistic regression like models (with continuous non-linearities) rather than multiple perceptrons (with discontinuous non-linearities). Although this may not be a good choice, we will continue using the term MLP!  Notes on the MLP  Consider a two-layer network: input layer, hidden layer and output layer (see figure below).  Figure. Two-layer neural network.  10.7 Backpropagation Algorithm  10.8 Python Programming  Refer to workbook  10.9 Introduction to Deep Learning  A deep learning model is designed to continually analyze data with a logic structure similar to how a human would draw conclusions. To achieve this, deep learning uses a layered structure of algorithms similar to ANNs.  Deep learning methods are advanced neural networks. They have been successful in learning many real world tasks (e.g. handwritten digit recognition, image recognition). Some of the common Deep learning architectures are:  10.10 Convolutional Neural Networks  The architecture of a Convolutional Neural Network (CNN or ConvNet) is modelled after the mammalian visual cortex, the part of the brain where visual input is processed.  Within the visual cortex, specific neurons fire only when particular phenomena are in the field of vision. For example, one neuron might fire only when you are looking at a left-sloping diagonal line and another only when a horizontal line is in view. Our brains process images in layers of increasing complexity. The first layer distinguishes basic attributes like lines and curves. At higher levels, the brain recognizes that a configuration of edges and colours is, for instance, a house or a bird.  Consider the figure below. Focusing on the regions of the image is the main attribute. As you can see in the figure, this network does not appear to be fully connected (it’s not going to use all the pixels) and is dealing with local regions which result in sparsity and locality.  Figure. How a CNN works on different regions.  CNNs are made of three basic concepts:  ■ Sparse interactions: Sparse weights within a smaller kernel (e.g., 3×3, 5×5) instead of  the whole input. This helps reduce the number of parameters. The term kernel in CNN generally refers to an operator applied to the entirety of the image such that it transforms the information encoded in the pixels (see the figure above).  ■ Parameter sharing: A kernel uses the same set of weights while applying to different  locations (sliding windows).  ■ Translation invariance: Invariance means that you can recognize an object as an  object, even when its appearance varies in some way. This is generally a good thing, because it allows abstraction of an object’s identity or category from the specifics of the visual input. For example it will recognise the object even with different relative positions of the viewer/camera and the object (see figure below).  LeNe5  Figure. Translation invariance  The very first CNN called LeNe5 was introduced by Yann LeCun.  The LeNet5 architecture was fundamental. In particular the insight that image features are distributed across the entire image and that convolutions with learnable parameters are an effective way to extract similar features at multiple locations with few parameters. The following figures illustrate the structure of LeNet5.  Figure. LeNet5 structure.  Figure. General LeNet5 structure. Source: (O’Shea & Nash 2015)  In the figure above the CNN architecture is comprised of just five layers. As O’Shea & Nash (2015) highlight, the basic functionality of the example CNN above can be divided into 4 key areas:  1. As found in other forms of ANN, the input layer will hold the pixel values of the image. In  the previous figure, you see a picture of a number 0 as an input to the CNN.  2. The convolutional layer will determine the output of neurons which are connected to local regions of the input through the calculation of the scalar product between their weights and the region connected to the input volume. The rectified linear unit (commonly shortened to ReLu) aims to introduce to LeNet5, an elementwise activation function such as sigmoid to the output of the activation produced by the previous layer. 3. The pooling layer will then simply perform downsampling along the spatial dimensionality  of the given input, further reducing the number of parameters within that activation. 4. The fully-connected layers will then perform the same duties found in standard ANNs and attempt to produce class scores from the activations, to be used for classification. ReLu may be used between these layers to improve performance. Through this simple method of transformation, CNNs are able to transform the original input layer-by-layer using convolutional and downsampling techniques to produce class scores for classification and regression purposes.  To conclude, LeNet5 features can be summarized as:  10.12 Autoencoder  An Autoencoder is a neural network which can handle many hidden layers in its structure.  The aim of an Autoencoder is to learn a representation (encoding) for a set of data, typically for the purpose of dimensionality reduction.  This type of neural network is trained to attempt to copy its input to its output. Internally, it has a hidden layer that describes a code used to represent the input. Recently, the Autoencoder concept has become more widely used for learning generative models of data.  