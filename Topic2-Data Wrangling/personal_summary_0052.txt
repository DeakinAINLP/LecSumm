 Neural Systems  The development of artificial neural networks are inspired by biological neural systems. “Our brain has networks of interconnected neurons and highly-parallel architecture.”  What is different about neural networks?  -  Linear models are sometimes insufficient when the underlying function or decision boundary is  -  extremely nonlinear SVMs can construct nonlinear functions but use fixed feature transformations, which depend on the kernel function. (Eg. While you’re using a linear kernel, your model output will also be linear.) -  Rather than picking the kernel, neural nets can determine this feature themselves as they allow  feature transformations to be learnt from the data itself.  One line of research into ANNs uses them to study the brain. The other uses the brain as the motivation in designing effective machine learning models based on ANNs.  The human brain is occupied by various tasks throughout the day:  -  Approximately 15% devoted to low-level vision tasks -  Approximately 15% to image and action recognition -  Approximately 15% to objects detection and tracking -  Approximately 15% to speech recognition and pronunciation -  Approximately 10% to reinforcement learning (orbitofrontal cortex and part of medial prefrontal  cortex)  -  Remaining perform miscellaneous tasks.  “The brain takes physical or mental stimuli as input, processes it and, if necessary, produces an output. For example, perhaps you see a dog. Your brain processes that visual and auditory input and, depending on your past experiences, produces a desire to pat the dog or run away etc.”    A typical neural network has an input layer, one or more hidden layers, combiners (sum functions), nonlinear activation functions and an output layer. Two example neural networks in the image below.  The input layer, hidden layers and output layer can all be different in dimensionality. Neural networks are compatible with high dimensional data, as neural networks can be very complex. However, like other ML models, increased complexity comes with a risk of overfitting if there’s not enough training data.  Perceptron Algorithm  The perceptron algorithm is a linear classifier which is comprised of a single-layer neural network. It is used for binary classification. A multi-layer perceptron is known as a neural network.  Multilayer perceptrons are needed so we can separate the data points nonlinearly. When a problem is not linearly separable the single layer perceptron algorithm cannot model the decision boundary. This is the reason why multiple layers are required in neural networks. In a multilayer perceptron the output is binary but there’s an activation function which allows the network to combine inputs in a more complex way. In turn, this provides a richer capability in the functions they can model.  Feedforward Neural Networks  A feedforward neural network is one where data can only move in one direction through the layers, as the connections between units don’t form a cycle.  