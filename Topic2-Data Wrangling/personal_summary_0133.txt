 Perceptron algorithm  The perceptron algorithm is a type of linear classifier based on a linear predictor function that combines a set of weights with the feature vector. These weights are learned by the algorithm by iteratively processing the training set and adjusting based on prediction errors.  Multilayer Perceptron (“MLP”)  MLP is a class of feedforward artificial neural network that includes one or more hidden layers of neurons between the input and output layer. These neurons use a non-linear activation function enabling complex and non-linear relationships to be modelled between the input and output data.  Backpropagation  The weights of MLP are generally learned using backpropagation, along with gradient descent. As the name suggests, this algorithm propagates the output error backwards through the network. The gradient of the loss function is calculated with respect to the input-output pair. This is then used in a gradient descent optimisation method to adjust the weights and minimise the loss function.  Deep Learning  Deep learning models are designed to continually analyse data using a structure that is similiar to how humans draw conclusions. There are various types of deep learning architectures, which include:    Convolutional Neural Networks (“CNN”) – This type of model is structured with layers of convolutional nodes which apply a filter to the input data. These layers identify local patterns within the data, and deeper layers in the network can recognise more complex features.    Autoencoders – This model aims to ignore noise and extract the most important features of the input data. It achieves this by compressing the input data into a hidden representations and then uses a decoder to reconstruct the input from this representation. This type of model is often used for dimensionality reduction.  