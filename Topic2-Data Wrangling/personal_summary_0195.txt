Neural Networks and Deep Learning  Neural Networks  Artificial Neural networks are the computational modelling of a human brain. Our brains are made up of billions of neurons (estimates are between 50 and 500 billion) which take input from external stimuli and create output to create decisions. Artificial Neural Networks use multiple decision nodes which are interconnected with each other and pass the input across it’s layers until it reaches a decision and passes to the output. There are three layers in a neural network, an input layer, a hidden layer and an output layer. The input layer takes input from external data and passes to the hidden layer. The hidden layer can be made up of a single layer of connected nodes, or multiple layers. These nodes make decisions on piece of the data and pass to the next layer of connected nodes within the hidden layer until it pass to the output layer. The output layer then passes on this output.  The Perceptron Algorithm is a single layer Neural Network which acts as a linear classifier. This model is only useful for linearly separable data. For more complicated problems, such as XOR problems, a multi-layer approachis required. Feed-forward networks are neural networks in which the data is only passed forward from one layer to the next, with no loopbacks. A multi-layer feed-forward Neural Network (NN) is also known as a Multi-layer Perceptron (MLP).  We can use a method called the back-propagation method to train these MLPs.  Deep Learning  Deep Learning models use a layered structure similar to neural networks to continuously analyze data and draw conclusions in a similar manner to how humans do. Deep learning methods have been successfully used in the real world to solve problems such as handwriting recognition and image recognition.  The Convolutional Neural Networks (CNN) are modelled off the mammalian visual cortex, which is the part of the brain which processes visual input. In this model, different neurons have different ‘fields of vision’, which will fire when specific parts of an image are recognised. There are three main concepts with the CNN models:  Sparse Interations where having the neurons look for specific criteria within a specific subset of the overall data reduces the amount of parameters.  Parameter Sharing where the same set of weights are applied to different parts of the data as it comes into view (known as sliding window).  Translation Invariance meaning the model can recognise an object as an object even as it may vary across different objects of the same classification.         