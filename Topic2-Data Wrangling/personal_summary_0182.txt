Introduction  This topic we continued our coverage of non-linear models, focusing on neural networks and deep learning.  Artificial neural networks  The approaches that we’ve followed so far in this course have largely been rule based, and as such they can struggle with tasks that are either complex or ambiguous. For example, speech recognition.  Neural networks were created by researchers in the field of Artificial Intelligence who wanted to mimic the functioning of the human brain. In so doing they hoped that they would be able to create machines that could perform some of the tasks that traditionally require human intelligence, and also overcome some of the limitations of the rule based approaches.  A neuron is a cell within our nervous system that communicates with other neurons. It passes information on to other cells and is the fundamental working unit of our brains (‘The Neuron’ n.d.).The human brain has billions of these neurons.  The brain takes stimuli from various sources as input, processes it, and if necessary, creates a response. Neurons play a large role in this processing.  The human brain has well defined zones, with each zone dedicated to particular task. It is a testament to the plasticity of the human brain that should one part of a brain be damaged, it can often reorganise its working to overcome the damage.  Despite human attempts to model neurons using software, the human brain is still significantly more complex.  Neural network basics  The neural networks based on the structure of the human brain normally have the following structure:  1. Input layer: The layer that receives in the initial data or features that are being fed into the network. Each input neuron will correspond to a specific attribute or feature of the input data.  2. Hidden layers: One or more layers between the input and the output layers. They are  termed “hidden” as their activities are not directly observed. Each hidden layer consists of one or more neurons, with the neurons in one layer being connected to the neurons in adjacent layers.  3. Output layer: The output layer is responsible for outputting (presenting) the the prediction of the neural network. The number of neurons in the output layer can depend on the task that the network is designed to perform.  The structure and layers in a neural network is dependent on the problem and the desired performance. Different architectures have been developed to deal with different tasks.  One disadvantage of neural networks is that they can be difficult to audit.  The perceptron algorithm  The perceptron classifier is a linear algorithm for binary classification tasks. It was one of the first artificial neural network learning algorithms, being proposed and demonstrated by Frank Rosenblatt in 1958, when he showed it learning to sort punch cards (Lefkowitz 2019).  Rosenblatt's article, “The Design of an Intelligent Automaton,” in Research Trends, a Cornell Aeronautical Laboratory publication, Summer 1958  The perceptron is a single layer neural network that makes predictions, classifying its input into one of two possible categories. If it finds it is making wrong predictions, it adjusts its output so that it will make better predictions. As it iterates it becomes increasingly accurate. As it was originally intended to be an image recognition machine, the name was derived from the word “perception”.  The perceptron introduced both the concept of assigning numerical weights to the inputs, and a mechanism for learning those weights. The output is only set (fires) when the weighted sum of the inputs is greater than a set threshold (theta). However, instead of setting a fixed value for theta, it is  accepted as one of the inputs to the perceptron. This allows theta to become a changing learnt value, rather than a static threshold.  As an rough example:  x0 = theta  x1 = isRugbyOnTV x2 = areTheHurricanesPlaying x3 = isItAFriendly  w0, w1, w2, w3 = weights applied to inputs  y = will the viewer turn the TV on?  A rugby mad person would definitely turn the TV on [theta = 0]. However, I, Martin, being a more demanding viewer, will only turn the TV on if the Hurricanes are playing and the match is not a friendly one [theta = 2]. The output will depend on the inputs and their weights. And their values can be set by the viewers prior viewing history.  The multilayer perceptron  Motivation  Marvin Minsky, a colleague of Frank Rosenblatt, was sceptical of the perceptron, arguing that it was too simple to support Frank Rosenblatt's vision of computers that could both hear and listen (Goled 2022). He used as his central proof the fact that the perceptron couldn’t perform the ‘exclusive-or’ (XOR) function.  The solution to the complaint was to come many years later (1986), when a researcher by the name of Geoffrey Hinton built a complex network of artificial neurons, complete with a hidden layer, and showed that this architecture could perform the XOR function (Rumelhart, Hinton & Williams 1986).  Architecture  As discussed in the motivation for a multilayer perceptron, the multilayer perceptron will have an input layer, one or more ‘hidden’ layers, and an output layer.  Multilayer perceptron. Image by (Bento 2021)  The inputs are combined with the initial weights. From there each layer will feed its output into the next layer until the output layer is reached. This is, in essence, a feedforward system.  Backpropagation  But how does learning occur in a multi-layer perceptron? The mechanism that allows learning is called backpropagation. When this is done, the weights are iteratively adjusted, according to the result obtained, with end goal being the minimisation of the cost function.  Multilayer perceptron, showing backpropagation. Image by (Bento 2021)  In Python  The lecture notes claim that the scikit-learn library does not have support for a Multi-Layer Perceptron Classifier (MLPClassifier) in the stable release (Pedregosa et al. 2011). However, the lecture notes are outdated: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html shows that the sklearn.neural_network.MLPClassifier is available in scikit-learn version 1.2.2.  Deep learning  The multi-layer perceptron architecture has been used as the basis for other, more complex architectures. These newer architectures tend have a larger number of hidden layers, different patterns of neuron connectivity. This increase in complexity gives these advanced models better performance when it comes to capturing and modelling relationships in data.  Deep learning differs from machine learning in that machine learning leverages labelled structured data to make predictions. Deep learning machines can ingest and work with unstructured data and automatically manage the feature extraction.  The specialised deep learning architectures can be tailored for specific types of data and tasks.  The downside is that these more complex architectures require more computational resources than the basic multi-layer perceptron architecture.  Convolutional neural networks  A convolutional neural network (CNN) is a deep learning architecture that excels at image recognition. They are based on the workings of the visual cortex's of mammals. In both cases, certain neurons will only fire when a specific observable feature is in the field of vision. By example, one set of neurons may fire when a rectangle is viewed. Another, different set of neurons may fire when a circle is in view. A further level may recognise that the combination of these shapes forms a post box shape.  The three most common hidden layers in a CNN are:  1. Convolution layers that activates on certain features on the input image. These are the most  import feature of a CNN.  2. Activation layers, that applies a non-linear function to the weighted output of the  convolution layers. This enables the CNN to learn about more complex relationships in the input image.  3. Pooling layers that simplify the output by performing a non-linear down sampling, thus  reducing the number of features that the CNN needs to learn.  A feature of CNN’s is that the weights and biases values are the same across all neurons in a given layer.  After the learning feature layers, classification layers will be found. These layers provide the final classification output.  CNN’s can be trained from scratch. This requires time, and lots of images. Alternately transfer learning can be used. Here a model with prior training is fine tuned for the new classification task.  CNN’s are used in various domains. For example:  image classification: they can accurately label and classify images;  object detection: they can detect and identify objects in images or videos;  facial recognition: a specialisation of object detection, in which peoples faces can be recognised and identified;  video analysis: meaningful information can be extracted from video streams and used for tasks such as captioning, segmentation and action recognition;   medical image analysis; a specialisation of image classification, in which diagnoses can be  made from patient images;    natural language processing; although associated primarily with images, CNN’s can also be used for text classification, sentiment analysis, text generation etc…  Autoencoder  An autoencoder is a neural network that takes its input, encodes (compresses) it, then decodes it and presents this as output, hopefully with the output as close to the original input as possible. Some of the uses of this are:  1. dimensionality reduction – through the creation of a compressed representation of the  input, irrelevant or redundant features are discarded. This means that storage requirements or transmission bandwidth can be reduced;  2. noise removal – by being able reconstruct clean outputs from noisy data, an autoencoder  can be used to clean the data and restore an original signal;  3.  feature extraction – the compressed representation can be used as input to other tasks, such as classification or clustering. This will reduce the computational requirements of the downstream tasks;  4. anomaly detection – if the autoencoder is trained on a dataset with normal instances, it will  be able to reconstruct the majority of the instances correctly. Hence when a new or unfamiliar instance is fed into it, the reconstruction error will be high, signalling the presence of an anomaly.  Autoencoders give us a flexible tool for unsupervised learning, data compression, feature extraction, and generative modelling, making them both powerful and applicable in various domains and tasks.  Google have created a Python library that allows us to build our own deep learning solutions. The name of the library is ‘TensorFlow’. It can be installed via pip or Docker. Note, however, that the instructions may differ dependent on what CPU architecture and operating system are being used. The Google instructions on installing TensorFlow can be found here: https://www.tensorflow.org/install.  