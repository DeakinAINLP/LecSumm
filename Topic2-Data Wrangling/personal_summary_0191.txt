 Deep learning's foundational ideas are taught in Topic 10. Deep learning has acquired notoriety for its outstanding performance in fields including speech recognition, picture recognition, and natural language processing. Large data sets accessibility and improvements in computer power have been major factors in the development of deep learning.  It explains the fundamentals of brain networks and how linked neurones process and transfer information. The perceptron technique, a fundamental building block of neural networks, is then investigated. It enables binary classification by modifying weights and biases based on training data. The rationale for adopting multilayer perceptrons (MLPs) is explained, highlighting how well they can perform challenging tasks because of the numerous linked layers of neurones they include.  To train MLPs by propagating errors backwards and adjusting weights correspondingly, the backpropagation method is introduced. Python programming is explored, including key resources for putting deep learning algorithms into practice and conducting experiments with them. Convolutional Neural Networks (CNNs) are described as specialized architectures for processing grid-like input, notably images, and their uses in numerous fields are investigated.  