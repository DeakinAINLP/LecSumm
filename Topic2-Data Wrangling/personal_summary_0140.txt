The main topics that were covered during topic 10 included introduction to neural networks, perceptron (including multilayer perceptron) and Deep learning. On the programming side, I covered the implementation of MLP and perceptron using python.  The main source of reference was unit site contents for topic 10 along with the external videos and article links provided.  The topic’s topic began with the basic understanding of Neural networks, with the concept being explained with emphasis to neurons and brain function. Other associated topics included the complexity of neural networks. Next, I gained an understanding of linear classifier by using perceptron algorithm as an example. I also learnt about multilayer perceptron which is a perceptron that comprises multiple layers of logistic regression. The next topic was about backpropagation algorithm, which is used for training MLP’s. We also covered the introduction to deep learning model which is aimed at continually analysing data with a logistic structure similar to how human brain makes conclusions. Then, I explored the topic of Convolutional neural networks(CNN) and its three pillars namely sparse interactions, parameter sharing and translation invariance. In the final phase of the topics learning journey, I learnt various applications of CNN, the concept of out of bag error and Autoencoder. The autoencoder is a neural network which can handle many hidden layers in its structure. The implementation of MLP and perceptron using python programming marked the end of the unit’s topics.  