 This topic we touched base on the foundations of machine learning, how we can use it, the different types and how these are evaluated. Machine learning is a type of artificial intelligence that helps computer systems to learn  automatically  from  data  and  improve  their  performance  on  a  specific  task  over  time.  It  does  this  by teaching computers to learn from examples or experience rather than relying on explicit instructions. Machine learning algorithms are helpful in various applications, such as speech and image recognition, natural language processing, recommendation systems, fraud detection, and more. Machine learning involves learning the basics of algorithms, how to train models, evaluate their performance, and select the appropriate model for a given task. It also involves learning how to preprocess data and handle missing values, outliers, and other issues that can impact the accuracy of models. We also had a little exposure to Python and completed some tasks. Below are some activities I found on the Unit site content.   How much programming have you done? If you an experienced coder, share any tips for getting started that you found helpful. Why it was helpful. Share your experience with your fellow students. I haven't done much programming. However, I completed what was needed to pass the units with a better grade than Pass. I know the foundations, but apart from my studies, I do not practice them a lot in a work environment.   How would you define machine learning? Do a bit more reading and come up with your own definition. Machine  learning  is  a  field  within  artificial  intelligence  where  mathematical  models  and  algorithms  are constructed  to  allow  computers  to  learn  from  data  without  being  programmed  directly.  Instead,  machine learning aims to enable computers to enhance their performance on a particular task as they gather insights and patterns  from  data.  This  involves  teaching  a  computer  system  to  identify  and  understand  patterns  and relationships in data using adaptable algorithms that can improve their accuracy as more data is introduced. As a result, machines can perform tasks that would typically necessitate human intelligence, including tasks such as image recognition, natural language processing, and decision-making based on intricate data sets.   What do you think of these examples? Find another problem or application where machine learning could be used. Another real-world example of machine learning that includes supervised learning is the use of facial recognition technology in security systems. The system is trained using a dataset of labelled images of faces, with each image labelled with the person's name displayed. The system then uses this information to distinguish and identify individuals whose faces are taken in real-time by cameras. The system's exposure to more data improves its ability  to  recognise  faces  reliably  and  can  be  utilised  for  various  applications  such  as  employee  attendance, access control, and law enforcement. Amazon's Rekognition service, for example, provides facial recognition APIs for developers to employ in their apps.   Do some research and provide a real-life example of machine learning that uses supervised learning. One example of real-life machine learning is recommendation systems used by online shopping websites like Amazon, which uses machine learning algorithms to suggest products to customers based on their past purchase   Harry Magoulias â€“ Topic 1 summary and activities  history, browsing behaviour, and other factors like ratings and reviews. (How Amazon uses machine learning?, 2022)  These  recommendations  are  personalised  and  tailored  to  each  individual's  preferences,  resulting  in  a more engaging and satisfying shopping experience for customers. The use of facial recognition technology in security systems is one real-world example of machine learning that includes supervised learning. The system is trained using a dataset of labelled images of faces, with each image labelled with the person's name displayed. The system then uses this information to distinguish and identify individuals whose faces are taken in real-time by  cameras.  The  system's  exposure  to  more  data  improves  its  ability  to  recognise  faces  reliably  and  can  be utilised for various applications such as employee attendance, access control, and law enforcement. Amazon's Rekognition service, for example, provides facial recognition APIs for developers to employ in their apps (Upstill, 2018).   Do  some  research  and  provide  a  real-life  example  from  machine  learning  that  uses  unsupervised learning. Justify why it classifies as unsupervised learning and not supervised learning. The Google News algorithm is an example of machine learning that utilises unsupervised learning to cluster and categorise  news  articles  based  on  their  content.  The  algorithm  examines  each  article's  language,  topic,  and content to identify similarities and group them accordingly, allowing users to access related news articles on a given topic (Upstill, 2018). This approach is unsupervised because the algorithm does not rely on labelled data or specific instructions on grouping articles; instead, it discerns patterns and similarities in the data to make decisions. The algorithm learns independently from the data without direct feedback or guidance, meaning there is no predetermined outcome or 'right' grouping of articles to learn from. The algorithm can operate without needing labelled data by creating its own clusters based on the similarities it identifies. This distinguishes it from supervised  learning,  where  labelled  data  and  specific  instructions  are  provided  to  make  predictions  or classifications.   Perform  your  own  exploration  of  model  evaluation  and  try  to  understand  the  differences  between training, validation and test datasets. Training, validation, and test datasets are critical components in building machine learning models. Each of these datasets has a specific role to play in the model development process and serves a different purpose (Brownlee, 2017).   Training dataset: The training dataset is the initial data set used to train the machine learning model. It is the data on which the model is built and optimised to make accurate predictions. The training dataset contains  labelled  data,  meaning  the  input  data  is  already  associated  with  the  expected  output  or outcome. The machine learning model uses this data to learn the patterns and relationships in the data and create a predictive model (Brownlee, 2017).    Validation dataset: The validation dataset is used to fine-tune the machine learning model and ensure it is not overfitting or underfitting. Overfitting occurs when the model is too complex and performs well on the training data but poorly on new, unseen data. Underfitting occurs when the model is too simple and  does  not  capture  the  complexity  of  the  data.  The  validation  dataset  is  typically  a subset  of  the training dataset and is used to evaluate the model's performance during training. In addition, it helps to optimise the model's hyperparameters to improve its accuracy (Brownlee, 2017). Test dataset: The test dataset is used to evaluate the performance of the final machine learning model. It is an entirely new data set that the model has not seen before and contains no labelled data. The purpose of the test dataset is to simulate real-world scenarios where the model must make predictions on unseen data. By evaluating the model's performance on the test dataset, we can determine how well it generalises to new, unseen data and estimate its accuracy in real-world situations (Brownlee, 2017).  