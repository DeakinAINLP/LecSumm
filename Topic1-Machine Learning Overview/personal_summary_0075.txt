 This topic’s content was focussed on introductions to various concepts revolving around  machine learning, some fundamental linear algebra basics, and Python.  In terms of theoretical concepts, one of the first topics was on what machine learning is and  what it does. Overall, it essentially involves the collection and processing of data so that relationships and  patterns within the data can be discovered for some kind of desired output. It is also worth mentioning  that the model that is created isn’t static and will act dynamically and update depending on the data it is  provided (essentially, the data provides the model with new/different “experiences” so that it can learn  from it and improve). Some important steps to note in this entire process is collecting data, followed by  cleaning and preparation. Once this is done, we can then start to train a model which then needs to be  evaluated through the use of testing data (dataset would have been divided to a training and testing data  set prior to training). Once the model has been determined to be good, we can then deploy the model.  Some information was also provided regarding supervised and unsupervised learning. Essentially,  in supervised learning, we have data that has been labelled with pre-existing information and we can  perform classification and regression. For example, we can train a model that can classify cats and dogs  by providing labelled images. If we were to provide that model after training with an image of a cat or  dog, it should be able to tell us what classification this image would belong to. Unsupervised learning on  the other hand is not labelled and we can perform clustering which involves finding similar patterns in  the features of the data.  Very briefly, we also covered some basic linear algebra. Vectors is our main way of representing  features of a singular data instance. When we want to make comparisons to other vectors to find  similarity, we can use techniques such as the Euclidean distance and Cosine similarity/distance which all  involve vector mathematical operations. Once we move into multiple data instances (multiple patients  for example) for a given feature set, we end up creating a matrix. Matrices also have mathematical  operations that can be performed, and we can also have different types of matrices such as diagonal  matrices (values only in the diagonal direction) and identity matrices (1’s in the diagonal direction).   