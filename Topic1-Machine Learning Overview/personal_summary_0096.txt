1.1P:  Summary:  1.3:  An algorithm is a set of instructions, computers need precise ones to perform correctly.  1.4:  Machine Learning is the ability for a computer to learn without explicit programming, or a set of tools to derive meaning from data.  A computer learns when performance (P) increases with Experience (E) while performing tasks (T). Machines learn by reacting to data and getting closer to a desired outcome each time.  ML allows for processing large datasets, which would be incomprehensible for humans due to their scale.  Activity: How would you define machine learning? Do a bit more reading and come up with your own definition:  After more reading, I would broaden the definition slightly to: “The ability for a machine to recognise useful patterns in data with minimal human intervention”  1.5:  ML has a wide range of applications, including allowing for:  ▪  Robotics to move through and navigate their surroundings ▪  For machines to ‘see’ and interpret the environment ▪  Solving games like Go and Chess ▪  Processing natural language voices and transcribing speech ▪  Recognising handwriting and numberplates ▪  Diagnosing medical conditions ▪  Predicting stock market trends  1.6:  ML happens in three stages:  1.  Data manipulation involves the acquisition, conversion into data useful for  machines, cleaning and over preparation of data.  2.  Analytics involves finding correlations in order to design a model, this works with statistics to build a machine capable of decision making/ classification. 3.  Finally, Evaluation/ Visualisation is the step where the result is analysed against a different dataset, if the product is unsatisfactory, it undergoes refinement.     1.7:  Supervised learning relates inputs to known outputs. There are two types, classification and regression problems. Classification involves dividing data based on the trained algorithm, creating a decision boundary. Regression analyses the relationship between response and predictor variables.  Activity: Do some research and provide a real-life example of machine learning that uses supervised learning:  Object identification uses a neural network to interpret context in images. It works with the bitmap representation of an environment and seeks to identify an object within, this is supervised as the object is known/ supplied in an evaluation set.  1.8:  Unsupervised learning involves the analysis of a dataset which is unlabelled, to determine its structure. This can be accomplished by clustering and factor analysis (among other methods). Clustering works by grouping similar points together, this uncovers possible patterns in the set and divides data points.  Activity: Do some research and provide a real-life example from machine learning that uses unsupervised learning. Justify why it classifies as unsupervised learning and not supervised learning.:  Anomaly detection attempts to identify unusual or outlier data points that are of note such at in network activity or financial transactions. The model uses unlabelled data as the point being sought may not be known to exist. Therefore it is unsupervised learning.  1.9:  Reinforcement learning, as an algorithm, involves acting on the environment and receiving a reward for positive actions. Although, it cannot know what the action(s) to achieve the desired end goal are. These actions influence the data it will receive in another iteration.  Activity: Other than applications in games, can you find an example where reinforcement learning is used in machine learning? Justify you answer.  Pathfinding, much like playing a game with set moves, finding optimal routes through complex trees can happen step by step. With positive and negative feedback fed to the model for more or less efficient solutions. Thus this represents reinforcement.        1.10:  To effectively train a model, a dataset must be randomly split into a training and evaluation portion. The training set will be used to build the model, the evaluation set will test its accuracy. The process of partitioning the data randomly is repeated and the results are average out.  This is then repeated until the model produces useful predictions or results. A significant influence on the outcome is choosing the correct model for the outcome  Activity: Perform your own exploration of model evaluation and try to understand the differences between training, validation and test datasets.  From further reading, an important step in evaluation is the confusion matrix, which allows for defining negative and positive outcomes. This can be tracked and factored into the model.  Training sets are employed to provide examples used to fit parameters, the validation set allows for an evaluation of the model’s ‘fit’ and the test set is used to evaluate the final fit of the model. These can be partitioned in various ways but the test set is sometimes withheld and not used in training, and generally the model randomises its dataset prior to division.  1.11:  Mathematics form the basic for ML, its theory and application. Specifically the topics of vectors, matrices and probability.  1.12:  Vectors are a series of related numbers, which can be represented as a single column matrix. Their main function are transposition, addition and inner product. They are represented visually by a magnitude and a direction.  1.13:  Cosine similarity is a technique whereby the angle of two vector’s cosine is calculated and used to gauge similarity of vectors inner product space.  Cosine distance measures dissimilarity by the angular difference of two vectors.  We have three vectors, A=[1 5 2 9], B=[5 8 2 9] and C=[3, 0, 2, 6].  Activity: Find the relation between Distance(A,B) and Distance(A,C) using various distance measures explained in this article:         1.14:  Matrices are a fundamental concept for ML, some basic operations include addition and subtraction, which works where matrices are of equal size. To do this, all elements corresponding to one another in the matrix are added or subtracted from one another. Multiplication multiplies each element by a constant.  Element-wise multiplication involves multiplying each element by each element where matrices are of equal size. Matrix to matrix multiplication where the columns in the first matrix are equal to the rows in the second. Where product matrix is C, for each element (i, j) this is populated by dot product of A(i,:) and B(:,j).  Square matrices have equal rows and columns, otherwise the matrix is rectangular. An orthogonal matrix is a square matrix where its transpose is equal to its inverse. Transposing a matrix involves reshaping, where columns become rows and vice versa. Matrices which are equal to their transpose are symmetrical.  A diagonal matrix only have values > 0 along a single diagonal through the array.  An identity matrix is a diagonal matrix with all values 1. A matrix has a square matrix if it * another matrix and vice versa = I  1.15:  Vectors can represent documents and their Euclidean distance can be used to gauge closeness.  1.16:  Activity: What level of experience do you have with Python? What’s the most difficult thing you’ve ever coded and why was it difficult?:  Basic level. Some experience with scripting and automation, building console and GUI applications, data mining, processing, analytics and visualisation etc.  Hardest program was either a GUI constructed with Tkinter for a Raspberry Pi which linked to a physical circuit and controlled input and output of various pins on the device, or a piece of malware which randomly attacked open ports on a network device with UDP traffic.   