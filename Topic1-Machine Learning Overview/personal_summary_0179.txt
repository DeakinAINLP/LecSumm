We started this topic with a brief overview of conventional algorithm based software development. This was then compared to the field of machine learning (ML). We were shown that a class of computer applications could be created that would dynamically respond to changing input, and improve on that response over time, without being explicitly programmed to follow step by step instructions.  We then examined some real world usage of ML applications: and were challenged to come up with our own idea for field in which ML applications could make a difference. I believe that real time traffic management would be a natural fit for this domain.  ML applications can require large volumes of data: and before working with that data, it needs be prepared: missing values need to found and dealt with, some values might need to be mapped into different forms, and outliers and noise need to be dealt with.  Once the data has been prepared, the ML application can begin to be built. Different statistical techniques (models) are applied to the data (training) to create a system that can be used to support decision making going forward.  Once the system has been created, it is evaluated. If the performance does not meet the desired standard, the whole process is repeated, from the start if need be.  There are three ways in which an ML system can be trained:  1. Supervised learning 2. Unsupervised learning 3. Reinforcement learning  Supervised learning: we label the data before we feed to the model. The model can then work out the relationship between the input features and the desired target output.  There are two supervised learning approaches: classification and regression. In classification, an algorithm is used to group the test data into categories. In regression, we try to understand the relationship between predictor and response variables.  Unsupervised learning: algorithms are used to analyse and cluster the data. Essentially, hidden patterns in the data are being searched for.  In unsupervised learning, data clustering or factor analysis (creating factors from the observed variables) are common approaches.  Reinforcement learning: trial and error solutions are attempted. Favourable results are ‘rewarded’ and unfavourable results are ‘punished’. The system is learning from repeated interactions in an  environment. Essentially, the system is told the goal, but not how to get there. In a way, this imitates human learning.  We then again touched on model evaluation and selection: given that there are many models out there, we have to ensure that our selected model meets the desired criteria: and that the only way to do this is to split the initial data into training and test components: then to use the training data to teach the model and use the test data to evaluate the performance. Then, if need be, we repeat this cycle, until we achieve the desired performance.  Having gone through this brief introduction to Machine Learning we then moved on to cover the mathematics that underlies much of Machine Learning.  We covered vectors and matrices.  In vectors we refreshed our memories of transposition, addition, the inner product and vector magnitude. We also covered calculating the distance between vectors.  In matrices, we touched on addition, subtraction, scalar multiplication and scalar division, elementwise multiplication, matrix to matrix multiplication and transposition.  When covering matrices, we also defined matrix types: symmetric, diagonal, identity, the inverse matrix and the orthogonal matrix.  The final section of the topic introduced both the Python programming language and Jupyter notebooks.  Python is a high level general purpose interpreted language. It is a dynamic strongly typed interpreted language. It supports object orientation, functional programming, and has a ‘batteries included’ design philosophy. There are also a lot of Monty Python references around the language and its libraries. It has a large online repository of third party software, named ‘PyPi’.  The third party software that we will make heavy use of in this course is:  Pandas: a data analysis library SciPy: algorithms and data structures for scientific computing   NumPy: a numerical computing library    matplotlib: a visualisation library   scikit-learn: machine learning package  Jupyter is an environment that supports the creation of executable notebooks that contain both text and Python code.  