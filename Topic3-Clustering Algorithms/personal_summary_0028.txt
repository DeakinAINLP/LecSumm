My beliefs definitely have changed after seeing how Bayesian has worked by increasing the chance of wins in a scenario. It’s interesting to see how learning occurs by using other methods to increase the chance of learning. I like how the source emphasizes that using a single strategy will lead to poor results as learning require an array of different strategies to optimize it’s skill.  My understanding of random variables are that they are a range of possible values which are collected from any arbitrary source which can be measured continuously or numbered discretely. Some random data values around me could by the weight I obtain from standing on top of a scale, or the time I put something in the microwave for. A discrete value could be some kind of product quantity I have at my workplace or the amount of cars I have in my driveway. These are random because they have are mostly arbitrary and can be used in a probability function to solve something.  Distributions of random variables. A probability distribution is a function that relates the outcome of a statistical experiment with its probability of occurrence. There are several important distributions, including the Bernoulli distribution for binary random variables, the uniform distribution for discrete and continuous random variables, and the normal distribution, which is the most popular distribution for continuous random variables. The central limit theorem states that the distribution of the sum of independent and identically distributed random variables becomes increasingly normal as the number of variables grows. This theorem has important applications in statistics and probability theory.  Data wrangling also known as data munging, refers to the process of cleaning, transforming, and structuring a dataset to make it more suitable for analysis. This is a crucial step in the data science pipeline, and it involves a combination of manual and automated techniques. Data wrangling can be a challenging and time- consuming process, particularly when dealing with messy, unstructured, or incomplete data. Common tasks involved in data wrangling include identifying and correcting errors and inconsistencies, handling missing values, combining datasets, converting data into an appropriate format, identifying and removing outliers, normalizing data, and summarizing data into useful statistics.  Overall, data wrangling is essential in data science as it enables the transformation of raw, unstructured data into a structured format that is appropriate for analysis and insights  What sort of colour, shapes and textures would you expect in an outdoor image that sets it apart from an indoor image? What other features could you use in your model? Share your thoughts in the discussion forum.  I would expect mainly brighter and multi colored shades of light, especially shades of orange, yellow and white to signify the sun. I believe most textures and shapes would be blockier in an indoor image as indoors is a man-made environment with refined objects and sharp edges whereas outside images would have more nature and jiggered textures to show plants and other nature objects. Another feature you could use is similarity between objects that are always seen outside (such as the sun) or always seen inside, (such as a light bulb). Have a machine learn these kinds of distinguished patterns would give it a boost in accuracy.  The technique described in the video is a popular model used to encode text data. What are some of its limitations?  A few limitations with the bag of words model (BOW) could be vocab size for large documents with multiple words which would take up a ton of memory. Lack of context, each word given is without order and all treated equally important, this can lead to a loss of crucial information and meaning. The BOW model can only consider the presence or absence of a word, this result in sparse representations, where most of the entries in the matrix are zeros. This can negatively affect the performance of machine learning algorithms that rely on dense feature representations.  Data wrangling  Data wrangling refers to the process of acquiring, analyzing, and manipulating raw data to make it suitable for faster processing and evaluation. It includes several sections such as data loading and saving, data exploration, data processing (including handling missing values and encoding categorical values), data distribution, and scaling.  2. Provide summary of your reading list – external resources, websites, book chapters, code libraries, etc.  The module content, YouTube videos for further research into some of the concepts. Websites and stack overflow to get code examples for some of the tasks.  3. Reflect on the knowledge that you have gained by reading contents of this topic with respect to machine learning.  Data wrangling was a fairly important and interesting module. It made a lot of sense in the context of machine learning as machine require raw data to be organized and processed so it can be given a meaningful measurement. The concepts taught were very informative and explained the different data representations when compiled into something meaningful.  4. Attempt the quiz given in topicly content (2.16) and add screenshot of your score (³85% is considered completion of the task) in this report.  