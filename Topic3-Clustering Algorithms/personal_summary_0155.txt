 Probability The probability of an event is a number that indicates how likely the event is to occur.  a)  Random Experiments  The probability of a random experiment can be given by the number of favorable outcomes / total number of outcomes.  b)  Joint probability  is a statistical measure that calculates the likelihood of two events occurring together and at the same point in time. Joint probability is the probability of event Y occurring at the same time that event X occurs.  c)  Conditional Probability  Conditional probability is defined as the likelihood of an event or outcome occurring, based on the occurrence of a previous event or outcome. Conditional probability is calculated by multiplying the probability of the preceding event by the updated probability of the succeeding, or conditional, event.  d)  Bayes Rule  Bayes' Theorem is a way of finding a probability when we know certain other probabilities.  P(A|B) = (P(A) P(B|A)) / P(B)  Random Variable A random variable is a variable whose value is unknown or a function that assigns values to each of an experiment's outcomes. A random variable can be either discrete or continuous.    Discrete Random Variables  Discrete random variables take on a countable number of distinct values.    Continuous Random Variables  Continuous random variables can represent any value within a specified range or interval and can take on an infinite number of possible values.  Probability distribution  I.  Bernoulli Distribution  A random experiment that can only have an outcome of either 1 or 0 is known as a Bernoulli trial. Such an experiment is used in a Bernoulli distribution.  II.  Uniform Distribution  The uniform distribution can be visualized as a straight horizontal line.  III.  Normal Distribution  Normal distribution, also known as the Gaussian distribution, is a probability distribution that is symmetric about the mean, showing that data near the mean are more frequent in occurrence than data far from the mean. In graphical form, the normal distribution appears as a "bell curve".  IV.  Central Limit Theorem  The central limit theorem (CLT) states that the distribution of sample means approximates a normal distribution as the sample size gets larger, regardless of the population's distribution.  Data wrangling Data wrangling is the process of removing errors and combining complex data sets to make them more accessible and easier to analyse. The most used examples of data wrangling are for:  Task 2_1  Identifying gaps or empty cells in data and either filling or removing them.    Merging several data sources into one dataset for analysis.    Deleting irrelevant or unnecessary data.   identifying severe outliers in data and either explaining the inconsistencies or deleting them to facilitate analysis.  What are the Steps to Perform Data Wrangling?  Þ  Data Discovery Þ  Data Structuring Þ  Data Cleaning Þ  Data Enriching Þ  Data Validating Þ  Data Publishing  Difference between Data and Signal  Data usually refers to raw data, or unprocessed data. It is the basic form of data, data that hasn’t been analysed or processed in any manner. Once the data is analysed, it is considered as  information.  For  data  to  be  transferred  electronically,  it  must  first  be  converted  into electromagnetic signals. The signal can then be used to transfer data from one device to another device. The signal can be either analog or digital in nature.  Data scaling Scaling  is  a  method  of  standardization  that’s  most  useful  when  working  with  a  dataset  that contains continuous features that are on different scales, and you’re using a model that operates in some sort of linear space (like linear regression or K-nearest neighbors).  Data Wrangling Operations in Python:  Þ  Handling Missing Values  Most of the datasets having contained missing values of null. We can handle these using the Python pandas module by either deleting them or replacing them with mean, mode, the most frequent value of the column.  Þ  Grouping Data  We can use the groupby() method that returns a DataFrameGroupBy object. And by calling the method like value_counts() on the object obtained, we can get the number of occurrences for each unique value in the specified column.  Þ  Reshaping the data  In this process, data is manipulated according to the requirements, where new data can be added or pre-existing data can be modified.  Þ  Filtering the data  Sometimes datasets are composed of unwanted rows or columns which are required to be removed or filtered.  