Machine learning is dependant on maths for various iteration outputs and calculations for this purpose various mathematical operations such as statistics, vector functions, matrices, probabilities, python programming etc., are discussed when gaining a better understanding of Machine learning.  Probability is important in Machine learning because it helps in developing predictive models based on uncertain data. Various basic definitions linked to probability and its along with its parameters are discussed. These include a random experiment, an event, sample space etc. A random experiment can be defined as an activity or exercise for which the outcome cannot be defined or said with certainty. For example, when a coin is tossed it cannot be predicted with certainty if the outcome is going to be heads or tails. Such tasks are referred to as random experiments. When a random experiment occurs the outcome of this is referred to as the event. Sample space is the collection of all such possible outcomes for a random experiment.  Probability is the likelihood of an event to occur. Joint probability can be defined as the probability when there is more than one random experiment involved. That is, joint probability is the likelihood of the two events to happen. Example for this will be the likelihood of getting a four and six when two dice are rolled. Conditional probability is the likelihood of an event to occur when we already know the pervious event.  Bayes theorem is the process of changing current events considering events that has already occurred.  Random variable is a function which defines value to the outcomes of a random experiment. These variables can be continuous random variables or discrete random variables. Examples for continuous random variable is height of a building and for discrete random variable is number of guests attending a wedding. Discrete random variables are defined using probability mass function and Continuous random variables are defined using probability Density function. Then various probability distributions are discussed which are as follow.    Binary Distribution – It is the distribution achieved when there are two outcomes for an experiment. That is there are two random variables one is if the event is a success and the other is when the event is a failure.    Uniform Distribution – Uniform distribution is said to be achieved when the results of all the  outcomes are equal.    Normal Distribution- normal distribution is said to be achieved when there is no skewness in the  graph or in other words when the outcomes are symmetrical with mean at the centre of this graph.  Central Limit theorem- according to this theorem when a sufficiently large sample set is taken then the output distribution of its means is normally distributed.  Data Wrangling- Raw data is usually available with lot of inconsistencies before we can use it for analysis. Data cleaning and transformation needs to be performed on the raw data so that it is easy for analysis.  This process includes multiple processes like data cleaning, transforming, removing, or replacing any missing or incorrect data. Any data that is not correct can result in producing an analysis of that data which is not that accurate. Therefore, data wrangling is performed to produce a model with better performance.  Replacing any missing value present in data is an important component of data wrangling. This can be done by identifying the columns having missing values and replacing them with mean, median or any value that best suits the interest of analysis.  Another important part is normalization or scaling data. This is the process of transforming data withing a defined range. Min-max scaling, z-transformation etc are examples for this. This transforms the data in range 0 to 1. For categorical data various techniques like hoot encoding are used to transform data to integer values and use for analysis.  