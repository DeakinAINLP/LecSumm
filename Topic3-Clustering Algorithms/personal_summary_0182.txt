Data Wrangling  Probability defines the likelihood of an outcome of some event which can be written as the Probability (P) of some event (x) where P(x) = y.  While some events are straightforward, such as the probability of a coin landing on the side of heads is 50/50, or when written as a scale between 0 and 1, P(x) = 0.5, some events are affected by external factors. When we have knowledge of an event, the probability can be affected.  Random Variables are variables who’s value comes from the result of some action, for example if you roll a dice, the variable to store the result will come from the action of rolling and will be some random number between 1 and 6. When we look at the results of random variables across numerous events, we call the results distribution. Distribution helps us understand the trends in results across large numbers of events by looking at smaller subsets as examples. Three common types of distribution are normal distribution, where the most common results are from the middle (or average region) of the dataset; uniform distribution, where the data is spread evenly across the dataset; and skewed distribution, where the majority of results are towards one side of the dataset.  In order to make sense of the data in these distributions and to get accurate results, we need to clean the data to remove nonsense variables or outliers which aren’t meaningful. This process is called ‘Data Wrangling’.  The next step to understanding data fed into an ML model, is to properly represent the data. While the subject of an image might be obvious to us, a computer requires such data to be converted into numbers which can accurately represent the features of the image. These features become the key to how a model can understand the data.  Sometimes data needs to be converted to a numerical value which can be understood be a machine. This process is called encoding. We may also need to scale certain data, where the range of values of one dataset (such as weight) will be larger than another (such as height) which can result in the dataset with the larger values dominating the other and skewing results. Scaling allows both of these values to be converted to a common range while maintaining their meaning.  One common way to scale data is to convert values to a range between 0 and 1, where 0 is the minimum result and 1 is the maximum.     