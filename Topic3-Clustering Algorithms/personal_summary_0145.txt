Summary: In this topic we have covered the following: 1) Probability, conditional probability, Joint Probability and Bayes Rule 2) Types of random variable i-e discrete and random variable 3) Distribution of random variables. For example Bernoulli distribution, uniform distribution, normal distribution and central limit theorem 4) Learnt about data wrangling and how to replace missing values with immediate mean or median 5) Scaling or normalization on the given data 6) Data encoding in non-numerical data  Part 2:  Scaling: When a dataset has upsides of various segments at definitely various scales, it gets extreme to dissect the patterns and examples and examination of the highlights or columns. Thus, in situations where every one of the sections have a huge contrast in their scales, are required to have been changed so that that large number of values fall into a similar scale. This method is called Scaling. https://www.geeksforgeeks.org/how-to-scale-pandas-dataframe-columns/  Min-Max Scaler: We will utilize the default setup and scale values to the reach 0 and 1. Initial, a MinMaxScaler occasion is characterized with default hyperparameters. Once characterized, we can call the fit_transform() function and pass it to our dataset to make a changed form of our dataset https://machinelearningmastery.com/standardscaler-and-minmaxscaler-transforms-in-python/  Label Encoding: The way to deal with encoding all non-numerical values is to utilize a strategy called label encoding. Label encoding is essentially changing each value in a column to a number https://pbpython.com/categorical-encoding.html  Part 3: We have learnt about different kinds of probabilities and then learnt how to normalize a data. After that we have learnt how to scale a data if it is not on a same scale i-e large gap between values, after doing encoding and then plot a graph to see the changes before and after scaling  