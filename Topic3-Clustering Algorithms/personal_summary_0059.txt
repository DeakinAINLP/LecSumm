Topic 2 – Data Wrangling  Goals Understanding of    Vectors and basic operations   Matrices/Matrix operations   The basic concept of probability   Python Programming  Statistics Random experiment    The outcome cannot be predicted with certainty  o  Tossing a coin o  Catching a fish o  Daily temperatures  Event    A set of outcomes of a random experiment   E.g coin toss  o  Sample space is 𝛺 = {ℎ𝑒𝑎𝑑, 𝑡𝑎𝑖𝑙𝑠} where the event A could be either {heads} or {tails}    Dice rolls  o  Sample space is {1, 2, 3, 4, 5, 6} where the events A could be either  A = {{1}, {2}, {3}, {4}.  Probability  {5}, {6}}    Quantifiable from a number 0 to 1   P(A) = probability of occurrence   P(A) = 1 – P(A) = probability of non-occurrence  Joint Probability    More than one event   For E.g a random experiment where 2 coins are tossed  o  P(A∩B) or P(A and B) or P(A * B)  Conditional Probability    Probability of some event A, given the occurrence of another event B  (𝐴|𝐵) =  Bayes Rule  𝑝𝑟(𝐴∩𝐵) 𝑝𝑟(𝐵)  given that PR(B) Is not 0    Probability of an event A based on another event B, which is related to A  if cancer is related to age; the following rule can understand the probability that someone has cancer-based on their ag𝑝 (𝐴|𝐵) =  𝑝𝑣(𝐵|𝐴)×𝑝𝑟(𝐴) 𝑝𝑟(𝐵)  Random variables Random variables    A function that can assign probabilities to events of interest in a random experiment   E.g tossing a coin for head and tail  o  X can be a random value where  ▪  X = 1 means heads (in some cases head is 0.6) ▪  X  = 0 means tails (in some case tail is 0.4)  o  Therefore P(X=1) = 0.6 and P(X=0) = 0.4  Types of random variables    Discrete  o  countable ▪ ▪  number of emails (in an hour)  faces of a dice    continuous o  infinite as they keep changing or have not been set  ▪  height of a person ▪ time till failure  Discrete random variables    Probability Mass Function (PMF) → 𝜋(𝑥)   Is assigned a probability to each possible value of the random variable o  𝜋(𝑥) = 𝑃(𝑋 = 𝑥) (the summation should all add up to 1) o  The Summation value  ▪  Σ 𝑥𝜋𝑥 = 1  o    The case of a question like “what is the probability of rolling a die and getting a number less than  5” would require a Cumulative Distribution Function  o  The cumulative probability associated with a function  o  o  Continuous random variables    Probability density function (PDF) → f(x)  o  F(x) >= 0 o  Integration of f(x) should be 1    A statistical expression that defines a probability distribution for a continuous random variable  o  Assigns probability to a range of values    Probabilities assigned at an exact value = 0  Distributions of random variables    A function that links each outcome of a statistical experiment with its probability of occurrence  Bernoulli distribution    Defined for a binary random variable X = 0, 1     E.g the outcome of an exam implements this as the x = 1 is a pass, and x = 0 could be a fail  Uniform distribution    for both discrete and continuous random variables  o  discrete  ▪ ▪ o  Continuous  ▪ ▪  o  E.g rolling a die can be a uniform distribution  Normal distribution [1]    Used for finding probabilities   Defined for a continuous random variable     The function above gives the probability from a certain z score range a < x < b    Data Wrangling    Process of cleaning data, transforming and organising a dataset to make it suitable for analysis.   Common tasks in data wrangling include:  o  Correcting errors and inconsistencies in the data o  Handing missing or incomplete values o  Combining multiple datasets o  Converting the data into a format that is suitable for analysis o o  Normalizing the data o  Aggregating the data into useful information  Identifying and removing outliners  Images as data Introduction    Teaching a machine to analyse and categorize an image  Computers understand numbers    Finding features that can be represented as numbers   Use an image as input data for this computer algorithm, which needs to be represented in the  vector of features  Creating a model    For an example of identifying whether an image is outdoor or indoor, we can  o  Divide the image into smaller 9 * 15 = 135 blocks o  For each block, features of our choice should be computed  ▪  Colour averaged across the block ▪ Shapes within the block – number of straight lines and curves ▪  Texture for example the amount of light/dark variation in the block ▪  Radiance or brightness o  For the 135 blocks, calculate the  ▪  Mean ▪  Variance ▪  Other stats    P features were extracted from each block; therefore, 135p features per image. Therefore n  images. The total size of the feature matrix would be 135p *  n.  Text Data representation Introduction    Creating models from large-scale data   Machine learning describes an image using features, most commonly known as  attributes/parameters.    Feature vectors  o o  Doc1’s feature vector is {1, 1, 2, 1, 0} an d doc2’s feature vector is {0,  2, 2, 0, 2}    Feature matrix  o o  In ML, each document is known as an instance/example/record  ▪  The matrix is known as a feature matrix  ▪  Each matrix is put on a row or column  What are signal and data? Data    Doesn’t have any meaning apart from when it can be used in the form of information  Signal    The quantity that varies in space and or time (or any other parameters)   E.g audio signal is an electrical representation of sound   The signal can be represented in the form of a reflected parabola   F(x) = -ax^2 + bx + c   The signal is another form of data  Encoding and Distribution Encoding    Used to convert integer values   E.g features of campus facilities can be represented as [“Engineering”, “Computing”, “Burwood”]  Some values contain categorical values which the machine may not understand  which can be denoted as [0,1]    Well-known encoding techniques include Ordinal Encoder, one-Hot encoding and Label Encoder  Distribution    Refers to the values inside a data set that are distributed   Can impact the performance of the learning algorithm   The normal distribution is represented using a bell-shaped curve   Uniform distribution is represented where values are evenly distributed across the range of the  data Skewed; values are not evenly distributed and are instead concentrated on one side of the range     E.g if the values are not evenly distributed; the algorithm can be biased toward certain values  Scaling and Normalisation Scaling    Purpose of converting a set of values to a new range of values   E.g if there are 2 features height in feet and weight in pounds  Normalisation    Used to transform values inside a dataset into a common range   Many ML algorithms work best based on standardized data   A common way of normalisation data is using the min-max normalisation  o  0 and 1; where 0 is the minimum value and 1 is the maximum  Data loading and saving Data wrangling    Procedure for acquiring, analysing and manipulating raw data into a suitable format.   Is divided into 5 subsection  o  Data loading and saving o  Data Exploration o  Data processing; missing values handling encoding categorical value s o  Data Distribution o  Scaling Random data into a pandas data frame Check the code in the file  Question 4 Discussion Questions 1 and 2 have been explained in the form of comments in the python code    Before and After scaling both had similar graphic shapes, however, due to the scaling of ranges of  the after data, it is noticeable that features 1-6 all have ranges of 0 to 1, unlike the before ranges which varied based on the max and min of that specific feature.    By applying the min-max function on the features, we can account for multiple features as they all    would have the constant 0 – 1 range (distribution similar binomial) It would be harder to manage with features that had different min max, which can cause wrong values for machine learning algorithms  Before Scaling  After Scaling  