1. Topicly Summary Probability – Defined as measure of likelihood and event will occur, quantified between 0 and 1.   Joint probability – probability can be defined jointly for more than one event, such as tossing two coins.    Conditional probability – probability of some event A, given the occurrence of another event  B.    Bayes rule – Mathematical rule to explain how you should change beliefs as a result of new  occurrences. Describes probability of event A based on event B that is related to A.  Random Variables – possible values that are generated outcomes of a random phenomenon.  Two types of random variables:    Discrete - defined using a Probability Mass Functions(PMF)   Continuous - defined using Probability Density Functions (PDF)  Distribution of random variables - a function that links each outcome of a statistical experiment with its probability of occurrence.    Bernoulli distribution - discrete distribution and defined for a binary random variable with  values X = 0 and X = 1.    Uniform distribution - can be defined for both discrete and continuous random variables.   Normal distribution - defined for continuous random variables.  Data wrangling - process of cleaning, transforming, and organizing a dataset to make it suitable for analysis. This often involves a combination of manual and automated processes, and it is a crucial step in the data science pipeline.  Images as data – Need to find features that can be represented with numbers. It needs to be represented in a numerical vector of features.    Can divide image into smaller blocks.  o  For each block, calculate:  ▪  Colour averaged across block. ▪  Shapes in block – number of straight and curved lines ▪  Texture ▪  Radiance o  For all blocks, can calculate:  ▪  Mean ▪  Variance ▪  Other stats   Text data representation – Bag of words model – assign each word found in documents a unique number. Can then count occurrence of words in documents. This results in feature vector for documents, turning them into term-by-document matrix.  Feature extraction - In machine learning, feature extraction is one of the key steps.  Data vs. signal - When any data is represented in an organized manner, that becomes information.  Encoding and Distribution - some features contain categorical values which the machine cannot understand. To solve this, encoding techniques are used to convert to integer values. For example, a dataset of student with features campus [“Burwood”, “Warun Ponds”] can be coded as [0,1].  Distribution refers to the way that the values in a dataset are distributed. This can be important, as the distribution of the values can have a significant impact on the performance of a machine learning algorithm. The distribution of the values in a dataset can affect the performance of a machine learning algorithm in many ways. For example, if the values are not evenly distributed, this can cause the algorithm to be biased toward certain values, which can lead to poor performance.  Scaling and Normalisation - scaling refers to the process of converting a set of values to a new range of values. The raw or unscaled features can be of different ranges, which may cause problems while training a model. Therefore, we need to scale both features in a certain range.  Normalization is a scaling technique used to transform the values of a dataset into a common range. This is often done to improve the performance of machine learning algorithms, as many algorithms operate better when the data is in a standardized range. One common method of normalization is to scale the data to a range of 0 to 1, where 0 is the minimum value in the dataset and 1 is the maximum value. This is known as min-max normalization.  Overall, normalization is a useful technique in machine learning, as it can improve the performance of many algorithms by standardizing the data.  Data wrangling  - is the procedure of acquiring, analysing, and manipulating raw data into a suitable format for faster processing and evaluation.  Data wrangling can be divided into the following sections:    Data loading and saving   Data exploration   Data processing, such as missing value handling, encoding categorical values   Data distribution   Scaling  