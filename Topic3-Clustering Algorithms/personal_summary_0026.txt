For topic 2, we mostly reviewed some basic mathematics fundamental that are behind machine learning such as statistics and probability:  -  Statistics: applied mathematics which deals with collecting and analyzing a large number of quantitative data. There are some basic concepts of statistics such as population (the whole group events), sample (a random and representative group of population).  -  Probability: the likelihood of an event happens. For example: the probability of tossing a coin and get tail is 0.5. The most important concept of probability is conditional probability which is the chance of an event happens in the condition that another event already happened. We usually use Bayes rule to solve conditional probability.  -  Distribution is another important concept of statistics and probability. There are  some types of probability distribution:  o  Bernoulli distribution: distribution of binary data (0 and 1) o  Uniform distribution: distribution of the same outcomes. For example: when  rolling a dice, the probability of each face appears is the same. o  Normal distribution (Gaussian distribution): data are distributed  symmetrically to the mean value.  -  Central limit theorem: if the samples are large enough, the means of all random  samples would be normally distributed.  -  There are some basic concepts that we should consider when processing data such  as: mean, median, standard deviation, correlation coefficient, skewness, normalization.  -  The next part of this topic is to review how to use python to process and visualize  data: reading data, handling missing values, doing some basic aggregation, standardize data, and visualize the data.  