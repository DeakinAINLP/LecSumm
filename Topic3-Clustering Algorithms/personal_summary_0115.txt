A random variable is a variable that can take several different values (a result of a chance happening). A discrete random variable which you can list and count the number of values while a continuous random variable can take any values in a defined interval. Some types of distribution: Bernoulli distribution (for discrete random variables), Uniform distribution (for both discrete and continuous random variables), and normal distribution (for continuous random variables).  Encoding: used to convert categorical values to integer values. Some techniques of encoding OrdinalEncoder, One-Hot Encoding, and LabelEncoder. One-hot encoding uses the binary number to map each category, to avoid machine learning assuming that a higher number has a higher impact on the model. OrdinalEncoder would apply for categorical variables that have ordinal relationships to make sure the higher level will have more impact on the algorithm.  Scaling: scale features in the same range to prepare for training a model. One of the common scaling techniques is min-max normalisation which is to scale the data to a range of 0 to 1.  Distribution: the distribution of each value in a dataset can affect the performance of a ML algorithm. It would be easier for the algorithm to learn if the values are normal distributions. Conversely, if the values are skewed distribution, the algorithm could be biased and have poor performance.  Data wrangling is the process of transforming raw data into a suitable format to analyse and evaluate. Data wrangling will contain some tasks:  -  Data loading and saving -  Data exploration: find the missing values and handle. -  Data processing: data encoding -  Data distribution -  Scaling  