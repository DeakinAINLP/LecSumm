Refresher of probability P(X), x in [0, 1], is the likelihood of X occurring. P(X and Y) is likelihood of X and Y occurring in the same trial P(X | Y) = P(X and Y) / P(Y) , the probability of X occurring, given that Y has already occurred Bayes rule is for updating belief due to an event P(A | B)  = P(B | A)P(A)/P(B) Random variable – discrete (a fixed set of often integer values) or continuous (infinite continuum) Pi(x) represents the probabilty mass function (for each outcome) Cumulative distribution function represents the probability the result is less than the cutoff. For continuous variables, f(x) is the probability density function and the CDF will be continuous. Random distributions Bernoulli – Takes on binary values (eg 0 and 1) Uniform – same probability for each outcome (eg fair dice) Normal – shape determined by mean and standard deviation. Under the central limit theorem, with a significantly large (30, 100?) number, the distribution of sample means will be approximately normal, regardless of the population distribution. Data Wrangling If the data fed into the model is not correct, the outcome of the training may be affected. Assuming the data was collected following the protocol with care, wrangling involves examining it to deal with missing values, incorrect values, the effect of outliers, and representing it in an appropriate format for machine learning eg combining several datasets, encoding strings into numerical values, deriving summary statistics and adapting the representation of the data considering the needs of the training algorithm. Images can be broken up into blocks (even down to pixels), and features extracted from each block. Text data is represented as a bag of words, indicating presence and number of times each word appears in the text (position information is lost) Signal is the quantity which varies over space or time. Measuring this gives raw data. Once this is processed/organised it becomes information Encoding is the way of representing the data. For categorical data, labels can be represented as indices into an array, or onehot encoding to indicate membership of each category. For Onehot the categories are mutually exclusive. Ordinal encoding represents ordering between values (but can’t rely on the interval between them being consistent) Scaling alters the range of the values Normalisation alters the distribution of the values eg min-max. 