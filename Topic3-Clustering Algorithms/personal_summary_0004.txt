Maths is base of ML. Almost all algorithms are using maths to make a decisions, iterating and developing and output. As an ML Engineer, we need to learn the following key areas that base of ML and AI: Algebra including Vectors, Feature vectors, Matrices Statistics including probabilities However at this topic, we learn about python programming too. Vectors and Matrices: Vector space model is representation of set of documents as vectors. Text data representation is addressed as feature vectors. We can use feature vectors to create matrix which includes N feature vectors. Statistics: Random experiment: A random experiment is an experiment or a process for which the outcome cannot be predicted with certainty. Such as: Roll of a dice Daily temperature Number of phone calls received on a mobile phone in a given duration Event: In probability we have event which is a set of outcomes from a random experience. For example for a dice roll experiment, sample is {1,2,3,4,5,6}, but the event could be {1} or {2} or {3} or {4} or {5} or {6}. So the probability is the measure of the likelihood of an event can occur in a sample space. The probability of happening A is P(A). Joint Probability: This kind of probability is happening when more than one event can happen. For example when we role two dices together. If the events are independent then the probability of happening A and B is: P(A and B)=P(A).P(B) Conditional Probability:The conditional probability is the probability of some event A, given the occurrence of another event B. P(A|B) read as probability of A given B is defined as: P(A|B)=P(A and B)/P(B) (P(B) is not Zero.) Bayes Rule: Bayes rule describes the probability of an event based on another event. For example the probability of buying a cheese in Coles when they have already bought bread. P(A|B)=P(B|A).P(A)/P(B) (P(B) is not Zero.) Random Variable: Random variable is a variable whose possible values are the generated outcomes of a random phenomenon. There is two types of random variable: Discrete random variables: which have a countable number of values. For example, number of people coming into a bank branch in a certain day. Continuous random variable: which can take values on a infinite continuum. For example height of men in a country. Discrete random variable: It`s defined using a Probability Mass functions (PMF.If the above figure, we wanted to find out about the probability of getting a number less than 5, then we use the Cumulative distribution Function (CDF). So, the probability of seeing a number equal or less than 5 is:   P(X<= 5)=5/6 And the probability of seeing a number greater than 5 is:  P(X>5)=1-5/6=1/6 Continuous random variable: It has been defined using Probability density Functions (PDF). This is a statistical expression that defines a probability distribution for a continuous random variable. Distributions of random variables: There are different types of distribution which we have learnt. A simple explanation of a probability distribution is that it is a function that links each outcome of a statistical experiment with its probability of occurrence. Bernoulli Distribution: This is a discrete distribution which defined with binary values. X=0 and X=1. Or X=True and X=False. Uniform Distribution: This kind of distribution can be defined for both discrete and continuous variables. For continuous variables, we have: For example rolling a dice follows a uniform distribution. Normal Distribution: It`s defined for continuous variables and the most common useful distribution. Central limit theorem: This theorem states that if we have a population with mean and standard deviation, and take large random samples from the existing population, then the distribution of the sample means will be approximately normally distributed. Data wrangling: It`s the process of cleaning, transforming and organizing a dataset to make it suitable for analysis. This process involves a combination of manual and automated processes, and it`s a crucial step in the data science pipeline. Identifying and correcting errors and inconsistencies in the data Some common task s of data wrangling include: Handling missing values Combining multiple datasets Converting the data into a format that is suitable for analysis Standardisation and normalization Identifying and removing noise and outlier data Images and Texts as data: No matter what kind of text, document, image and data we want to analyse; the main point is that computers just understand the numbers. So we need to convert it to the numbers. For example by dividing a photo to a multiple cells, and calculating some statistical and some features to use them as an input to algorithms. For example, one of the way for text data representation as a matrix is using the bag of word representation which can be used. Feature extraction: This step is one the most important steps in ML. At this step we need to find out and decide which features we should consider to use for the process of developing a model. There are a lot of ways for feature engineering and feature extraction. We can use statistical methods such as correlation or using algorithms to find out which feature should be considered. Encoding: Encoding is another important step in the process of data wrangling. As we know, when the machine cannot understand the categorical values, we use encoding to convert it to integer values to be useful for the machine. For example in a feature we have {low, medium, high} which we can use encoding to present it as a integer to be useful for the machine. There are several techniques for encoding: One-hot Encoding, ordinal encoding, label encoder. Scaling: This is another important step in data wrangling. And very important step to prepare values for modelling. For example when we want to use Age and salary as two features for a modelling, the range of these two features can be very different; so we use normalization to solve the issue and bring all the data in a scale of for example 0 to 1. One of the most useful way of doing that is the min-max normalization: One of the key points of using this method, is that we need to handle the outliers first. As we are using the max and min, we need to solve the problem of outliers first and then use this formula. 