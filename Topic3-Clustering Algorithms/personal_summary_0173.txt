Key Learning:    Basic definitions of probability and related concepts, such as random experiments, events, joint probability, conditional probability, and Bayes' rule, emphasizing their importance in machine learning algorithms. Probability is the likelihood that an event will occur, quantified as a number between 0 and 1, and Bayes' rule explains how to change beliefs based on new information. random  variables  and  their  importance  in  assigning  probabilities  to  events  of  interest  in  a random  experiment.  Random  variables  can be discrete  or  continuous  and  are defined  using probability  mass  functions  or  probability  density  functions,  respectively.  Probability  mass functions assign probabilities to each possible value of the random variable, while probability density functions assign probabilities to a range of values.      Probability distributions are functions that link outcomes of a statistical experiment with their probabilities. Bernoulli distribution is defined for a binary random variable, uniform distribution can be defined for both discrete and continuous variables, and normal distribution is the most popular  continuous  distribution.  The  central  limit  theorem  states  that  the  distribution  of sample means will be approximately normal if random samples are taken from a population with a large enough sample size.    Data  wrangling  is  a  crucial  step  in  the  data  science  pipeline,  involving  the  cleaning, transformation, and organization of a dataset to make it suitable for analysis. It involves tasks such as identifying errors and inconsistencies, handling missing values, converting data formats, removing outliers, and aggregating data into useful summary statistics.    The process of teaching machines to analyse and categorize images by representing them as numerical  vectors  of  features  and  creating  a  model  for  image  classification,  which  involves selecting features and computing statistics for each block of an image.    Feature extraction is a key step in machine learning where a set of features are derived from raw data, containing information on the target variable. In the case of identifying whether an image is indoors or outdoors, images are divided into smaller blocks and features such as colour, shape, texture, and radiance are computed for each block, resulting in a feature matrix that can be fed into a computer algorithm for classification.    Data refers to any information shared by users in the form of text, numbers, or media that is stored  as  observations  or  measurements,  with  meaningful  representation  generating  new insight for companies. In contrast, a signal  is a quantity that varies over parameters such  as space or time and can be represented as an equation with varying shapes depending on the value of the equation's parameters.    Encoding techniques are used to convert categorical values to integer values, including well- known  techniques  such  as  OrdinalEncoder,  One-Hot  Encodings,  and  LabelEncoder.  The distribution of values in a dataset can impact machine learning algorithm performance, with normal, uniform, and skewed distributions being common, and can cause bias toward certain values or make it easier for the algorithm to learn and make predictions.    Scaling in machine learning involves converting a set of values to a new range of values, while normalization is a scaling technique used to transform the values of a dataset into a common range, with one common method being to scale the data to a range of 0 to 1.    The  Python  library  "pkg"  is  useful  for  statistical  data  analysis,  including  the  creation  and manipulation of random variables. Random variables are a key concept in statistics and can be discrete or continuous, with their probabilities described by probability density or cumulative distribution functions.    A random variable is a function that assigns probabilities to outcomes of a random event. The random  matrix  and  discrete  random  variable  examples  illustrate  the  concept  of  random variables and their probability distribution.    Data  loading  and  saving,  data  exploration,  processing  (such  as  missing  value  handling  and  encoding categorical values), distribution, and scaling in Python.    Checking data type, range, and missing values using Pandas.   Using  the  scikit-learn  library  to  convert  data  frames  into  integer  labels.  Plotting  histograms using the Matplotlib library, both before and after standard scaling.  