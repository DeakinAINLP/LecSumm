 Main points summary  -  Statistics. Probability is the likelihood that an event will occur, quantified as a  number between 0 and 1. If the probability of an event A occurring is P(A), then the probability of the event A not occurring is 1 – P(A). If two events, A and B, are independent, the probability of both of them happening is P(A) * P(B). For events that are not independent, Bayes rule can be useful.  -  Random variables, discrete or continuous. Some important probability  distributions are: Bernoulli distribution, Uniform distribution and Normal distribution. The central limit theorem tells us that if we take a sufficiently large random sample from a population with the same mean and standard deviation, the distribution will be approximately normally distributed.  -  Data wrangling, also known as data munging. It is about cleaning data and  making it suitable for analysis. Often a combination of manual and automated processes and can be complex and time consuming. Images as data. For a computer to understand an image it would have to be fed in as a set of numbers. Feature extraction.  -  -  Data vs Signal. Data is important. Companies gather large amount of data to  generate insight and help them take certain decisions. A signal another form of data.  -  Encoding is the process of assigning quantitative value to features that contain categorical values which the machine can’t understand. Some known encoding techniques are OrdinalEncoder, One-Hot Encodings, and LabelEncoder.  -  Scaling refers to the process of converting the values in a dataset to a new range of values. For example, “squeezing” all values into a range from 0 to 1, which is called normalization.  -  Data wrangling with Python. There are several useful python libraries for  statistical analysis, for example NumPy.  