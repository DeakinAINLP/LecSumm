Lesson Review: Introduction Module Learning Objectives  1.  Vectors and basic vector operations 2.  Matrices and matrix operations 3.  Basic concept of probability 4.  Python programming : using different modules and packages.  Summarising the content: Random Experiment – an experiment or process for which the outcome cannot be predicted with certainty. For example, toss of a coin, roll of a dice. Event – a set of outcomes of a random experiment. For example – in the coin toss, the event could be either heads or tails.  Probability – the likelihood that an event will occur. Joint Probability – the likelihood that two or more events will occur together. I.e. tossing two coins and getting a heads on both coins. Conditional Probability – Probability of an event, given the occurrence of another event.  Bayes Rule – A mathematical rule that describes the probability of an event, based on another event that is related to the first. Represented mathematically as:  Random Variable – a  variable whose possible values are the outcomes of a random phenomenon.  Discrete random variables – have a countable number of values, such as the values on a dice.  Probability Mass Function (PMF) – assigns a probability to each possible value of the random variable. Cumulative Distribution Function (CDF) – give the cumulative probability associated with a function.  Continuous random variable – uncountable values that are related to real numbers. Ie. A person’s height. They can be defined using Probability Density Functions (PDF) – a statistical expression that defines a probability distribution for a continuous random variable.  Distribution – refers to the way that the values in a dataset are distributed.  Normal Distribution: a commonly used symmetrical bell shaped distribution of data values:  Data Wrangling (Data munging) – the process of cleaning, transforming, and organising a data set to make it suitable for analysis. This can include correcting errors and inconsistencies, handling missing or incomplete values, converting data format, removing  outliers, aggregating and normalising the data set. Data Wrangling can be broken into three categories;  ▪  Data Loading and Saving ▪  Data exploration ▪  Data encoding, distribution and Scaling.  Feature Extraction – a method that selects and or combines variables into features. This reduces the amount of data that must be processed, while still accurately describing the original data set.  Data Representation – since computers understand numbers, words and images must be turned into numbers before a computer can process them.  Encoding – techniques use to convert to integer values. Scaling – refers to the process of converting a set of values to a new range of values. Normalization – a scaling technique used to transform the values of a dataset into a common range. A common method is to scale the data to a range of 0 to 1, where 0 is the minimum and 1 is the maximum.  