Probability plays a major part in numerous machine learning algorithms.  Probability is defined for an event and is the measure of the probability that an event will happen. It is evaluated as a number between 0 and 1.  The probability of an event A occurring is indicated as P(A). The probability of an event A not occurring is signified as P(A) = 1 - P(A)  Probability can be defined jointly for more than one event. The conditional probability is the probability of some event A, given the occurrence of another event B.  The substance of most of Bayesian approaches are to supply a mathematical rule clarifying how you ought to change your existing convictions in the light of modern event. Bayes rule portrays the probability of an event A based on another event B that's related to A.  A random variable, could be a variable whose possible values are the created outcomes of a random phenomenon.  There are two types of variables,    Discrete random variables: have a countable number of values. For case, faces of a  dice, number of emails received in an hour etc.    Continuous random variables: can take values on an infinite continuum. For  illustration, height of an individual, time to failure etc.  Discrete random variables are defined using a Probability Mass Functions(PMF), denoted as π(x). Continuous random variables are defined using Probability Density Functions (PDF), denoted as f(x).  Share your understanding of random variables. Can you determine some of the random processes around you? Why do you think they are random?  ➢  A random variable could be a variable whose value is subject to randomness or instability. In probability theory and statistics, irregular factors are utilized to demonstrate phenomena whose results are not deterministic but rather have a few degree of unusualness.  A basic explanation of a probability distribution is that it may be a function that links each result of a statistical experiment with its probability of occurrence.   Bernoulli distribution could be a discrete distribution and defined for a binary random variable with values X = 0 and X = 1.  Uniform distribution can be defined for both discrete and continuous random variables.  Normal distribution is defined for continuous random variables. It is by far the most popular distribution.  The central limit theorem states that if you have a population with mean µ and standard deviation.  Data wrangling, also known as data munging, is the method of cleaning, changing, and organizing a dataset to form it appropriate for analysis. This regularly includes a combination of manual and automated processes, and it could be a vital step in the data science pipeline.  Data representation is an vital step towards making models from large scale data. Machine Learning requires data to be portrayed by ‘features’ called attributes or parameters before use. Choosing the proper features is vital to creating a useful model.  The technique described in the video is a popular model used to encode text data. What are some of its limitations?  ➢  The bag-of-words representation is a broadly used model for encoding text data in  natural language processing (NLP), but it has several limitations, such as:    Loss of ordering and context   High dimensionality   Sparsity   Lack of semantic meaning  In machine learning, include extraction is one of the key steps. As we already know, which means a full representation of data is considered information.  Data refers to any collection of facts, figures, or statistics that can be analyzed and used to draw conclusions, make decisions, or provide experiences. In the context of computing and technology, data can take numerous diverse forms, including text, images, audio, video, and more. A signal is commonly referred to as a sign or gesture which conveys certain data. However, in digital electronic or signal processing, the flag is considered as the quantity that changes over a parameter such as space or time.  In machine learning, scaling refers to the method of converting a set of values to a new range of values. Normalization could be a scaling method utilized to convert the values of a dataset into a common range.  Then we looked into python coding in relate to this topic and did some practices.  