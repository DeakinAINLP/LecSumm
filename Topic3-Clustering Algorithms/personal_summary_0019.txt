Tristen Clifton 221211319 SIT307 (Topic 2)  Summarize the main points that is covered in this topic.  Statistics is process of collecting and analyzing data.  A random experiment is an experiment where the outcome cannot be predicted with certainty.  Events are the possible outcomes of a random experiment.  Probability is the likelihood that an event will occur.  Joint probability is the probability of a sequence of events.  Conditional probability is the likelihood of something happening given the occurrence of another event.  Random variables can either be discrete (solid numbers EG dice faces) or continuous (time something takes, heights Etc.)  Bernoulli distribution is the discrete probability distribution of a random variable.  Noted as  Uniform distribution is probably distribution where all probabilities are evenly distributed.  For discrete  And continuous  Normal distribution is defined exclusively for continuous fandom variables and is defined as          Data wrangling or data munging is the process of of cleaning, transforming, and organizing a dataset to make it suitable for analysis.  To make use of images for computer processing, the images need to be turned into numbers, this is done by defining features as numbers that can then be recognised by a computer. This can be done by defining features such as colour shapes m texture and radiance as numerical values rather than just blocks of colour.  In the same way, text documents can be represented by numbers by counting how frequently certain words appear in the text, this is known as the bag of words method.  When information is organized manor, it is known as data.  A signal is when data is being transferred from one source to another,  Encoding is the process of converting quantitative values such as town names into numbers so it can be recognized by a machine.  Provide summary of your reading list – external resources, websites, book chapters, code libraries, etc.  https://thispointer.com/count-number-of-zeros-in-pandas-dataframe-column/  https://www.geeksforgeeks.org/how-to-get-column-names-in-pandas-dataframe/  https://sparkbyexamples.com/pandas/pandas-get-column-average-mean/  https://stackoverflow.com/questions/21608228/conditional-replace-pandas  https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html  Reflect on the knowledge that you have gained by reading contents of this topic with respect to machine learning.  This topic was mostly revision as I have covered the basic concepts of data wrangling from other subjects, however the idea and process of feature extraction was a new concept. It make a lot of sense to me that information such as pictures would need to be made machine readable but I was unsure of the exact process. The idea of using feature extraction to convert colors / light intensity to assign values to a grid makes a lot of sense when using numbers to compare 2 pictures together.  Attempt the quiz given in topicly content (2.16) and add screenshot of your score (³ 85% is considered completion of the task) in this report.      Topic 2 Problem Solving  March 20, 2023  0.1 Tristen Clifton : 221211319 : Topic 2 Activitiy  0.1.1 Task explanation  In this topics activity I am tasked with taking some data collected from paitent records in the from of a CSV file and importing them into python, From there i am required to do some data wrangling and finnaly create some visualisations of the data to extract information from the dataset and present it in graphical form  0.1.2 Read “train_wbcd.csv” and print the feature name with numbers of missing  entries.  [39]: import pandas as pd  import numpy as np df = pd.read_csv('train_wbcd.csv') df.info()  <class 'pandas.core.frame.DataFrame'> RangeIndex: 100 entries, 0 to 99 Data columns (total 32 columns):  # --- 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  Column ------ Patient_ID 100 non-null 100 non-null Diagnosis 100 non-null f1 100 non-null f2 100 non-null f3 100 non-null f4 100 non-null f5 100 non-null f6 100 non-null f7 100 non-null f8 100 non-null f9 100 non-null f10 100 non-null f11 100 non-null f12 100 non-null f13 100 non-null f14 100 non-null f15 100 non-null f16  Non-Null Count Dtype -------------- ----- int64 object float64 float64 float64 float64 float64 float64 float64 float64 float64 float64 float64 float64 float64 float64 float64 float64  1  18 19 20 21 22 23 24 25 26 27 28 29 30 31  f17 f18 f19 f20 f21 f22 f23 f24 f25 f26 f27 f28 f29 f30  float64 float64 float64 float64 float64 float64 float64 float64 float64 float64 float64 float64 float64 float64 dtypes: float64(30), int64(1), object(1) memory usage: 25.1+ KB  100 non-null 100 non-null 100 non-null 100 non-null 98 non-null 100 non-null 100 non-null 100 non-null 100 non-null 100 non-null 100 non-null 100 non-null 100 non-null 100 non-null  [40]: def CountZeros(dataFrame):  for feature in dataFrame.columns:  print("Feature Name : "+str(feature) + ", Number of Missing entries : "␣  ↪+ str((df[feature] == 0).sum()))  CountZeros(df)  Feature Name : Patient_ID, Number of Missing entries : 0 Feature Name : Diagnosis, Number of Missing entries : 0 Feature Name : f1, Number of Missing entries : 0 Feature Name : f2, Number of Missing entries : 0 Feature Name : f3, Number of Missing entries : 0 Feature Name : f4, Number of Missing entries : 0 Feature Name : f5, Number of Missing entries : 0 Feature Name : f6, Number of Missing entries : 0 Feature Name : f7, Number of Missing entries : 6 Feature Name : f8, Number of Missing entries : 6 Feature Name : f9, Number of Missing entries : 0 Feature Name : f10, Number of Missing entries : 0 Feature Name : f11, Number of Missing entries : 0 Feature Name : f12, Number of Missing entries : 0 Feature Name : f13, Number of Missing entries : 0 Feature Name : f14, Number of Missing entries : 0 Feature Name : f15, Number of Missing entries : 0 Feature Name : f16, Number of Missing entries : 0 Feature Name : f17, Number of Missing entries : 6 Feature Name : f18, Number of Missing entries : 6 Feature Name : f19, Number of Missing entries : 0 Feature Name : f20, Number of Missing entries : 0 Feature Name : f21, Number of Missing entries : 0 Feature Name : f22, Number of Missing entries : 0  2  Feature Name : f23, Number of Missing entries : 0 Feature Name : f24, Number of Missing entries : 0 Feature Name : f25, Number of Missing entries : 0 Feature Name : f26, Number of Missing entries : 0 Feature Name : f27, Number of Missing entries : 6 Feature Name : f28, Number of Missing entries : 6 Feature Name : f29, Number of Missing entries : 0 Feature Name : f30, Number of Missing entries : 0  0.1.3 Fill in the missing entries. For filling any feature, you can use either the mean or median value of the feature values from observed entries. Explain the reason behind your choice and print replacement value of each feature.  [62]: for feature in df.columns[2:]:  mean = df[feature].mean() print("Feature : "+str(feature)+" Mean value: " + str(mean)) df.loc[df[feature]==0,feature] = mean  CountZeros(df)  Feature : f1 Mean value: 14.225920000000004 Feature : f2 Mean value: 19.2079 Feature : f3 Mean value: 92.72259999999999 Feature : f4 Mean value: 666.375 Feature : f5 Mean value: 0.09569570000000001 Feature : f6 Mean value: 0.10612939999999994 Feature : f7 Mean value: 0.09578558559999996 Feature : f8 Mean value: 0.05230697199999998 Feature : f9 Mean value: 0.17989299999999997 Feature : f10 Mean value: 0.0627905 Feature : f11 Mean value: 0.39530800000000005 Feature : f12 Mean value: 1.2281610000000005 Feature : f13 Mean value: 2.8304389999999997 Feature : f14 Mean value: 39.19528999999999 Feature : f15 Mean value: 0.00701167 Feature : f16 Mean value: 0.02602664 Feature : f17 Mean value: 0.03360152300000001 Feature : f18 Mean value: 0.012298904400000003 Feature : f19 Mean value: 0.02018859000000001 Feature : f20 Mean value: 0.00365038 Feature : f21 Mean value: 16.486765306122457 Feature : f22 Mean value: 25.380800000000004 Feature : f23 Mean value: 108.9252 Feature : f24 Mean value: 909.1910000000004 Feature : f25 Mean value: 0.13256349999999997 Feature : f26 Mean value: 0.2651438999999998 Feature : f27 Mean value: 0.29486677200000005 Feature : f28 Mean value: 0.12465282000000003  3  Feature : f29 Mean value: 0.28919599999999995 Feature : f30 Mean value: 0.08399879999999998 Feature Name : Patient_ID, Number of Missing entries : 0 Feature Name : Diagnosis, Number of Missing entries : 0 Feature Name : f1, Number of Missing entries : 0 Feature Name : f2, Number of Missing entries : 0 Feature Name : f3, Number of Missing entries : 0 Feature Name : f4, Number of Missing entries : 0 Feature Name : f5, Number of Missing entries : 0 Feature Name : f6, Number of Missing entries : 0 Feature Name : f7, Number of Missing entries : 0 Feature Name : f8, Number of Missing entries : 0 Feature Name : f9, Number of Missing entries : 0 Feature Name : f10, Number of Missing entries : 0 Feature Name : f11, Number of Missing entries : 0 Feature Name : f12, Number of Missing entries : 0 Feature Name : f13, Number of Missing entries : 0 Feature Name : f14, Number of Missing entries : 0 Feature Name : f15, Number of Missing entries : 0 Feature Name : f16, Number of Missing entries : 0 Feature Name : f17, Number of Missing entries : 0 Feature Name : f18, Number of Missing entries : 0 Feature Name : f19, Number of Missing entries : 0 Feature Name : f20, Number of Missing entries : 0 Feature Name : f21, Number of Missing entries : 0 Feature Name : f22, Number of Missing entries : 0 Feature Name : f23, Number of Missing entries : 0 Feature Name : f24, Number of Missing entries : 0 Feature Name : f25, Number of Missing entries : 0 Feature Name : f26, Number of Missing entries : 0 Feature Name : f27, Number of Missing entries : 0 Feature Name : f28, Number of Missing entries : 0 Feature Name : f29, Number of Missing entries : 0 Feature Name : f30, Number of Missing entries : 0  I replaced the values with mean as it would cause less of a change to the existing mean than if i had chosen to use median  0.1.4 Encode the categorical variable “Diagnosis” using an appropriate encoding ap- proach and display the encoded values. Justify your selection of encoding ap- proach. Save the modified data into a csv file. Upload this new file with your submission in OnTrack.  [68]: from sklearn.preprocessing import LabelEncoder  label_encoder = LabelEncoder() integer_encoded = label_encoder.fit_transform(df["Diagnosis"]) df["interger label"]=integer_encoded print(df[0:3])  4  Patient_ID Diagnosis  0 1 2  909410 84358402 8912284  f4 f2 f1 B 14.02 15.66 606.5 M 20.29 14.34 135.10 1297.0 516.6 B 12.89 15.70  f3 89.59  84.08  f5  f6 \  0.07966 0.05581 0.10030 0.13280 0.07818 0.09580  f7  f8 …  f23 f22 0 0.02087 0.02652 … 19.31 96.53 1 0.19800 0.10430 … 16.67 152.20 92.12 2 0.11150 0.03390 … 19.69  f24  f25 688.9 0.10340 1575.0 0.13740 595.6 0.09926  f26 0.1017 0.2050 0.2317  f27 0.0626 0.4000 0.3344  \  f28  f29  0 0.08216 0.2136 0.06710 1 0.16250 0.2364 0.07678 2 0.10170 0.1999 0.07127  f30 interger label 0 1 0  [3 rows x 33 columns]  0.1.5 Apply the min-max scaling on features f1 to f30. Plot distribution of first six features before and after scaling. Is there any difference? Please explain.  There is no difference as i Scaled the values evenly and they are plotted as a histogram, the values would appear different if i used a bar graph instead as i have essentially reduced the scale of the difference between the values  [92]: X = df.loc[:, 'f1':'f30']  Xsc = X-X.min()/X.max()-X.min()  print(X.loc[0:4, 'f1':'f7'])  print(Xsc.loc[0:4, 'f1':'f7'])  f1  f4  f3 89.59  f5 f2 14.02 15.66 606.5 0.07966 20.29 14.34 135.10 1297.0 0.10030 516.6 0.07818 12.89 15.70 321.6 0.09996 10.26 12.22 538.7 0.07335 13.16 20.54  84.08 65.75 84.06 f2  f6 0.05581 0.13280 0.09580 0.07542 0.05275 f4  f7 0.02087 0.19800 0.11150 0.01923 0.01800 f5  f1  f3 5.984537 4.506769 41.330233 12.254537 3.186769 86.840233 4.854537 4.546769 35.820233 2.224537 1.066769 17.490233 5.124537 9.386769 35.800233  1118.104792 -0.48761  f6 427.604792 -0.50825 -0.042903 0.034087 337.704792 -0.50973 -0.002913 142.704792 -0.48795 -0.023293 359.804792 -0.51456 -0.045963  f7 0.011644 0.188774 0.102274 0.010004 0.008774  0 1 2 3 4  0 1 2 3 4  [93]: X = X.loc[:, 'f1':'f6']  Xsc =Xsc.loc[:, 'f1':'f6']  5  import matplotlib.pyplot as plt X.hist() plt.tight_layout() plt.show()  import matplotlib.pyplot as plt Xsc.hist() plt.tight_layout() plt.show()  6  [94]: df.to_csv("modified_train_wbcd.csv",index=None)  [ ]:  7   