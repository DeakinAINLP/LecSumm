 This topic’s lecture in Machine Learning unit discussed data wrangling. We learned:  -  Random  variables  and  probability.  Random  variables  which  could  be  discrete  or continuous,  are  variables  that  are  the  generated  from  a  random  process.  Discrete variables uses probability mass functions to describe their behavior while continuous variables uses probability density functions. Probability is defined as the likelihood on an event to occur.  -  Examples  of  random  variables  distributions:  Bernoulli,  uniform,  and  normal distributions.  Normal  distribution  is  the  most  common  distribution  as  it  describes many natural phenomena.  -  Some of the main tasks that are done in data wrangling:  o  Feature extraction and representing data numerically such as images and texts. For  example,  images  could  be  subdivided  into  smaller  images  and  features such as averaged colour, shapes, and brightness.  o  o  Encoding, which is representing qualitative features such “good” and “bad” in quantitative values. For example, “good” and “bad” could be represented as 0 and 1. Scaling which a process that modifies the value range of a certain feature. This is done in cases where multiple features with different value ranges are to be used. By scaling the features into a common range, for example, 0 to 1, then we avoid having one feature being more dominant than the rest. -  Appling some key data wrangling tasks using python and pandas library. This included reading data frames from csv files and filling any missing values in the file, plotting the distribution of the data frame features, encoding any qualitative features into numeric values, and scaling and normalizing data frame features to unify their range.  