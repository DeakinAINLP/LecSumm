Probability: A measurement of an event that might or might not have occurs  P(A) → Probability of event A occurring  P(A) = Outcome / Total Outcome  P(A) = 1 - P(A) → Probability of event A not occuring  Joint Probability: A measurement of the probability of two event happening at the same time  P(A and B) → Joint probability of A & B  P(A and B) = P(A) P(B)  Conditional Probability: Probability of an even happening given the occurrence of another event have already happen  P(A|B) → Conditional probability of event A when event B already occurs  P(A|B) = P(A and B) / P(B)  Bayes Rule: Measurement of probability base on new / pass occurrence as evidence  Random Variables: Measure of outcomes that happens randomly There are 2 types of Random Variables ● Discrete random variables  ○ Can be count as there have infinite number  ● Continuous random variables  ○ Can take values variable that in any specific range / interval  Distribution of random variables: Explain how the probabilities are distribute across the values of random variables  Bernoulli distribution: Define the probability (discrete probability )of only 2 possible outcomes. Pass or Fail  Uniform distribution: Define both discrete and continuous probability.  Normal distribution: Define continuous probability that are very often use in data analysis.  Reference: https://link.springer.com/referenceworkentry/10.1007/978-0-387-32833-1_50#:~:text=The%20centr al%20limit%20theorem%20is,approximately%20follows%20a%20normal%20distribution.  Data Wrangling: Process of clean, changing and making sure the data are ready to be analysis 1. Cleaning Data (remove duplicates, fixing missing data, remove weird / wrong data) 2. Transforming Data (make sure the data information are consistent) 3. Aggregation Data (store data that match certain criteria / suitable for analysing and  summarise them into useful information)  Image as Data & Feature extraction  How to use images in computer algorithms ?  1. Turn image into input that the computer understand by turning the image into numeric  vector of feature (set of numbers)  2. Divide the image into smaller blocks (pixels) 3. Each block can represent a feature (tails, colours, head, etc..) 4. The blocks also can compute the mean, variance, other statistic  For example one image divide into 100 blocks  ● One feature per block is = 100p ( p = feature) ● The size if feature matrix = 135p x n (n= number of image) ● So if there are 65 image to sort and 5 feature to find the equation will be:  ○ 100 x 65 x 5  Text Data representation ● Again, the computer doesn't understand text data / images. Therefore the information like  the text data need to be converted into numerical / categorical format data.  ● Machine learning need the data to be describe by attributed (features) / parameters  How does Bag of Words Methods ( for text representation) are used ?  1. Process data (change all letter into lowercase, remove punctuations / stop words) 2. After processing a list of only unique words are created 3. The list of how many times of each unique word will be created with matrix form  Example:  Sentence 1: Monkey is not an animal. I do not what is it  Uniques word  Count  ● monkey ● not ● an ● animal ● do ● What ● it  monkey - 1 |not - 2 | an - 1 | animal - 1 | do - 2 | what - 1 | it - 1  Sentence 2: Monkey like eating mango  Uniques word  Count  Matrix  ● monkey ● like ● eating ● mango  monkey - 1 | like - 1 | eating - 1 | mango - 1  A =  1 2 1 1 2 1 1 0 0 0 0  1 0 0 0 0 0 0 1 1 1 1  Encoding and Distribution  Encoding: Technique used to convert data from one form to another. For example turning “true” and “false” into 1 and 2 (binary)  Encoding approach for Categorical Variables:  ● One-Hot encoding: ● Ordinal Encoding: ● Binary Encoding: ● Label Encoding:  Distribution: A way when a data / value is more distributed (average / mean). For example using the mean / average of data set and create a visualisation such as graph  Scaling: Changing data / set of values into range of values  Scaling and Normalisation  Normalisation: Change data / set of value into common / standard range   