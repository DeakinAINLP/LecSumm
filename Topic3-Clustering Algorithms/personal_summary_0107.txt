 Topic 2 : Data Wrangling - Evernote  Topic 2 : Data Wrangling Random experiment : A process for which the outcome cannot be predicted with certainty.  Event : Set of outcomes of a random experiment.  Probability : It is a measure of the likelihood of an event to occur. Its a number between 0 to 1.  Joint Probability :  Conditional Probability : It is the probability of some event A,  given the occurrence of another event B.  Bayes Rule : Bayes' Theorem states that the conditional probability of an event, based on the occurrence  of another event, is equal to the likelihood of the second event given the first event multiplied by the  probability of the first event.  Random Variable : Its a variable whose possible values are the generated outcomes of a random  phenomenon. Random variables can be classified as Discrete random variable and Continuous random variable.  Discrete Random Variables : They have a countable number of values. eg. faces of a dice, number of emails received in an hour etc.  Continuous Random Variables : They can take infinite number of values. eg. height of a person, time to  failure etc.  Probability distributions : It is a function that links each outcome of a statistical experiment with its probability of occurrence. Some examples of probability distributions are Bernoulli distribution, Uniform  Distribution and Normal Distribution.  Central limit theorem : It states that the distribution of sample means approximates a normal distribution as the sample size gets larger, regardless of the population's distribution. Sample sizes equal to or greater than 30 are often considered sufficient for the CLT to hold.  Data Wrangling : Its a process of cleaning, transforming, and organising a dataset to make it suitable for analysis. Steps involved in data wrangling are as follows :    Identifying and correcting errors and inconsistencies in the data. Handling missing or incomplete values.  Combining multiple datasets. Converting the data into a format that is suitable for analysis. Identifying and removing outliers. Normalising the data Aggregating the data into useful summary statistics.  https://www.evernote.com/client/web?login=true#?n=e8f6b39c-d7d2-ccce-ca3d-f7f3a8c75143&  1/3   Topic 2 : Data Wrangling - Evernote  Encoding : Its the technique used to convert categorical values into integer values. There are different  types of encoding like OrdinalEncoder, One-Hot Encodings and LabelEncoder.  Distribution : Different types of distributions that occur in a dataset are as follows  Normal Distribution : It is the most common and is characterised by a bell-shaped curve symmetrical  around the data's mean.  Uniform Distribution : In this, the values are distributed evenly across the range of the data.  Skewed Distribution : In this, the values are not evenly distributed and are instead concentrated on  one side of the range.  Scaling : Process of converting a set of values to a new range of values. It is important to scale the  features in a dataset to a certain range to ensure that no single feature totally dominates over other  features just because their numerical value is higher.  Normalisation : Its a scaling technique used to improve the performance of machine learning algorithms.  One common method of normalisation is min-max  normalisation, where the data is scaled to a range of 0 to 1, where 0 is the minimum value in the dataset and 1 is the highest value.  https://www.evernote.com/client/web?login=true#?n=e8f6b39c-d7d2-ccce-ca3d-f7f3a8c75143&  2/3   Topic 2 : Data Wrangling - Evernote  https://www.evernote.com/client/web?login=true#?n=e8f6b39c-d7d2-ccce-ca3d-f7f3a8c75143&  3/3   