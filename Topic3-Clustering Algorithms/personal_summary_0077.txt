   Feature vectors and matrices   Feature Vectors:  o  A numerical representation of a set of features that describe a specific entity,  o  such as a document or an image. In text data, each dimension of the vector represents a specific term, and the value of the dimension represents the frequency or importance of that term in the document.  o  The vector space model is a widely used approach to represent text data as  feature vectors.  o  Enables mathematical techniques to analyze and compare documents, such as  cosine similarity.    Feature Matrices:  o  A feature matrix extends the concept of feature vectors by stacking feature  vectors as a matrix X.  o  Each row represents an instance, and each column represents a feature. o  Enables us to perform operations such as matrix multiplication, which can be  used to compute similarities between instances or to train models.  o  Provides a convenient way to visualize the data, as each instance can be plotted  as a point in a high-dimensional space defined by the features.    Probability Concepts  o  Random Experiment & Event o  Joint probability Joint probability refers to the likelihood of two or more events occurring simultaneously. In a scenario where two coins are tossed, the joint probability of obtaining heads on both coins is an example of two independent events. If events A and B are independent, their joint probability can be calculated as P(A and B) = P(A)P(B). o  Conditional probability What is the probability of some event A, given the occurrence of another event B.  o  Bays Rules probability of an event A based on another event B that is related to A    Random variable  o  Discrete Random Variable; o  Continuous Random Variable.    Data Wrangling        o  Data wrangling, also known as data munging, is a crucial step in the data science  pipeline that involves cleaning, transforming, and organizing datasets for analysis. Key aspects of data wrangling include:  o  Missing value replacement: Null values can hinder machine learning models, so they must be replaced using methods such as imputation with immediate value, mean, or median.  o  Scaling or normalization: This technique standardizes the range of dataset values,  often leading to better performance in machine learning algorithms. o  Non-numeric data encoding: Categorical values need to be converted to numerical form using encoding techniques like OrdinalEncoder, One-Hot Encodings, or LabelEncoder for machine learning models to process them effectively.  