Machine Learning Unit  Topic 2 Key Learning Points    Random experiment, Joint Probability and Condition Probability and how Bayes rule helps to  calculate the conditional probability for events A and B    Random Variables: random variables are generated in our random experiments when it can take  several different values. There are two types of random variables:  o  Deseret: the variables can be countable (such as rolling a toss) o  Continues: the variables belong to a continues interval and not countable (from the Real  Numbers)    Cumulative Distribution Function (CDF): The cumulative distribution function gives us the  cumulative probability associated with a probability function, for example when we want to calculate the probability of less than 5 in a dice experiment. For the Discrete variables, this function is calculated using the sigma summation and for continues variables, it uses the integrals    Distribution of random variables: the probability distribution of random variables represents the outcome of each experiment. Depending on the nature of the experiment, there is different types of distribution functions. It includes but not limited to Bernoulli distribution, Uniform and Normal functions    Central Limit Theorem, this theorem proves that if we have large random experiment from the existing population, then the distribution of the sample means will approximately match a normally distributed    Data wrangling: to prepare the data before analyzing or modelling it  Identifying and correcting errors and inconsistencies in the data  o o  Handling missing or incomplete values (different methods_ o  Combining multiple datasets o  Converting the data into a format that is suitable for analysis o o  Normalizing the data (to have all variables values from a consistent scale) o  Aggregating the data into useful summary statistics  Identifying and removing outliers  