It is possible to measure uncertainty and revise probabiliGes depending on new evidence by using probability concepts like random experiments, events, joint and condiGonal probability, and Bayes' rule. To describe the probability of various values, random variables and their distribuGons are used. Data preparaGon techniques include data wrangling, missing value replacement, scale or normalisaGon, and non-numeric data encoding. Feature vectors and matrices are mathemaGcal representaGons of data points. These ideas are fundamental to comprehending staGsGcal models as well as machine learning algorithms, and they are widely applied in many Ô¨Åelds, including predicGon, data analysis, and decision- making.  In machine learning, probability theory is a key idea. Working with staGsGcal models and making predicGons require an understanding of probability concepts including random experiments, occurrences, joint probability, condiGonal probability, and Bayes Rules. Machine learning relies on random variables because they enable us to express uncertain values in a probabilisGc framework. Understanding random variable distribuGon is essenGal for accurate data modelling and analysis. The preparaGon of data for analysis requires the use of data wrangling techniques such missing value replacement, scaling, normalisaGon, and non-numeric data encoding. These methods aid in ensuring that the data is correct, clean, and in a format that machine learning algorithms can use.   