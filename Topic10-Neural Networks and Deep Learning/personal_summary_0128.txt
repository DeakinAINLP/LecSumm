The main points that were covered and taught this topic is around the random forest and the various boost algorithms out there. For example, we covered gradient boosting and adaboost. We also covered how to implement these algorithms, and general knowledge about ensemble learning and various techniques that can be used to gather predictions from ensemble learning models such as voting and stack classifiers.  