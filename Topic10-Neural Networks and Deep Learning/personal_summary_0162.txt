Ensemble learning is a prominent machine learning approach in which numerous individual models, known as base models or weak learners, are combined to increase overall prediction performance. The assumption behind ensemble learning is that by combining the predictions of numerous models, the final forecast will be more accurate and resilient than any single model.  Bootstrap estimation is a statistical resampling technique used to evaluate the variability and uncertainty associated with a statistical estimator or model. It is a non-parametric method for approximating a statistic's sampling distribution by creating repeated resamples from the original dataset.  AdaBoost (Adaptive Boosting) is a common ensemble learning technique that combines numerous weak learners (often decision trees) to generate a strong learner. Yoav Freund and Robert Schapire invented it in 1996.  AdaBoost's fundamental principle is to train weak learners iteratively on various weighted copies of the training data, with the weights modified at each iteration to focus on previously misclassified examples. This technique enables poor learners to gradually learn from their errors and improve their performance.  Bagging, also known as Bootstrap Aggregating, is an ensemble learning approach that combines predictions from many independently trained models to increase the accuracy and resilience of machine learning models. Bagging, unlike AdaBoost, takes a parallel method by training each base model on distinct bootstrap samples of the training data.  The Random Forest algorithm is an ensemble learning approach that makes predictions by combining numerous decision trees. Leo Breiman initially proposed it in 2001, and it has since become a popular and strong method in machine learning.  The OOB error is a statistic that is used to assess the performance of a Random Forest model in the absence of a separate validation set. It makes use of Random Forest's bootstrap sampling mechanism. Some samples from the original training set are left out (not included in the bootstrap sample) during the development of each decision tree in the ensemble and are referred to as out-of- bag samples. These out-of-bag samples may be used to assess the overall performance of the trees.  The OOB error is determined by aggregating each tree's predictions on out-of-bag samples and comparing them to the real labels. This aggregated error estimates how well the Random Forest model will perform on unknown data. For model selection and hyperparameter adjustment, the OOB error might be a valuable statistic. It indicates the model's generalisation ability and may be used to compare different Random Forest designs.  