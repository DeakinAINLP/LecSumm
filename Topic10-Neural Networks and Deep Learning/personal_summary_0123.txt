 The topics that were covered during topic 9 were concepts focusing on Ensemble learning, Bootstrap estimation, AdaBoost, Bagging, Random Forest algorithm, out of bag error and feature. Then, implementation of random forest and boosting in python.  I referred to the unit site contents for learning the topics that were covered in topic 9 along with the external video links and articles provided.  The learning journey started with the basic understanding of Ensemble learning, which is the process by which multiple models are generated strategically and combined to solve particular computational intelligence problems. I gained an idea on the concept of Bootstrap estimation which is a bootstrap sample is a smaller sample that is generated from larger sample. Then, I gathered knowledge about Adaptive Boosting(AdaBoost) which is an algorithm for classification problems. Then, learnt about Bagging(Bootstrap aggregation) which is used for reducing the variance of statistical learning methods. I gained an understanding of Random Forest classifier which creates a set of decision trees from randomly selected subsets of the training dataset, then aggregates the votes from different decision trees to decide the final class of the test objects. Then, out of bag error and feature importance along with advantages/Disadvantages of Random Forest was learnt. Finally, I acquired knowledge on implementation of Random Forest in python , boosting methods in python.   