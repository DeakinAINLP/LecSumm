  The primary topics that were covered during topic 9 included concepts focusing on Ensemble learning, Bootstrap estimation, Bagging, AdaBoost, Random Forest model, out of bag error and some associated topics. On the programming side, we covered the implementation of random forest model and adaboost using python. The main source of reference was unit site contents for topic 9 along with the external videos and article links provided.  The topicâ€™s topic began with the introduction of Ensemble learning, which basically is the process using which multiple models are generated strategically and combined to solve a particular computational intelligence problem. Next, I gained an understanding of the concept of Bootstrap estimation and bootstrap sample, which is a smaller sample that is generated from larger sample. Then, I explored the topic of Adaptive Boosting(AdaBoost) which is an widely used algorithm for classification problems. Next, I gained a basic understanding of Bagging(Bootstrap aggregation) which is aimed at reducing the variance of statistical learning methods. I also learnt about Random Forest classifier which basically creates a set of decision trees from randomly selected subsets of the training dataset, which then aggregates the votes from different decision trees to the final class of the test objects. During the final phase, the topic of out of bag error and feature importance was covered along with advantages/Disadvantages of Random Forest model and to boost my programming skills, I learnt to successfully implement Random Forest and boosting in python.       