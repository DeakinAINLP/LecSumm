 Ensemble method: An ensemble method is a machine learning technique that combines multiple base models to create a single optimized predictive model.  Bootstrap sample: In statistics, a bootstrap sample refers to a smaller sample that is generated by resampling from a larger sample. It is used to estimate properties of the larger population or to assess the variability of a statistical estimate.  AdaBoost: AdaBoost is a machine learning algorithm primarily used for classification tasks. It involves combining multiple weak classifiers to create a strong classifier that can make accurate predictions. AdaBoost assigns higher weights to misclassified instances, allowing subsequent weak learners to focus on the difficult examples and improve overall performance.  Bagging: bagging uses multiple classifiers trained on different under-sampled subsets and then allows these classifiers to vote on a final decision.  Advantages/Disadvantages of Random Forest:  fully parallelizable since you can run trees in parallel to go even faster!     ability to handle data without pre-processing.   data does not need to be rescaled, transformed, or modified! (Resistant to outliers)   automatic handling of missing values (a property of decision trees)   less interpretable results than a single decision tree.  