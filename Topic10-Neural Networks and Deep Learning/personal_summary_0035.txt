Learning Summary: Nonlinear models (Boosting and random forest) SIT307 Machine Learning  Summary This topic’s unit continued to look at nonlinear models, specifically boosting and random forest. The unit in introduced the concept of Ensemble learning; a technique used to combine multiple models together to get more accurate results. Bootstrap estimation was the next component introduced in the unit; it is a resampling method, that uses bootstrap samples generated from a larger sample set to reduce variance. The unit covered the AdaBoost algorithm which combines weak classifiers to create strong classifiers. Bagging was the final component that the unit covered, a technique that uses multiple classifiers to process the data and a voting method to determine the final outcome. All of these techniques can be applied in various situations to create Ensemble learning solutions.  Random Forest is a commonly used ensemble learning method based on Bagging. The method creates multiple decision trees from randomly select subsets of the training data, then aggregates their votes to come to the final decision. Out-of-bag error is an instance of the train data that is not used to build one of the trees and can be used to estimate the performance of the model. The Random Forest method is popular because it is fast and efficient and does not require significant preprocessing. The technique can handle missing values and can be used to identify important features. The biggest problem with this method is the use of multiple decision trees makes it hard to interpret or explain the results.  As with each of the units, the final part of this topic’s content focused on applying random forest and boosting with Python.  Reading List What is Random Forest?, IBM Technology, https://www.youtube.com/watch?v=gkXX4h3qYm4, Accessed on 20 May 2023  Reflection This topic’s unit content was completely new, and quite interesting. The unit content was significantly shorter than previous topics. When working through the Python part of this unit it seemed like there was information missing as the content jumped significantly. There are numerous online resources that cover these topics as such it didn’t have a massive impact.  