Boosting methods are built sequentially, and one tries to reduce the bias of the combined estimator. The motivation is to combine several weak models to produce a powerful ensemble. More details AdaBoost AdaBoost Conde example#1 Require library for AdaBoost classifier from sklearn.ensemble import AdaBoostClassifier from __future__ import print_function from ipywidgets import interact, interactive, fixed, interact_manual from IPython.display import clear_output, display import ipywidgets as widgets Code Example#2 Train the AdaBoost model with a number of estimators is 110 and a learning rate  is 0.1 def f(n_estimators,learning_rate):     abc =AdaBoostClassifier(n_estimators=n_estimators,learning_rate=learning_rate, random_state=0)     abc.fit(X_train, y_train)     pred = abc.predict(X_test)     conmat(y_test, pred)     print('The accuracy of the RF classifier on test data is {:.2f} out of 1 '.format(abc.score(X_test, y_test))) interact(f,learning_rate=np.arange(0.1,1,0.1),n_estimators=np.arange(10,800,100)); Output; Example#2 Train the AdaBoost model with a number of estimators is 210 and a learning rate  is 0.4 AdaBoost, which stands for Adaptive Boosting, is a machine-learning algorithm for classification problems. It works by combining weak classifiers to create a strong classifier. The algorithm has the following steps: Inputs: X: dataset of features y: vector of corresponding labels (+1 or -1) T: number of iterations (i.e., number of weak classifiers to train) Outputs: List of weak classifiers, each with an associated weight Step 1: Initialize weights   w i  =  1 N     for each  i ∈  1 , 2 , . . . , N  {"version":"1.1","math":"w_i = \frac{1}{N} \qquad \text{for each } i \in {1, 2, ..., N} "} Step 2: Train weak classifier   Step 3: Evaluate classifier    e r r o  r t  =  ∑  i = 1   N    w i  ⋅ [  h t  (  x i  ) ≠  y i  ] {"version":"1.1","math":"error_t = \sum_{i=1}^{N} w_i \cdot [h_t(x_i) \neq y_i] "}Step 4: Calculate classifier weight     α t  =  1 2  l o g  (   1 − e r r o  r t    e r r o  r t    )  {"version":"1.1","math":"\alpha_t = \frac{1}{2} log \left(\frac{1 - error_t}{error_t}\right)"} Step 5: Update weights     w i  =    w i  ⋅  e  −  α t   y i   h t  (  x i  )     Z t      for each  i ∈  1 , 2 , . . . , N  {"version":"1.1","math":"w_i = \frac{w_i \cdot e^{-\alpha_t y_i h_t(x_i)}}{Z_t} \qquad \text{for each } i \in {1, 2, ..., N} "} where Zt{"version":"1.1","math":"<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>Z</mi><mi>t</mi></msub></math>"} is a normalization constant that ensures the weights sum to 1:     Z t  =  ∑  i = 1   N    w i  ⋅  e  −  α t   y i   h t  (  x i  )   {"version":"1.1","math":"Z_t = \sum_{i=1}^{N} w_i \cdot e^{-\alpha_t y_i h_t(x_i)} "} Final output:   H ( x ) = s i g n  (   ∑  t = 1  T   α t   h t  ( x )  )  {"version":"1.1","math":"H(x) = sign\bigg(\sum_{t=1}^T \alpha_t h_t(x)\bigg)"} where:  H(x){"version":"1.1","math":"<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>H</mi><mo>(</mo><mi>x</mi><mo>)</mo></math>"} is the final strong learner that classifies the input vector x{"version":"1.1","math":"<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math>"} T{"version":"1.1","math":"<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi></math>"} is the number of iterations (weak learners) in AdaBoost  ht(x){"version":"1.1","math":"<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>h</mi><mrow><mi>t</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></msub></math>"} is the weak learner at iteration t{"version":"1.1","math":"<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi></math>"} αt{"version":"1.1","math":"<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>&#x3B1;</mi><mi>t</mi></msub></math>"} is the weight assigned to the weak learner at iteration  t{"version":"1.1","math":"<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi></math>"}  sign(z){"version":"1.1","math":"<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>s</mi><mi>i</mi><mi>g</mi><mi>n</mi><mo>(</mo><mi>z</mi><mo>)</mo></math>"} is the sign function that returns +1 if z≥0{"version":"1.1","math":"<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>z</mi><mo>&#x2265;</mo><mn>0</mn></math>"} and -1 otherwise.  References:   SIT307 and SIT720 student must complete the following topic.  Feature importance of using Random forest (RF)  The significance of each feature in the input dataset can also be determined using Random Forest. Based on how much it helps to reduce impurity in the decision trees, the significance of each characteristic is assessed. The higher the contribution, the more important the feature is. To increase the model's performance, feature importance utilising Random Forest can be utilised to find the most pertinent features for classification and feature selection.  References: Kursa, Miron B., and Witold R. Rudnicki. "The all relevant feature selection using random forest." arXiv preprint arXiv:1106.5112 (2011).  Hasan, Md Al Mehedi, et al. "Feature selection for intrusion detection using random forest." Journal of information security 7.3 (2016): 129-140.  Huljanah, Mia, et al. "Feature selection using random forest classifier for predicting prostate cancer." IOP Conference Series: Materials Science and Engineering. Vol. 546. No. 5. IOP Publishing, 2019.   SIT720 student must complete the following topic.  Voting Classifier:  An ensemble learning technique called a voting classifier combines the predictions of various separate classifiers to provide a final prediction. Several types of classifiers, such as Decision Trees, K-Nearest Neighbors, or Support Vector Machines, can be used individually. Each classifier is given one vote, and the final forecast is determined by a majority vote. Voting Classifier can increase prediction accuracy and robustness because it incorporates the benefits of various models while minimising the effects of their particular flaws.  Stack Classifier: Another ensemble learning technique that aggregates the predictions of various separate classifiers is the Stack Classifier, which is more complex than the Vote Classifier. The first layer of a stack classifier comprises multiple separate classifiers that create predictions based on the input data. The second layer then integrates the previous layer's predictions to arrive at a final prediction. Several algorithms might be used at the second layer, including Decision Trees and Logistic Regression. Stack Classifier can increase the prediction's accuracy and generalizability by learning a more complicated decision boundary and minimising the chance of overfitting.  References: Wolpert, David H. "Stacked generalization." Neural networks 5.2 (1992): 241-259.  Breiman, Leo. "Stacked regressions." Machine learning 24 (1996): 49-64.  Yousaf, Anam, et al. "Emotion recognition by textual tweets classification using voting classifier (LR-SGD)." IEEE Access 9 (2020): 6286-6295.  Bagging In contrast to using just one classifier, bagging uses multiple classifiers trained on different under-sampled subsets and then allows these classifiers to vote on a final decision. Bootstrap aggregation or bagging (B+agg), is a general-purpose procedure for reducing the variance of a statistical learning methods. Given a set of n{"version":"1.1","math":"\(n\)"} independent estimates Z1,Z2,…,Zn{"version":"1.1","math":"\(Z_1,Z_2,\dots,Z_n\)"}, each with a variance of σ2{"version":"1.1","math":"\(\sigma^2\)"}, the variance of their mean Z¯=Z1+Z2+...+Znn{"version":"1.1","math":"\(\bar{Z} = \frac{Z_1+Z_2+...+Z_n}{n}\)"} is σ2n{"version":"1.1","math":"\(\frac{\sigma^2}{n}\)"} (n−{"version":"1.1","math":"\(n-\)"}times lower). Note and remember that when the estimates are not independent, reduction in variance is lower. Consider the following figure as an example of bagging. As you can see, different independent classifiers voted for different boundaries (light green), but if you take the aggregation of these boundaries (dark green) it will clean up and improve the final decision boundary. Figure. Bootstrap aggregation or bagging The video above explores how bootstrap sampling works. A bootstrap sample is a smaller sample that is generated (bootstrapped) from a larger sample. It uses a resampling method found in statistics. In many cases bootstrap can result in less variance and more accurate results. View transcript SPEAKER: In this tutorial, I'll be going to show you how bootstrap sampling works. A bootstrap sample is a smaller sample that is bootstrapped from a larger sample. Bootstrapping is a type of resampling from a single original sample, where large numbers of smaller samples of the same size are repeatedly drawn with replacement. So as we said, bootstrap is a resampling method from statistics. It is also often used to get error bars or confidence intervals on estimates. So basically, we are using bootstrapping in order to reduce the variance. Bootstrap samples are generated as follows. First we have a data set with N data instances. The collective knowledge of a diverse and independent body of people typically exceeds the knowledge of any single individual, and can be harnessed by voting. James Surowiecki (2004) Ensemble learning Sometimes your designed classifier on a dataset is weak and inaccurate. You may have designed many classifiers but some of them could be inaccurate and some could perform better on specific occasions. You may have faced this phenomenon in your own machine learning practices. Ensemble learning is the process by which multiple models, such as classifiers or experts, are strategically generated and combined to solve a particular computational intelligence problem. Consider this scenario: We know that a single decision tree might not perform well. But, it is super fast. What if we learn multiple trees? We just have to make sure that they do not all learn the same thing. To reduce the variance of unstable (high variance) learning methods such as decision trees, we can train multiple decision trees, each with slightly different subsets of data. Then when doing classification/regression you take their combined decisions (via averaging for regression or voting for classification). This is called the ensemble method. A popular ensemble method is the Random Forest (Breiman 2001) It has been shown that the variance of these ensemble models are lower. The critical point is to try to design an ensemble model in which you can train different independent models with slightly different subsets of data. The way the data is fed into the models can be challenging. Activity Can you explain why ensemble models have a lower variance compared to other models? Share your thoughts. Out of bag error and feature importance It is possible to estimate the goodness of a bagged model in the same way as every model in machine learning. Out of Bag is equivalent to validation or test data. Each tree in a random forest is trained on a bootstrapped sample. It can be shown that on average, each bagged tree makes use of 23{"version":"1.1","math":"\(\frac{2}{3}\)"} of the training instances. The remaining 13{"version":"1.1","math":"\(\frac{1}{3}\)"} of the instances are referred to as the out-of-bag (OOB) instances. We can predict the response for the i−{"version":"1.1","math":"\(i-\)"}th observation using each of the trees where that observation was OOB. This will yield around B3{"version":"1.1","math":"\(\frac{B}{3}\)"} predictions for the i−{"version":"1.1","math":"\(i-\)"}th observation, which we then average. Figure. Out of bag error and distribution of data As you can see in the above figure, data points are sampled into a training set and unused data points make up a test set. Then we build the random forest by using this training data. Later we can evaluate our model using the unseen test data. Like cross-validation, performance estimation using out-of-bag samples is computed using data that were not used for learning. If the data have been processed in a way that transfers information across samples, the estimate will (probably) be biased. Advantages/Disadvantages of Random Forest Now let’s summarize the important facts about the random forest: random forest is fast to build and even faster to predict! decision tree complexity is O(d×n×log⁡n){"version":"1.1","math":"\(O(d \times n \times \log{n})\)"}. A random forest with T{"version":"1.1","math":"\(T\)"} trees would have O(T×d×n×log⁡n){"version":"1.1","math":"\(O(T \times d \times n \times \log{n})\)"}.  d{"version":"1.1","math":"\(d\)"} is the number of features and n{"version":"1.1","math":"\(n\)"} is the number of data points fully parallelizable since you can run trees in parallel to go even faster! ability to handle data without pre-processing. You are not always required to normalize your dataset before running this method data does not need to be rescaled, transformed, or modified! (Resistant to outliers) Random forest algorithm Based on the bagging decision tree idea, we can define a new method called a random forest. The random forest classifier creates a set of decision trees from randomly selected subsets of the training dataset. It then aggregates the votes from different decision trees to decide the final class of the test objects. The difference between the random forest algorithm and the decision tree algorithm is that in the random forest algorithm, the processes of finding the root node and splitting the feature nodes will run randomly. Random forest builds on the idea of bagging. Each tree is built from a bootstrap sample of data. Node splits are calculated from random feature subsets to make sure each of the trees is as independent as possible. Then we randomly pull out a subset and try work with the subset. Whenever it needs to split to from the tree, based on the best feature, we choose the best feature from the subset. Ultimately you have to do these steps T{"version":"1.1","math":"\(T\)"} times, where T{"version":"1.1","math":"\(T\)"} is the number of the trees. If you are wondering whether this model increases the bias, you are right. It does! It uses subsets of features in different independent trees so it is likely to slightly increase the model bias. A useful rule of thumb states that the number of features is: mtry=Number of features{"version":"1.1","math":"m_{try} = \sqrt{Number \ of \ features}"} In random forest: all trees are fully grown with no pruning we are dealing with two parameters: number of trees (T{"version":"1.1","math":"\(T\)"}); Remember if you raise this value too much and make too many trees, you are likely get trapped in the overfitting problem! number of features mtry{"version":"1.1","math":"\(m_{try}\)"} Let  T{"version":"1.1","math":"\(T\)"} be the number of trees to build. Training For each of T{"version":"1.1","math":"\(T\)"} iterations (T{"version":"1.1","math":"\(T\)"} is the number of trees you may like to build): select a new bootstrap sample from the training set build an un-pruned tree on this bootstrap sample at each internal node of the tree, randomly select mtry{"version":"1.1","math":"\(m_{try}\)"} features and determine the best split using only these features. Testing You can easily output overall prediction as a mean (or majority vote) from all individually trained trees. Now let’s look at the error rate. In random forest, the error rate depends on: Correlation between trees (lower is better) Strength of single trees (higher is better) Increasing number of features for each split: Increases correlation Increases strength of single trees As you can see, like most concepts in machine learning there is a trade-off here. By using more features in creating the trees you are increasing the strength of single trees and increasing the correlation among the trees! Activity Random Forest in Python We will now fit the same titanic dataset (from the previous lesson) using random forest classifier. This model uses an ensemble of decision trees to learn. We can set the number of decision trees (n_estimators) and the depth of the tree (max_depth) among other options. We use a value of n_estimators=300, max_depth=3, and see that it outperforms decision trees. You can change these values and observe how it affects model accuracy. Code example #1 Data preparation import pandas as pd df=pd.read_csv("data/HR-Employee-Attrition.csv") df.head() Output: Class balance checking Code example #2 import seaborn as sns sns.countplot(x='Attrition', data=df) Outout: Removing unnecessary features and class/target convert to integer df.drop(['EmployeeCount', 'EmployeeNumber', 'Over18', 'StandardHours'], axis="columns", inplace=True) categorical_col = [] for column in df.columns:     if df[column].dtype == object and len(df[column].unique()) <= 50:         categorical_col.append(column) df['Attrition'] = df.Attrition.astype("category").cat.codes Output: Train and test data separation from sklearn.model_selection import train_test_split X = df.drop('Attrition', axis=1) y = df.Attrition X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) 