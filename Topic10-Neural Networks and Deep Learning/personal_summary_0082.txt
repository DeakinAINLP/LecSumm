 Ensemble machine learning combines multiple weaker models to create an effective model. Each model is trained on different subsets of data or using different algorithms. The ensemble model combines their predictions for a final decision.  Bootstrapping is the process of taking random samples from a given dataset and using them to train the different models. This helps reduce overfitting and increases performance.  Adaboost is a machine learning algorithm that combines multiple weak classifiers into a strong classifier. Adaboost works by iteratively training weak classifiers on  different subsets of the data. Any misclassifications increase the weights for that iteration. The predictions are combined through weighted voting to create the final strong classifier.  Random forest classifier works similarly to Adaboost, using multiple decision trees to  create the model.  