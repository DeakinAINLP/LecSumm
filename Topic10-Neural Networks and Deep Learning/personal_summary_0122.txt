This is the last second topic of this trimester and I have learned some of the core topics of this unit.  Nonlinear models are powerful techniques used in machine learning for solving complex problems that do not have a linear relationship between the input features and the target variable. In this report, we will explore two popular nonlinear models: Boosting and Random Forest. These models are part of ensemble learning techniques that combine multiple weak models to create a strong predictive model. Boosting: Boosting is a technique that sequentially builds a strong model by combining multiple weak models. Each weak model is trained on a modified version of the dataset, where the misclassified samples from the previous model are given higher importance. The final model is an ensemble of these weak models. Boosting algorithms such as AdaBoost, Gradient Boosting, and XGBoost have achieved great success in various domains.  