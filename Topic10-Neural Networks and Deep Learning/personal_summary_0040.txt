In this topic we studied about non-linear models (Boosting and random forest), ensemble learning, bootstrap elimination, AdaBoost (Adaptive Boosting), random forest algorithm, random forest and boosting in python. Boosting and random forest are popular non-linear machine learning algorithms used for classification and regression tasks. They are ensemble methods that combine multiple weaker models to create a stronger predictive model.  Ensemble learning combines multiple individual models to create a stronger and more accurate predictive model by using collective knowledge of multiple models to outperform a single model, leading to improved predictions. It can be applied to both classification and regression problems  Boosting algorithms work by iteratively training weak models, also known as base learners or weak learners, on different subsets of the training data. Each subsequent model is trained to correct the mistakes made by the previous models. In this way, boosting focuses on improving the areas where previous models struggled, gradually improving the overall predictive power of the ensemble.  AdaBoost is capable of handling complex relationship between features and target variables, it is resistance to overfitting and its flexibility to work with the different weak learners, itâ€™s widely used in image recognition, text classification, and face recognition.  Random Forest is an ensemble learning method that builds a collection of decision trees and combines their predictions to make a final prediction. It creates multiple decision trees using different subsets of the training data and random subsets of features. Each tree in the forest is built independently and the final prediction is obtained by averaging or voting the predictions of all the trees. It overcomes some limitations of individual decision trees, such as overfitting and high variance. Random Forest is computationally efficient, capable of handling high-dimensional data, and provides estimates of feature importance, making it useful for feature selection. It can handle both classification and regression tasks.    