This topic introduced the topic of Ensemble Learning, particularly focusing on the Random Forest Algorithm.  Ensemble Learning  Ensemble Learning involves combining or averaging the results of a collection, or ensemble, of different learning models in order to produce a combined result that reduces variance.  Bootstrap Sampling  Bootstrap Sampling involves creating smaller samples from a larger sample dataset. Bootstrap samples are taken with replacement, meaning that each sample is taken from the original data as a whole â€“ meaning that individual data points may be included in many, or none, bookstrap samples. Boostrap sampling helps to improve performance and reduce variance.  Adaptive Boosting  Adaptive Boosting, known as AdaBoost, is an algorithm which combines multiple weaker classifiers to create a single stronger classifier.  Random Forest  Random Forest is a form of Ensemble Learning which combines together the results of many Decision Trees. Individual decision trees are created randomly based on a bootstrap sample of the full data set. Results of the individual trees are then aggregated to determine the final performance of the model.  