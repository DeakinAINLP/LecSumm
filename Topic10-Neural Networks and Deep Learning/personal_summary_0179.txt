Topicly Summary  This topic we discussed ensemble methods including:    Ensemble – ensemble seeks to use multiple models (such as multiple decision trees in a  random forest) to get a consensus on the best prediction for a model. In the classification sense it will take the majority of all the models, in the regression sense it may take an average of the results from many models.    Bootstrapping – Bootstrapping is selecting a sample of the data set to train a model. We draw N different bootstrap samples and replace the data back in for the next bootstrap. Conducting bootstrap can reduce variance and reduce overfitting.    AdaBoost – Adaptive Boosting, unlike a random forest that takes the consensus of many  models performs an iterative approach on the model by modifying the weights. Unlike a tree, the AdaBoost method uses ‘stumps’ (just one feature at a time) also known as weak learners. The AdaBoost model iterates over the data set with different model weights (each iteration is a ‘weak classifier’. We then evaluate that iteration by calculating it’s error. When there are misclassifications we increase the weights and when there are correct classifications we decrease the weights. We continue this process until we hit a stop criteria or after a set number of iterations.  If a stump makes a misclassification then it it’s weights are increased for the next iteration so the next stump can ‘stress test’ that highly weighted data point. This iterates through until good weights for each feature is found.    Voting Classifier – A voting classifier is an ensemble but instead of using multiple of the  same classifiers it uses different types of classifiers (such as SVMs, DT and KNN all together) to provide a prediction. For classification it determines the predicted value based off a majority vote.    Stack Classifier – A stack classifier is a two stage process where in the first stage is multiple classifiers make a prediction and in the second stage the predictions are fed to a meta classifier that uses that data to make a prediction.  