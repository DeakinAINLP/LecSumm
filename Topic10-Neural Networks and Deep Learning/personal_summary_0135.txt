This topic I have learned about Ensemble learning and how it works and how to implement it in Python programming language. As we have gone through different machine learning models in this unit, we know that some models perform good and some don’t, and we choose the one which has highest accuracy. However, it is always possible that one model can better predict some inputs, whereas others cannot, in summary, some models better understand some data than others.  This is where ensemble learning comes into play.  It learns from different weak models and create a strong model which is known as best model, the most commonly used ensemble techniques are Random Forest and Gradient Boosting. Random forest takes n number of randomly selected models and asks to predict the output and aggregates all the votes to correctly predict the final prediction. This can be enhanced by hyperparameter tuning by grid search.  The advantages of random forest classifier is that it doesn’t always require data to be pre-processed, scaled or normalized and it automatically handles null values. However, the prediction values are harder to interpret since it is not a single tree which is making the final predictions.  Later I learned how to apply Random Forest classifier and hyper tune its parameter in Python programming language.      