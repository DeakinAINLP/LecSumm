 In this module we learned about ensembled learning. It is the concept of wisdom of crowd concept. The knowledge of a diverse group of people that can be harnessed by voting. Generating and combining multiple models is ensembled learning. By combining multiple models, the accuracy and robustness of the model can be improved.  Random forests are one of the ensembled learning models. Here we combine multiple trees and take the output from them and aggregate them to create one accurate output.  To do so we need to use subsamples of datasets each with a bit of different samples. This is called Bootstrapping. A bootstrap sample is a smaller sample which is generated from a larger sample. Bootstrapping can result in less variance as more accurate results. It helps in using slightly different datasets which results in slightly different patterns of output. This results in more accuracy and robust estimation.  Then we proceeded to learn how random forest algorithm works: -    Each tree is built from a bootstrap of sample data   The node of the tree is the best features from the subset, we can determine  that from Gini index or entropy.    Repeat these steps T times   This increases bias as it uses subsets of features in different independent  trees.    Aggregate the votes from different trees to decide the final class of test  objects.  Then we learned about out of bag error, it can be thought of as equivalent to validation set or test data. From the bootstrapped data only 2/3 is used as bagged data the rest 1/3 is used as out of bag instances.  Then we discussed how we can rank feature importance. Then we proceeded to discuss the advantages and disadvantages of random forests.   We also learned about boosting, which is concept of ensembled learning where we teach various models sequentially, each one of the models learning from the mistakes made by the previous model. Then we also learned about adaboost.  In the end we learned about how to practice these theoretical concepts in real world using python and various libraries.  Evidence of self-assessment: -      