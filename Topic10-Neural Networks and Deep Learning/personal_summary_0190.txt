Summary This topic we covered ensemble learning based algorithms like ada boost, gradient boost, and random forest.  Just  like  previous  topic,  this  module  also  includes  some  advanced  concepts  like  feature importance  in  relevance  to  random  forest,  voting  classifier  and  stack  classifier  along  with  python implementation. In addition, the python implementation section also includes removal of redundant attributes from a dataset.  Reading List We  start  with  9.1  to  9.3  which  gives  a  brief  introduction  with  a  video  explanation  for  concepts  of ensemble learning and bootstrap estimation. Then we go on to 9.4 where we learn about adaboost algorithm and how it works in step by step manner followed by bagging in 9.5 and from here on we start random forest algorithm with 9.6. With additional topics in 9.7 which include out of bag error, merits and demerits of random forest along with feature importance.  Then come some more advanced classifiers like voting and stack in 9.8 and then we finish of this topic with  python  implementation  of  ensemble  algorithms  in  9.9  and  9.10  along  with  the  concept  of removing redundant attributes from a dataset.  