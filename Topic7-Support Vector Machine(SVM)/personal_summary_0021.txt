Covariance: In linear regression, training data is ğ‘¥ğ‘–, ğ‘¦ğ‘–, where x is the input and y is the output. The relationship between x and y can be calculated by measuring the covariance. There are three possible outcomes when calculating covariance:  1.  ğ‘ªğ’ğ’—(ğ’™, ğ’š) > ğŸ â€“  positive correlation, thus as x increases, so will y 2.  ğ‘ªğ’ğ’—(ğ’™, ğ’š) < ğŸ â€“ inverse correlation, thus as x increases, y decreases 3.  ğ‘ªğ’ğ’—(ğ’™, ğ’š) = ğŸ â€“ no correlation, x and y are independent.  Pearsonâ€™s correlation coefficient: another method that can be used to measure the linear correlation between two variables. The outcome ranges between -1 to 1 where outcomes closest toâ€¦  -  1 have a stronger positive relationship. -  0 have a weaker relationship.  -1 have a stronger negative relationship.  Curvilinear relationship: shows the relationship between two or more variables and where the graph is depicted as anything but a straight line.  Linear regression formulation Used to find the best fitting linear trend line for the linear regression model. The linear regression line has two parameters:  1.  w â€“ the slope 2.  b â€“ the y intercept  Hypothesis: The two parameters above can be used to find the line. Error of value: The difference between what has been predicted and the true output. ^ ğ‘’ğ‘– = ğ‘¦ğ‘– âˆ’ ğ‘¦ There are two ways to find the best fitting line:  1.  Find a line that minimizes the total absolute error. This can be done by trying different w and b combinations.  2.  Find a line that minimizes the total squared error.  Binary classification: when there are only two possible values for output. E.g., given an image of a vehicle, the task may classify it as a car or not a car. Multi-class classification: when there are more than two possible values for an output. E.g., given an image of a vehicle, the task may identify it by brands such as BMW, Mercedes, Toyota etc. Linear classification: the hypothesis that separation between two classes is linear. Despite outputs having the same classification, it does not necessarily mean they are linear to each other. Complexity: If the number of features captured is increased, so will the modelâ€™s complexity. Training a complex model on limited training data may cause over fitting. Generalisation: prediction of unseen data. MSE can be used to measure the error of the prediction made against the unseen data.  Logistic regression A decision function used to determine the classification of an output. This function uses a fixed non-linear link function to find a score. The score can be anywhere between 0 to 1, with closeness to 1 indicating one label and closeness to 0 indicating the other label. If the decision is somewhere in the middle of 0 to 1, then it is unclear what the label/classification should be. Logistic regression formulation: the function is also known as a sigmoid function. The graph produced from this function is an S-shaped curve that takes any real number and maps it between 0 to 1. Unlike the linear regression function, logistic regression does not directly model y (output) in terms of x (input). Instead, logit, the log of odds based on x is modelled. Odds:  ğ‘ƒ(ğ‘¦=1|ğ‘¥) 1âˆ’ğ‘ƒ(ğ‘¦=1|ğ‘¥) 