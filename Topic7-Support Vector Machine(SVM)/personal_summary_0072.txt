Evidence of learning Summary of this topic Covariance and Pearsonâ€™s correlation coefficient Covariance is a way to measure the linear relationship between two variables, x and y.  In this case x can be multidimensional and y is one dimensional.  It is defined as:  -  A positive value means that y increases as x increases -  A negative value means that y decreases as x increases -  A value of 0 means that the two variables are independent to each other  Pearsonâ€™s correlation coefficient measures the linear relationship between two variables by giving a value between -1 and +1. Positive and negative values represent positive and negative relationships respectively, and values closer to -1 and +1 represent stronger relationships.  It is defined as:  Moore-Penrose pseudoinverse Used to find the linear regression line for a dataset with the minimum mean-square-error.  Regression line definition:  Moore-Penrose pseudoinverse:   Linear classification Linear classification is used in cases where a sampleâ€™s class can be determined by drawing a linear line somewhere in space to separate each class from each other.  If the hypothesis function that makes up the regression line is h(x), we can make a binary linear classification decision by using another function called a link function: Ïƒ(h(x)).  Sigmoid function One commonly used link function is the sigmoid function. It is an S shaped curve that approaches but never actually reaches 0 and 1:    This function is commonly used in machine learning because it has useful mathematical properties such as:  -  mapping all real numbers to between 0 and 1 regardless of its magnitude -  it is differentiable, which makes it possible to use optimization techniques in ML algorithms that use the gradient or derivative of the function  It is defined as:  In the context of linear regression the sigmoid function is used to model the probability that the result from the hypothesis function h(x), y, belongs to a class. I.e.:  ğ‘ƒ(ğ‘¦ = 1|ğ‘¥)  We can set a threshold from the result of the sigmoid function to classify the sample x as belonging to either class 1 or class 0:  ğ‘ƒ(ğ‘¦ = 1|ğ‘¥) > 0.5 â†’ ğ‘ğ‘™ğ‘ğ‘ ğ‘  1  ğ‘ƒ(ğ‘¦ = 1|ğ‘¥) â‰¤ 0.5 â†’ ğ‘ğ‘™ğ‘ğ‘ ğ‘  0  Odds In probability, odds is defined as the ratio of the probability of an event occurring to the probability of an event not occurring:  Odds is not the same as probability.  ğ‘‚ğ‘‘ğ‘‘ğ‘  =  ğ‘ƒ(ğ‘¥) 1 âˆ’ ğ‘ƒ(ğ‘¥)     Logit function The logit function does the opposite thing as a sigmoid function. It maps all numbers from a range of 0 to 1 to negative and positive infinity.  The logit function is defined as the log of the odds:  ğ‘™ğ‘œğ‘”ğ‘–ğ‘¡ = log (ğ‘œğ‘‘ğ‘‘ğ‘ )  Logistic regression In the context of logistic regression, the log of odds is the odds that a sample will be classified to a class, which is a linear combination of weights and predictor variables:  log(ğ‘œğ‘‘ğ‘‘ğ‘ ) = ğ‘¤0 + ğ‘¤1ğ‘¥1 + ğ‘¤2ğ‘¥2 + â‹¯ + ğ‘¤ğ‘›ğ‘¥ğ‘›  Training a logistic regression model means estimating the regression coefficient vector w.  The maximum likelihood estimate l(w) is used to estimate w. It is defined as:  Which is formulated from the sigmoid function or the probability of the outcome y occurring given the input x.  If we have some training data with n independent instances the joint likelihood is:  To maximise w we can maximise the log of l(w):  Maximizing log(l(w)) is the same as minimizing -log(l(w)) due to logarithm properties, so this optimization problem can be restated as minimizing -log(l(w)) with respect to w:  This is also known as the logistic loss function.  There is no closed form solution to this function because the domain of the function is non-convex.  Coordinate wise gradient descent optimisation To find the global minimum of the function we can perform coordinate-wise gradient descent optimisation.  Related video: https://youtu.be/QDX-1M5Nj7s?t=2257. In this video the professor is talking about minimising a loss function of a neural network instead of the logistic loss function, but he still explains how gradient descent works so itâ€™s related.      Model complexity Reminder: If a model is suffering from underfitting or overfitting, it will have poor performance. The performance of a model can be measured using risk metrics.  The aim is to minimize the error of the model by minimizing the risk:  ğ‘…ğ‘–ğ‘ ğ‘˜ =   ğ‘ğ‘–ğ‘ğ‘ 2 + ğ‘£ğ‘ğ‘Ÿğ‘–ğ‘ğ‘›ğ‘ğ‘’ + ğ‘›ğ‘œğ‘–ğ‘ ğ‘’  Noise here is irreducible error. Depending on the dataset it could probably be cleaned up during pre- processing.  There tends to be a trade-off between bias and variance when fitting models:  Heuristics to diagnose underfitting and overfitting Underfit models (high bias):  -  Has a high error rate on the training set -  Has a high cross validation error and training error. CV error may be slightly higher  compared to training error.  Overfit models (overfit):  -  Has a low error rate on the training set -  Has a very high cross validation error compared to training set error  If we plot the error rate on the test set compared to the complexity of the model, we will see that the error rate peaks when the model is underfit or overfit. We will also usually see that the lowest error rate will occur at the point with the best generalization.     Regularised linear models The regularizer in machine learning models is a penalty term in the loss function that aims to avoid overfitting by regulating the modelâ€™s dependence on certain variables.  This penalty term discourages the model from assigning too much importance to those variables and encourages it to find a more generalizable solution.  This term can be considered as the complexity of the model. It can also be combined with other complexity metrics depending on use case.  Two popular regularizer functions:  -  Encourages sparsity by encouraging 0 weights. This uses the L1 norm, also known as Manhattan norm or Taxicab norm.  -  By encouraging the weights to be close to zero, the L1-norm regularizer can effectively  remove features from the model that are not contributing much to the overall prediction performance.  -  -  Penalizes large weights. This uses the L2 norm and is also commonly called ridge regression or L2 regularization. The effect of using the L2 norm as a regularizer is to encourage smaller and more uniformly distributed weights.  Regularization increases the bias but greatly reduces the variance. It is useful if it reduces the overall error of the model.  Additional reading on regularization  -  L1 regularisation (LASSO): Least Absolute Shrinkage and Selection Operator      -  L2 regularisation (ridge)  -  How â€œelastic netâ€ overcomes a limitation of LASSO -  The effects of the lambda hyperparameter (regularization weighting) on the overall modelâ€™s risk across different quantities of samples and lambda size.  