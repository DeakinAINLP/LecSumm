 Main learning points:    Logistic regression is for when the outcomes are binary.   Covariance is used to measure the amount of information a particular X variable can  provide for the y variable.       Regulariser are techniques used to avoid overfitting. o  More useful when there is smaller sample size  Ridge Regression (L2 regulariser):  For least squares regression, equation is determined by:    Minimising:  o  Sum of squared residuals in the line-of-best-fit  For ridge regression, equation is determined by:    Minimising:  o  The same sum of squared residuals plus (λ)(slope)**2  (slope)2 is a penalty to the least squares method.     λ determines the severity of the penalty. o  λ is any number from [0, inf) If λ=0, then ridge regression line is the same as least squared line o o  As λ gets larger, the slope of the ridge regression approaches 0 (flat  horizontal).    To decide the value of λ:  o  Try different λ values across cross-validation to find the best one.  