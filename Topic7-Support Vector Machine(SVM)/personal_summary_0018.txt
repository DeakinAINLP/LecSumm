Lesson Overview ‚Äì Linear Model  Linear  regression  is  a  widely  used  method  to  determine  the  relationship  between  one  or  more independent variables  and  a  dependent variable; or number of  features  x variables  and  an output commonly denoted as y variable.  It assumes that the relationship between these variables form a straight line.  Covariance can be used to measure the linear relationship between input variables, x and  the  output,  y.    If  the  covariance  is  positive,  it  indicates  that  the  two  variables  are  positively correlated, meaning that  if  x  increased y would  increase,  however, if  the covariance is  negative,  it means that the two variables are negatively correlated, meaning that if x increases y is decreasing. Additionally, if the covariance is 0, it indicates that x and y are independent.  Pearson‚Äôs correlation coefficient  measures  the  association  between  the  two  variables.    Pearson‚Äôs  correlation  (r)  ranges between 0-1, the  closer r  it is  to  1,  the  stronger the relationship  is, additionally, an  r value  can be positive or negative, indicating a positive or negative relationship.  Linear  regression  is  determined  by  the  formula  ùë¶ = ‚Ñé(ùë•) = ùë§ùë• + ùëè  where  y  is  the  dependent variable, w is the slope/weight, and b is the intercept or constant term.  Using this formula, we will be able to work out the estimated value for a given value of x.  However, this formula is only used for data with one dimension, for data with multidimension this formula will need to be expanded.    There are two main methods that can be used to find the best-fitted linear regression line, the first method is to find a line that minimises the total absolute error or a second methods which minimises the total squared error.  Logistic  regression  is  another  type  of  regression  used  to  predict  categorical  dependent  variable, normally used for binary classification.  To find the best logistic regression line, instead of using the squared  error  function,  the  maximum  likelihood estimation  is used  to  estimated  w. There are two common methods to find the optimal values for a logistic regression model.  First one being gradient descent and the second being the newton‚Äôs method.  The gradient descent is an iterative optimisation algorithm where an initial guess of where the minimum is performed, subsequently small steps are taken until the bottom/minimum is found.  Similar to gradient descent, Newton‚Äôs method is another iterative optimisation algorithm finding the minimum by finding the roots of a differentiable function.  Overfitting  occurs  when  a  model  is  over  complex  and  fits  the  data  too  closely  and  resulting  in performing poorly on predicting new/unseen data.  On the other hand, underfitting is when the model is too simple and is unable to capture the pattern presented in the data.  Bias-variance decomposition is a method used in machine learning to decompose the expected error of a model into a bias and a variance component.  Bias refers to the difference between the expected prediction of the model and the true value, and variance is the variability of the model‚Äôs prediction for different training set.  Low bias  can  result  in  high  variance  and  high  bias  results  in  low  variance,  only  with  the  right  balance between bias and variance can the expected error of the model be minimised.  