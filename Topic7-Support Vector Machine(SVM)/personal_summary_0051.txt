Learnt that linear regression is a statistical technique that tries to find the relationship between the dependent variable (y) and one or more independent variables (x). Learnt that each data point or feature vector is the independent variables (x) and output is the dependent variable (y) Learnt that we have to find the best line so that the obtained model can allow us to summarize and study relationships between two variables.  Linear Hypothesis 2:08pm   Linear regression is good for only one feature or one x, which can predict the value of y(x). However what if we increase the number of dimensions? Then this kind of linear will not be useful.  So therefore we expand and write a linear regression as:  Where x0 is a dummy feature with value being x0 = 1 and w0 being b.  Learnt that the dimensioned formula is almost the same as the single dimension formula. Learnt the difference is that the multiplication of w and x which should be handled in all d dimensions.   We use function:   To find the best linear line using minimum empirical risk using squared loss (yi ŷi)2  We can rewrite the formula as:      This formula is just the mean of the square error function which has already been introduced as a proper measurement for regression problems. Therefore to solve the minimisation problem we can take the derivative of the error function with respect to weight(w) and equate it to 0. Then we are able to find the w which can minimize this error. This is the formula:  Overall, we need to find the best line using squared loss functions, then find W,  then use W is find the predicted value.   Logistic Regression2:20pm   Learnt that this is used for binary classification or categorical dependent variable. Learnt that it is still to fit a linear function to predict y from x Instead of using squared error function, we use maximum likelihood estimation (MLE) to find W.  Assuming training data with 𝑛 independent instances  we have joint likelihood as:   So the Joint likelihood function while having 𝑛 independent samples using training data  is the multiplication of the likelihood of each point.  Maximum likelihood estimation method maximizes 𝑙(𝑤) with respect to 𝑤. Maximising likelihood is equivalent to maximising log of the likelihood function because  both provide same solution for 𝑤.  Maximising log 𝑙(𝑤) is equivalent to minimising −log 𝑙(𝑤), which brings us to the following  This is called a Logistic Loss function 𝐿(𝑤)  minimisation problem:   Learnt we can minimize the function with respect to W using the usual approach that takes the derivative and equate it to zero.  We perform Coordinate-wise Gradient Descent Optimisation where we take multiple  steps iteratively to reach the minimum.  Computing the minimum 2:31pm  When trying to minimize the loss functions there are two types of functions that  are different, the Convex and Non-convex.  A nonconvex solution means that it has two minimum solutions. One called local  minimum and one called global minimum(Most minimum solution).  A convex solution means that it has only one minimum.    Learnt that in mathematics, we call slopes derivatives. Two popular methods when we can compute gradient (derivatives) of the objective function:  Gradient descent (uses first derivative) Newton’s method (uses second derivative)  Gradient descent (uses first derivative):2:37pm We use iterative update to minimize L(w):  Essentially, it simulates the same concept we defined with a convex  shaped valley and escape at the bottom/minimum. Iterative process that takes steps in going towards the minimum   Newton's method (uses second derivative):  We use iterative update to minimize L(w):   Instead of using η (your step size), this uses H where it is the Hessian matrix.  So Newton’s method is an iterative method for finding the roots of a  differentiable function.  Overall, Gradient descent maximizes a function using knowledge of its  derivative while Newton’s method, a root finding algorithm, maximizes a function using knowledge of its second derivative.  Newton’s method is faster if the second derivative is known, however the second derivative is often complicated or intractable thus requiring a lot of computation and expensive.  Coordinate-wise Gradient Descent Optimisation 2:43pm   Learnt that we first randomly initialize 𝑤 to fulfill the first task.  Model Complexity (Bias & Variance) 2:47pm  Learnt that overfitting happens when we are finding an over complex model on the data. Learnt that underfitting is the result of an extremely simple model.    Overfitting occurs when we train a model and find that it is explaining the data better now    but the prediction is poor when used on unseen data. It has learnt too much specifics of training data and has probably learnt the background noise in the data. Therefore, fitting a perfect model that is only listening to the Symphony (signal) and not to the background noise.  Bias Variance Decomposition 2:52pm  A bias problem is an underfitting issue, while a variance problem is an overfitting issue. We use Bias Variance Decomposition to find out what the problem is. Let us assume our data (𝑥,𝑦) has the true relation 𝑦=𝑓(𝑥)+𝜖, where 𝜖 is a   measurement noise in 𝑦 with mean zero and variance  Additionally, assume that we are fitting a hypothesis function (or model)  using dataset 𝐷. This makes the expected loss or risk function to have three components as:  (Bias)2 is     Variance is  Noise or irreducible error is   For (Bias)2 2:55pm     Learnt that this term shows how accurate the hypothesis function (or your designed model, ℎD (𝑥)) is Learnt that the 𝐸 (expectation) means average out this error to find out the expectation of error regarding this hypothesis (ℎ𝐷 (𝑥)) and the true function output (𝑓(𝑥)) Learn that if the (bias)2 value is small or close to 0, then it means that the model is accurate with a low error rate.  By adding noise to the actual solution which is the hypothesis function, and then find a difference between these two functions. A good accurate model should not change as much from the difference. For Variance 2:57pm       Learnt that this term does not have 𝑓(𝑥) inside it, it solely relies on your hypothesis model which is ℎ𝐷 (𝑥). Learnt that this model measures the tolerance of your calculated model while changing just the data set 𝐷. Learnt that the 𝐸(expectation) of this term measures the amount of complexity of your model. Learnt that if it varies too much it will be overfitted.     Learn that if there is an increase in variance of the model, then there will be lower bias, making the model more complex.(Overfitting) If there is an decrease in variance of the model, then there will be a higher bias, making the model less complex. (Underfitting) This illustrates another trade-off problem in machine learning.  Variance bias trade off 3:00pm  Overall, the best model contains a low variance and low bias where the model is  not complex and is accurate.  A model with high bias will make the model not accurate based on the training data. A high variance will make the model too complex making it prone to poor predictions on the test data.  A Model with too few parameters (or lower complexity/variance) is inaccurate  because of a large bias (not enough flexibility): under-fitting.   A model with too many parameters (or high complexity/variance) is inaccurate because of a large variance (too much sensitivity to the sample): over-fitting.   We need to find the sweet spot where Risk = bias2 + variance + noise is the minimum.  Regulariser (L1 & L2) 3:06pm  Learnt that Regularisation is a technique used to control the model complexity. Learnt that it is an additional term in the loss function to avoid overfitting. Use the regularizer into the loss function and keep the control of the overfitting Regulariser tries to keep the parameters more normal, where it does not allow   regression coefficients (or weights) to take excessively large values. If the regression coefficients (or weights) is large, it implies that the model is highly dependent on that one feature.  Regularized linear models 3:09pm  As we don’t want to have to rely too much on any one feature when we are  designing a model.   Thus our loss function now has another term which is is a way to guide the training process to prefer certain types of weights over others.  , where it  Consider this term as complexity of the model:   λ is used to penalize based on the W(weight) as we don’t want a large W value that over relies on one feature.    If weights are huge, a small change in a feature would result in a large change in the prediction. There is two popular regulariser functions to penalize large weights or encourage small/zero weights: Option 1:  Where it encourages 0 weights (sparsity). This function implies the closed  form function of a square.  Or Option 2:  Where it penalizes large weights. This function implies the closed form  function of a circle.   The L1-norm on the left forms a square shape, assume the loss function in form of ellipses in the plot.  Since we are minimizing the loss function which actually has l1-norm  regularization inside it, we need to find a sweet spot which is the intersection of these two regions. If you keep drawing the ellipses, you can find the intersection in the image. The image on the right indicates the same concept with a different regulariser L2-norm that is the circle shape.   Where it has a higher chance of intersection in this occasion. Additionally, there is less chance of having 0 weights for β1 or 𝑤1 and β2 or 𝑤2. Therefore we have more options for selection of 𝑤1 and 𝑤2.  L1 Regularisation (LASSO) 3:16pm  LASSO (Least Absolute Shrinkage and Selection Operator) is a regression analysis method that performs both variable selection and regularization in order to enhance the prediction accuracy and interpretability of the statistical model it produces.    L2 Regularization (Ridge) and Elastic net 3:17pm  Elastic net overcomes a limitation of LASSO for 𝑑(dimensions)>𝑛(sample data)  case: Regularise linear models summary:    