In this topic we learnt several supervised learning related concepts focusing on model assessment and selection. We evaluate a model to determine if it will do a good job of predicting the target on new and future data. Also, after a model is trained, to measure its accuracy, we need to assess the model. Linear regression attempts to model the relationship between two variables. This happens by fitting a linear equation to the observed data, in other words an equation that graphs as a straight line.  This linear equation allows us to summarize and study relationships between two continuous variables. linear classification and introduces logistic regression can be used for appropriate analysis for binary classification problems. Classification is inherently non-linear when considering continuous outputs. Instances that have different characteristics may belong to the same class, leading to non-linearity.  There are two approaches for logistic regression:    Ignoring non-linearity by treating binary outputs as in regression and using least squares for classification.    Utilizing a link function to transform the output into a classification scenario, where the conditional probability of the class becomes the output in the regression problem.  In this topic we learned that linear regression has a closed-form solution, and that Python implementation uses Singular Value Decomposition (SVD) to compute the Moore-Penrose inverse of the matrix. Also importance of model complexity in linear regression, particularly when dealing with a limited set of training data has learnt which explains that increasing the number of features can increase model complexity, which can lead to overfitting if the training data is limited.  Moreover, during topic 6, we learnt the process of training a logistic regression model using maximum likelihood estimation (MLE) to estimate the regression coefficient vector.             