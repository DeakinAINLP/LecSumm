Linear regression attempts to model the relationship between two variables by fitting a linear equation to the observed data whereas logistic regression is to conduct when the output values of the feature vectors are binary. Linear regression assumes that the relationship between the  independent  variables  (or  predictors)  and  the  dependent  variable  (or  response)  can  be described by a linear function, which means that the effect of each predictor on the response is proportional  to  its  numerical  value  and  does  not  depend  on  any  higher-order  terms  or interactions . Pearsonâ€™s correlation coefficient can be used to measure the linear correlation between  two  variables.  It  ranges  from  -1  to  1,  where  -1  indicates  a  perfect  negative  linear correlation, 0 indicates no linear correlation, and 1 indicates a perfect positive linear correlation [2]. Logistic regression is a statistical method used for binary classification tasks, where the goal is to predict the probability of an event (such as a customer churning) based on one or more  input  variables  (also  called  features  or  predictors).  Unlike  linear  regression,  which predicts continuous numerical values, logistic regression outputs a probability score between 0 and 1, which can be interpreted as the likelihood of the event happening. This probability is then converted into a binary decision using a threshold value. Generalisation can be used to determine the quality of the model by predicting the output for a new instance. It can be quantified using Mean absolute error. For each model creation there should be a train data and a test data to check overfitting by using cross validation error. This is defined as the model complexity. Overfitting can also be limited by using regularised linear models. 