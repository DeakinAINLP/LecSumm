 Linear  Regression:  A  supervised  learning  approach  known  as  linear  regression  is  used  to forecast a con6nuous outcome variable using one or more predictor variables. The objec6ve of linear regression is to ﬁt a line that best explains the connec6on between the predictor factors and the result variable.  Logis-c Regression: The supervised learning process known as logis6c regression is used to forecast outcomes that are either binary or categorical. In contrast to linear regression, logis6c regression  forecasts  the  likelihood  of  an  outcome  rather  than  the  actual  result.  The  link between the predictor factors and the result variable is modelled by the algorithm using a logis6c func6on.  Model Complexity: A machine learning model's model complexity describes how well it ﬁts the training data. Bias and variance are two essen6al elements of model complexity.  i.  ii.  Bias is the degree to which a model predicts the incorrect result repeatedly. High bias models frequently underﬁt the data, which implies they miss the underlying paEerns and correla6ons in the data. Variance  describes  how  much  a  model  alters  its  forecasts  aFer  being  trained  on various subsets of the data. As a result of its propensity to overﬁt the data, a model with a large variance tends to include noise and unpredictability in the data.  Regularisa-on:  It  is  a  strategy  for  preven6ng  overﬁGng  in  machine  learning  models  by introducing a penalty term into the loss func6on. L1 and L2 regularisa6on are the two most prevalent types of regularisa6on.  i.  ii.  L1  regularisa-on:  also  known  as  Lasso  regularisa6on,  modiﬁes  the  loss  func6on  by including a penalty term propor6onate to the absolute value of the model weights. This results in sparse models with certain weights set to zero. L2 regularisa-on: also known as Ridge regularisa6on, introduces a penalty term into the loss func6on that is propor6onal to the model weights squared. As a result, models with smaller but non-zero weights are produced.  