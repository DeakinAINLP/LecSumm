 Topic 6 provided a solid synopsis on linear regression and other modelling techniques.  This topic reinforced concepts of a training dataset and test datasets. Segregation of these, influences of bias and the percentages they are separated (if using real world data).  This topic focused on linear and logisitic regression which had the following important principals;    Pearsons Correlation coefficient  o  Relates  to  the  linear  correlation  between  two  variables  with  the  closer  to  1  the  more  positive the relationship and -1 being a negative relationship    Several assumptions have to be made in linear regression such as a relationship between the dependant and independent variable, a normal distribution of residuals and that the variance of residuals is constant.    Bias, underfitting and overfitting is a delicate balance with a linear regression model and in some cases it may not be the most suitable regression technique due to these constraints. If itâ€™s getting into  an  overfitting  situation  to  get  the  accuracy  acceptable,  may  be  time  to  ditch  the  linear methodology.    Regulisors can be utilised in python to help prevent the overfitting of a linear regression curve.  Linear regression is itself a classification assumption that there is logical progression in the underlying data and is extremely subject to outliers, logistic regression can assist with this.  