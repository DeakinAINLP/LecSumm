This topic was focused on further exploring supervised learning, performing linear and logistic regression models, and ways to evaluate the performances of those models to assist in selecting an appropriate model for the desired outcome. Linear regression is to predict the target variable based on the features of a dataset, whereas logistic regression is for classifying the sets of data into respective types or classes. Such as with the Iris data set in the activity to determine if the row of data is one of three species of flowers. Ensuring that proper evaluation and selection is performed will help to reduce the bias of the outcomes and create a more ‘trustworthy’ output. This will mean that the predictions fit the data, and not have the predictions fit the desired output. We learned about how covariance of the variables can create observations in the strength or weakness of relationships between variables, or show no relation at all.  Fitting a linear regression model to the data is a way to figure out the relationship between variables and their covariance – creating a function to predict unknown values based on provided data. From the pass activity it can be seen that the Python methods of creating both a logistic regression and a linear regression model take are generally similar. The activities were interesting and challenging but it may have been beneficial to compare the performance of classifying the IRIS data set between a logistic regression and linear regression model as the content of the topic seemed to focus on that, and would have made it more relevant as well. 