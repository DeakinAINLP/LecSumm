Ans: Linear regression is a model which creates the relationship between the feature & the output using covariance.  ➢  Pearson’s correlation coefficient measures the linear relationship  between two variables & ranges between -1 to 1.  ➢  Strong relationships & weak relationships where former can be seen or  calculated by seeing all the data points highly correlated in the direction of line while the latter is opposite to it.  ➢  Error of value prediction in regression points is the difference between  the value we predicted & the output of that point.  ➢  Logistic regression is an appropriate analysis to predict the output  values of the vectors are binary.  ➢  Logistic regression generally uses two approaches: ignore non-linearity  & using link function.  ➢  Generalisation & complexity where python uses SVD to compute the  Moore-Penrose inverse of matrix & predicts the unseen data .  ➢  Sigmoid function is another name of logistic regression, it’s a S-shaped  curve which can take any value between 0 & 1.  ➢  When a training dataset is used to estimate the regression coefficient  vector than it is called as training a logistic regression model.  ➢  Convex function can deal with only one optimal solution that too which  is globally optimal.  ➢  Non-convex function has multiple locally optimal points. ➢  Iterative optimizing is used to calculate the gradient with two popular methods : Gradient Descent & coordinate wise gradient optimization. ➢  Model complexity is of two types where one is over-fitting because of  overly complexed model & under-fitting occurs if the complexity is low.  ➢  Regularised linear model is implemented to avoid overfitting, it does not allow the regression coefficient to take excessively large values.  ➢  Examples & sample codes of logistic regression in python.  