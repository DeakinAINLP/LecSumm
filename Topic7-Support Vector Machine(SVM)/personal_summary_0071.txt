 Learning Goals  By the end of topics 5 and 6 you will be able to:    differentiate supervised learning from unsupervised learning.   estimate the performance of different supervised learning models.   implement model selection and compute relevant evaluation measures.  In topic 6 we continue from topic 5 this topic focusing mainly on concepts of model assessment and selection in machine learning.  Prior to using any model its important to assess it and make sure that it does a good job for what you are trying to achieve and that it does well in predicting not just the current data but any future data you may have.  Assessing a trained model  After we train a mode, we need to consider its accuracy and we need to assess the model. However, getting an unbiased estimate of the accuracy is the tricky part.  Considering this when training a model, we should always try to separate a test set of data s that the test set labels don’t influence the trained model in anyway.  Some of the ways a biased estimation can impact our training model are:  Unfair decision making, Reinforcement on existing inequalities, Unintended consequences, Lack of accountability in decision making.  Relevance and Covariance among features of variables  When we are building models to predict a particular target variable, we need to remember that it is important to consider the importance of covariance among the features. We need to consider relevance which is how strongly associated with the variable the feature is. Covariance refers to how strongly features are associated with each other.  Highly correlated features can sometimes lead to overfitting and/or reduced model performance. It is important to carefully select features that are relevant to the target variable and have low covariance with each other to reduce the risk of this happening. We can do this via feature selection techniques like PCA and regularization.     Linear regression formulation  Linear regression is a statistical method we can use to model the relationship between a dependent and one or more independent variable. The idea of linear regression is to find the best linear relationship between these two variables. To do this we try to minimise the sum of squared errors between the predicted values and the actual values of the dependent variable. The formula for linear regression is --  Y = β0 + β1X1 + β2X2 + … + βnXn    Y is the dependent variable   X is the independent variable   β is the coefficient of the independent variable  Linear classification  Linear classification is a different supervised learning algorithm used to classify data into two or more categories based on their features.  In linear classification we make use of a linear boundary that is drawn between the classes to separate them. The boundary can be determined by finding the optimal values of the model parameters that maximize the margin between the classes. Linear classification algorithms often include logistic regression, SVM, LDA.  Generalization and complexity  In Machine Learning, two key concepts are Generalization and complexity, with generalization being the ability for a model to give good results on new data it has not seen before and complexity refers to the number of parameters we are using in the model.  If we go with a model that has too high complexity it can cause overfitting which means that its outcomes will be to do well on the training data but poorly on the test data, we provide. We can try to mitigate overfitting by balancing the complexity of our model against the ability to generalise new unseen data.  Logistic regression formulation    Logistic regression is is one kind of linear classification algorithm as we already know which can help predict the probability of some event occurring. One of the main differences between logistic regression and linear regression. Logistic regression is more commonly used for binary classification problem where the dependent is a categorical variable with 2 levels.  It can be represented with the following formulae, p = 1 / (1 + e^-(β0 + β1X1 + β2X2 + … + βnXn)).        ‘p’ shows the probability of an event occurring  ‘X’ is the independent variable  ‘Β’ is the coefficient of the independent variable.  Training a logistic regression model  The key to training a logistic regression model is the maximum likelihood estimation method this can be used to find the optimal values of the model parameters that optimise the likelihood of the observed data.  The optimization problem is solved using an iterative algorithm such as gradient descent, which updates the model parameters at each step to minimize the cost function.  Model Complexity  Further to the discussion around complexity earlier we also look further at Model complexity. The problem with having too many parameters is that it can cause overfitting, while a model with too few parameters can lead to underfitting, either option is not ideal.  To ensure we balance model complexity with model performance we can use regularization techniques, these can include L1 and L2 regulations which can be used to give penalties to large parameter values and encourage much more sparsity in our mode.  Regularized linear models  Regularized linear models are a type of linear regression model that includes a penalty term in the cost function to control the complexity of the model. Two common types of regularization are L1 regularization, which encourages sparsity in the model by penalizing large coefficients, and L2 regularization, which  Linear regression for feature selection  Typical methods for feature selection include Principal Component Analysis (PCA), correlation-based feature selection, and recursive feature elimination. The choice of feature selection method depends on the specific challenge at hand and the features present in the dataset. Linear regression can also be used as a strategy for feature selection to identify the most significant features in a dataset. The main concept behind this is to assess the strength   of the relationship between each feature and the target variable. By using linear regression, features with the highest absolute coefficient values can be identified.  