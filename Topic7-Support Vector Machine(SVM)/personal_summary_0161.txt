 Linear regression: It is a technique for modelling the connection between a dependent variable and one or more independent variables. It entails developing a linear hypothesis and determining the best line of fit to a given dataset. Logistic regression: It is a method for solving binary classification issues. It entails training a logistic regression model by minimising the logistic loss function, which calculates the difference between predicted and actual values. Model Complexity: The trade-off between bias and variance in a model is referred to as model complexity. Overfitting happens when the model is very complicated and closely matches the training data, resulting in poor performance on fresh data. Bias-variance decomposition is a method for identifying the causes of error in a model. Regularizer (L1 and L2): Regularisation is a strategy for preventing model overfitting. L1 and L2 regularisation are two types of regularisation algorithms that are often employed in machine learning. L1 regularisation adds a penalty term to the cost function to encourage model sparsity, whereas L2 regularisation adds a penalty term to encourage tiny weights.  