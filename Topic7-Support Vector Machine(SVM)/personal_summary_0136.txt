The main topic this topic is the accuracy of supervised models. Including linear regression, regression model, regularization, python practice  Linear regression  The linear regression model is the relationship observed data fitting a linear equation between two  variables.  The  Pearson  correlation  coefficient  measures  the  linear  correlation  between  two variables. When the output has only two possible values, we call the problem a binary classification problem. If there are more values, this is a multiclass classification problem.  Regression model  The model complexity of linear models increases with the number of features. We ultimately need to use the model to make predictions. If we have data to test, we use mean squared error (MSE), mean  absolute  error  (MAE)  or  explained  variance  (R^2)  to  evaluate  the  performance  of  linear regression models. The core of logistic regression is Logistic regression.  Normalization  The data may contain some noise value. Incorporating noise into the training data can lead to overfitting.  Make  predictions  uncontrollable.  Mathematically,  we  can  use  bias-variance decomposition to avoid noisy values. A regularizer is an additional term in the loss function to avoid overfitting. There are L1 Regularisation (LASSO) and L2 Regularisation (Ridge).  Python practice  Implement  linear  programming  in  Python  code  and  L1  Regularization  (LASSO)  and  L2  Regularization (Ridge) through logistic regression code.  