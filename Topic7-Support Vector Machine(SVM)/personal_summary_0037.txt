In topic 6 the unit covered focused on assessing the training model. The content firstly covered a summary of the regression models, and touches on linear and logistical models, before introducing risk minimization. Multiple methods for calculating distance / risk are introduced for both linear and logistical regression as well as model complexity and regularisers. The last topic touched on is implementation of these concepts in Python.  Regression is the distance between a data point and the line / equation that models the data. This calculation can be done at the data point level and aggregated to the model level to give an overall indication of the performance of the model. The goal of any model is to reduce the distance of the line from the data in both testing and operation (not just testing).  Linear regression is a type of regression that aims to find a linear relationship between the variables. While, logistical regression is a type of regression that aims to model the probability that independent variables will give a binary output of a dependent variable. For each type of regression different aggregate error methods are used. Linear regression can use Mean Square Error, Root Mean Square Error, Mean Absolute Error or R2 methods. Logistical regression can use Accuracy, Precision, Recall and F1-Score methods.  Model complexity (as covered in previous topics) is a term used to specific the complexity of the machine learning model. When creating a model there are two main issues, overfitting and underfitting. Overfitting occurs when the model is too complex and fits the training data too closing, but performs poorly on new data. Underfitting occurs when the model is too simple and performs poorly on both training and new data. Model complexity can be further analyzed by looking at bias and variance. Bias is the measure of the model’s variance from the true values, while variance measures the degree that the model varies from the training data. The relationship between these two attributes is captured by the bias-variance trade-off, which states that high bias → low variance and low bias → high variance.  The next topic covered is the Regularisation, a technique to prevent overfitting in machine learning. L1 and L2 regularisation are two of the most common types, and the ones covered by the unit. L1 regularisation is also known as LASSO (Least Absolute Shrinkage and Selection Operator). This technique adds a penalty term to the cost function of a model that is proportional to the absolute value of the coefficients of the model. This additional term aims to move the minimize the coefficients, to reduce overfitting. This technique is best used when there are a large number of features, and some features are irrelevant. L2 regularisation, also known as Ridge regularization, adds a penalty to the cost function of the model that is proportional to the square of the coefficients of the model. Similarly, to L1, the penalty term helps to reduce the coefficients. This technique is best utilized when the number of features in a model is small and the features are relevant.  The last unit topic is the implementation of these techniques in Python.  