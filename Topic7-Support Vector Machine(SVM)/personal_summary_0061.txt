Associations and covariances between features or variables  Linear regression attempts to model the   relationship between two variables by fitting a linear equation to the observed data. That is, an equation that is graphed as a straight line.  In linear regression, the training data is in the following format:  xi、yi、i=1、... 、n.  For each data point (feature vector) xi, the output is yi, which can be any real value. I'm looking for a specific relationship between features and outputs.  We can measure the linear relationship between variables  x (which can have many dimensions) and output y (for now assume y is only one-dimensional),  covariance .  Simply put, covariance is a specific measure of the amount of information. xi can provide yi. Cov(x、y).  It is calculated as follows:  Number of Pearson phase relations  Another interesting measurement is the  Pearson correlation coefficient. This is a measure of the linear correlation between two variables.  X and .  has a value between  +1  and −1 where 1  indicates a total positive linear correlation, and 0  indicates a total negative linear correlation of  −1, not a linear correlation.        In summary, the most important features of this measurement are:  §  Measures the linear relationship between two variables. Let's say that  =X 2 Should we expect a high value of Pearson's correlation coefficient?  No!  They are not linear equations because they are not related to linear.  Note: Pearson's correlation coefficient is about linear relationships. Range between −1 to 1 The closer you are,  the stronger the  positive relationship The closer to 0, the weaker the  barrier The closer -1, the stronger  the negative relationship  § § § §   Linear regression formulation  In linear regression, we want to find a line like h Linear equations allow you   to summarize and examine the relationship between two continuous (quantitative) variables. First, define the line (see figure below).  Linear hypothesis  So how can you find a straight line? This line has two parameters.  ω, straight line slope, and b and y line interception. Given these two parameters, you can use them to find a straight line.  Given the points, we can estimate the value of x i y  (xi).   We will call you for a quote y(xi). Thus the row predicts y(xi) for xi.  Now, if x is not a single-dimensional value?  The problem may have multiple single functions, so the problem may be in the d dimension. In this case, we would write linear regression as:       where xis a dummy feature with a value of i 0.  xi 0=1 and also ω0=b.   As you can see, dimensioned formulas are almost identical to single-dimension formulas.  The only difference concerns the multiplication of .  ω and x what should be treated as a whole d dimensions of the introduced formulation. Using vector notation, the above can be written as:  D+1D vector using Yi = xi^Tω.  For i=1,... , n We have:  How do you align this line with a data point?  But before that, let's find out what is the error of value prediction in regression.  The difference between   the predicted value  and the true value or output of that point is considered an error.  Displays errors for data points i and ei:  The above formulation is just the average of the squared error function that has already been introduced as a good measurement of regression problems. But how do we solve this minimization problem?      As with other optimization problems, using a closed-form function allows the derivative of the error function to ω and set it to  0.  Then use ω which will minimize this error.  Why is the derivative w and not x?  The answer is simple. Remember that there is a feature vector of data points.  x And we are looking for a suitable w to align with the line of the feature vector. So, taking the derivative of the error function and making it 0, we know that:   Linear classification  Logistic regression is a good regression analysis to perform when the output value of a feature vector is binary  .  Like all regression analysis, logistic regression is predictive analysis. Before talking about logistic regression, let's first review the linear classification.  Confirmation of linear classification  Consider the following set of training data:  {xi、yi} i=1、... 、n.  For each data point xi, the output is yi, which can take discrete values.  0/1、−1/+1、or{1、2、... 、K}.  If there are only two  possible values in the output  , the problem   is called a binary classification problem. If there are more values than that, it  is a multiclass classification problem.  But what does linear classification mean?  Linear classification means that  the separation boundary between any two classes is linear. This is just a hypothesis. That may not be true!  We start with linear assumptions and later derive more complex scenarios.       From a regression perspective, is a consecutive and distinct number,  and the classification is nonlinear in nature.  Two instances x i  and yi their output may be different, but they may belong to the same class. Take the red bubble in the figure above as an example. You can see that these are completely different points, but they have the same class label because they are under the line. They are in the same class, but not in a straight line with each other.  So how can this nonlinear ambiguity be handled in the form of regression?  Let's assume it's just a regression case. Next, treat nonlinearity as follows: h(x)=x^Tw.  So basically we project x  to a new line h(x)  Logistic recursion  But how can we determine the classification?  It seems that we need another function, such as the decision function δ(h(x))  using a fixed nonlinear link function and using h(x) )  at [0,1]  intervals.  So if the final score is close to 1, label that instance label  1.   If it were closer to 0, we would call it a label 0 and if it was closer to the middle   0 and 1  it would be  much closer to the decision boundary and it would not be very clear which side it should be classified on.  This is a very simple example of a logistic regression approach. In conclusion:     Therefore, two approaches are generally available:  §  Ignore Nonlinearity: Use Least Squares for Classification: Treats binary output like the output of a regression problem. This may not be the best way, but it's easy.  §  Using link functions:  Another approach is to use the conditional probabilities of the class as the output of the regression problem.  P(y=1| | x) other than y.  In other words, it uses a link function to transform the output into a classification scenario. Now, in the simple case, P(y=1| | x) >0.5, you may want to select a class label  of 1 data point X otherwise it seems more logical to select a label 0 for this data point 。  Least squares regression can perform very poorly if the values of the dependent variable at some points in the training data are extremely  large or small compared to the rest of the training data  (see figure below) 。 The reason for this is that least squares is concerned with minimizing the sum of squared errors, so training points with dependent values that are significantly different from the rest of the data have a disproportionately significant impact on the resulting constant. It has been resolved.     Generalizations and complexities  Linear regression has a closed-form solution.  The Python implementation uses singular value decomposition (SVD)  to compute the Moore-Penrose inverse.  X.  If the matrix is X size n×d, the calculation of degree 〇(nd^2) assumes n≥d.  As we can see here n≥d, larger dimensions will have a linear form in their final complexity (n)  and smaller values will have a complex squared form.  d^2.  Overall, 〇(dn^2).  If d≥n, the complexity is 〇(dn^2).  I thought of the linear regression problem as follows:  y=X w  where we used the hypothesis function h(xi)=xi^Tw.  You can use derivative features of the original functionality, such as:  φ(xi) other than xi.  That is, you can create your own functionality. They may even be non-linear!     For example, φ(xij)=[xij,xij^2].  As you can see, we added x^2ij to the feature vector as a new feature. As long as you are using linear formulations, the problem remains linear regression.  For example, h(xi)=φ^T(xi)w  Use linear regression to solve it. This is called a generalized form of linear regression, which employs its own list of features and tries to fit lines based on new features. With expressive features, linear regression is powerful!  Generalization (prediction of invisible data)  After you train a linear regression model, you can start  predicting the output y for the new instance x The prediction output is calculated as follows:  y=x^Tw.  By designating an invisible set of instances as  a test set, you can measure prediction errors as follows:   Logistic regression formulation  Logistic regression is named after the logistic function, which is a function used in the core of the method.  Logistic functions are also called sigmoid functions. This is an S-shaped curve (shown above)  that can take any real value and map it to the values between.  0 and 1 but never exactly reach those limits. The value approaches but does not reach 0 or 1.  Let x be a data instance and have a class of  y label {−1,1}.   Logistic regression does not  directly model in terms x.  Instead, it models what is called logit value or logarithm of odds  via linear regression. So, in general, we are modeling the logarithm of the odds.  x.  But what are the odds  ?  Class odds are defined as −1:     Testing the model  So assume you have trained a logistic regression model and you have come up with proper values of w. Now by having a test point such as x you calculate the value of x^Tw.  § § §  If this value is x^Tw>0 then it means P(y=1|x)>0.5, the point is allocated to class 1. On the other hand, if the value of x^Tw<0 then it means P(y=1|x)<0.5, the point is allocated to class 0. In case of x^Tw=0, your model is confused and it returns the same value for both of them.   Train a logistic regression model       Training a logistic regression model means using the training data to  estimate the regression coefficient vector. w.  When training a logistic regression model, you can estimate using maximum likelihood estimation (MLE).   w.  The likelihood function of  w The use of data (xi, yi) is given as:  Above, we assume a Bernoulli distribution because  the yi output is in binary format.  But how did we come up with this likelihood function?  Let's look at the mathematical derivation:  Also when y=−1 we have:  As you can see P(y | x) is:  When y=1 the  above formula looks like this:  When y=−1 the  above formula looks like this:       Thus, the  use of the likelihood function w data (xi, yi) is given as follows:  Assuming training data nindependent instances {(x i,y1),... , (xn, yn)}, joint likelihood is:  Therefore, the combined likelihood function is n  independent  samples using training data is the multiplication of the likelihood of each point.  Logistic Loss Numbers  Maximizing likelihood is the  same as maximizing the logarithm of the likelihood function. This is because they both provide the same solution.  w.  Recall that the logarithmic function is a monotonically increasing function, so you can find the maximum or minimum value of the function even if you get the logarithm of the function. Therefore, you can create a log for the likelihood function by taking the following log:  ι(w) as:       Maximizing log  ι(w) is equivalent to minimizing −log ι(w), which causes the following minimization problems:  But how do you add the above function to w?  Recall that we want to minimize the following function:  Counting the minimum value  Before answering this question, let's review the differences between the two types of functions: Convex and Non-convex. Think of the following illustration as a diagram of two types of functions.  The basic differences between the two categories are:  §  §  Convex optimization can handle only one globally optimal solution. Another possibility is to prove that there is no viable solution to the problem  (image to the right above). In a non-convex optimization, there may be more than one locally optimal point. It can take a lot of time to determine if the problem has no solution or if the solution is holistic (image on the left). Therefore, the time efficiency of convex optimization problems is much better.        Then:  §  §  In some cases, you can derive a minimother closed-form equation (such as linear regression).  This means that the minimother can be calculated in one step. If there is no expression in closed form, you will have to repeat several steps to reach the minimum value. (e.g. Logistic Regression and Kmeans)  Recall that gradient descent uses knowledge of derivatives to maximize functions. The Newtonian method, on the other hand, is a root-finding algorithm, which uses knowledge of the function's quadratic derivative to maximize the function. This  is faster when the second derivative is known and easy to calculate. However, the analytical equations for the quadratic derivative are often complex and cumbersome, requiring a lot of calculations.  Gradient descent optimization per coordinate  Now, let's go back to the gradient descent optimization by coordinates. To fulfill our original mission. First, randomly initialize w. modify all but one variable. That is, for each j, the optimization ωj,  the modification ω1, ... 、ωj−1、ωj+1、... 、ωd.  Next, minimize the objective function with respect to .  Use the  ωj gradient  descent as follows:       Model complexity  Therefore, if you increase the variance of the model, you can see that the bias decreases as the model becomes more complex. On the other hand, we can see that the lower the complexity of the model, the greater the bias and the smaller the variance. Therefore, a high bias results in low variance, and a high variance results in a lower bias.  This illustrates another trade-off problem in machine learning.  Basically, you don't have to worry about noise, so you can only minimize  bias and dispersion.  σ^2 for now. Noise is related to observations from the function.  Variance bias tradeoffs  To better illustrate the trade-off between variance and bias, examine the following diagram. As you can see, the best model is one with low variance and bias. This means that the model is not too complex and is adequately accurate. The worst model is highly biased, which means it's not accurate based on the training data, which means it's too variance and too complex.         Regularized linear model  Shadow of regularization  Consider the diagram below. The image on the left shows the effect of regularization.  The l1-norm  forms a square, assuming that the loss function is an ellipse in the plot. Since we are minimizing the loss function that actually has 1  - Norm regularization requires finding the sweet spot, which is the intersection of these two areas. If you continue to draw the ellipse, you will find the intersection.  The image on the right shows the same concept using different regularizers l2 - circular norms. As you can see from this figure, there is a high probability of intersection. The probability of hitting is also low because the  0 weight β 1  or ω1 and β1 or  ω 2 because it seems that more options can be selected  ω1 and ω2.  where lp−  is the norm regularization of the following.  As you can see,  the l 1  norm  regularization uses square regularization (pink square) and l 2− a regular (light blue ) to standardize. The ∞-norm regularization is also square (red). Keep in mind that all these lp norm regularization penalizes greater weights.  p≤1  tends to create sparse weights  (i.e. many zero-weights). Higher values  tend to favor similar smaller weights . Next, we'll look at two regularization methods: LASSO and Ridge  .   L1 regularization (LASSO)  Lasso ( Least Absolute Shrinkage and Selection Operator )  (also shown in uppercase: LASSO)  is a regression analysis technique that performs both selection and regularization of variables to improve the prediction accuracy and interpretability of the generated statistical model.  Therefore, it is very common to use the following formulation:  Now we can see the normal risk function + l1-norm regularization. Another method of regularization is called ridge.  L2 regularization (ridge)  The general formulation of the ridge is as follows:     What is the effect of regularization on bias and variance?  Regularization has been found to increase model bias.  You're just listening to part of the training data.  Why regularization makes sense This is because the variance is greatly reduced.  In conclusion, the net effect (i.e. bias)2 + variance) is reduced. The following diagram shows the effects of bias and variance on model complexity. As you can see, there are trade-offs or complications of the best model that we are always looking for.   Linear regression for feature  selection  Linear regression of feature selection  Principal component analysis (PCA), correlation-based feature selection, and recursive feature removal are typical feature selection methods. The specific issue at       hand and the features in the dataset will determine which feature selection method to use. To find the most important features in a dataset, you can use linear regression as a feature selection strategy. The basic idea of using linear regression for feature selection is to assess the strength of the relationship between each feature and the target variable. Features with the highest absolute coefficients can be found using linear regression. Find out further for further knowledge of this idea of using linear regression in the feature selection process.  