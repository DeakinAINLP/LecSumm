This topic we expanded our understanding on supervised learning models to include logistic regression and regularised learning models.  Logistic regression – A supervised machine learning model used to predict binary outcomes. The model calculates a weighted sum of the input variables, which is then transformed into a probability value between 0 and 1.  Loss function – Used to measure the difference between the predicted output and ground truth. By minimizing the loss function, the model learns to make better predictions and becomes more accurate in its task.  Overfitting data – Occurs when a model learns to fit the training data too closely, to the point where it starts to capture the noise and random fluctuations in the data instead of the underlying relationships.  Underfitting data – The opposite of overfitting data. Occurs when a machine learning model is too simple or too rigid, and it fails to capture the underlying patterns and relationships in the data.  Regularised regression models – These models aim to prevent overfitting by adding a penalty term to the standard loss function that the model is trying to optimize. This penalty term is designed to discourage the model from becoming too complex or having large parameter values.  