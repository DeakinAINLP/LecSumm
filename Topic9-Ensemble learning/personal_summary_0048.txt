 The main topics covered this topic were supervised learning, specifically focusing on K Nearest Neighbor (KNN) and Decision Tree. The lecture emphasized the significance of understanding Euclidean distance and determining the optimal number of neighbors. It also explored the Decision Tree classifier, highlighting the differences between KNN and the tree classifier approach, as well as the advantages of KNN. Additionally, we learned about the implementation of KNN and Decision Tree using the sci-kit processes in Python. This included training data, evaluating on test data, and utilizing different kernels for improved performance. Overall, the lecture provided a comprehensive understanding of KNN and Decision Tree.  