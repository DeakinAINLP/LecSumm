Main points of this module:    KNN (K-nearest neighbour) is a technique of assigning weights to the contribution of data  points in such a way so that the nearest neighbours contribute more than distant points, this is useful for both regression and classification.    A continuous valued target function uses the mean value of the k nearest training examples.   A discrete class label uses the mode of the class labels of the k nearest training examples.  Lower values of k will result in a low bias and high variance.   Higher values of k will result in a high bias and low variance.   Decision trees are maps of the possible outcomes of a series of related choices and can be  used to weight possible actions against each other based on costs, benefits, and probabilities.    Regression trees are a type of decision trees with a regression model.   Classification and Regression Trees (CART) are decision tree algorithms that can be used for  either regression or classification modelling problems.    The Gini index is the most commonly used measurement of inequality.   The ID3 algorithm aims to calculate the entropy of every feature, splitting the data into  subsets where entropy is minimum, make a decision tree containing that feature, and recurse on subsets using remaining features.    Pruning is a technique that reduces the size of decision tree by removing section that  provide little power to classify instances.    Pre-pruning is when we decide to stop adding nodes during the building process.   Post-pruning waits until the building process has finished before pruning via subtree  replacement.    Advantages of decision trees include being easy to understand, capable of modelling  nonlinear functions and can handle categorical data.    Disadvantages of decision trees include being sensitive to small changes in data, may overfit easily, can only handle axis-aligned splits and trees may not be as competitive in terms of accuracy.  Provide a summary of your reading list:  I just followed the given study material (8.1 – 7.14), reading everything until I understood it confidently, as well as viewing any linked videos provided. This topic I actually didn’t end up needing to spend that much time on the problem-solving activity. The first question was very similar to last topic’s problem-solving activity, so I only had to modify my old work and compare results.  