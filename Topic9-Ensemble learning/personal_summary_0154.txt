 Topic 8 was mainly about KNN and desicision trees. KNN is a supervised learning technique that may be applied to both classification and regression applications. By taking into account the majority vote or the average of the values of a data point's closest neighbours, it categorises or forecasts the target value for that data point. The mode of the class labels is utilised for discrete class labels and the mean of the nearest training examples is used for continuous target values. With weighted KNN, neighbours are given different weights dependent on how far away from the test point they are, with a greater distance corresponding to a lower weight. This can help give close neighbours greater significance. Maps of potential outcomes based on a succession of options or decisions are called decision trees. They can be applied to jobs requiring classification and regression. Regression trees use the mean of the response values in each region to produce predictions by segmenting the feature space into distinct, non-overlapping parts. Test instances are assigned by classification trees to the dominant class in the region to which they belong.  