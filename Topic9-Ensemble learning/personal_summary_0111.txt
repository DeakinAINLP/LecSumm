The topic for this topic is Nonlinear Models (KNN and Decision Tree)  Topic 8 summary  KNN Algorithm: The basic idea is to label the test data point is the same as the nearest neighbor (NN). This is useful for both classiﬁcation and regression.  Voronoi Diagram: It is a type of diagram that has sca(cid:425)ered random points (n) on a Euclidean plane.  Decision tree: A decision tree is a map of the possible outcomes of a series of related choices.  o  o  It is used to weigh possible actions against one another based on their costs, beneﬁts and probabilities. It starts with a single root node, which branches into possible outcomes.  Classiﬁcation tree: It refers to a decision tree algorithm that can be used for classiﬁcation or regression predictive modeling problems.  o  Gini Index: It is a measurement of inequality. The minimum value of the Gini Index is 0. This  happens when the node is pure.  o  Entropy: Entropy is a measure of information that indicates the disorder of the features with the  target.  Decision tree algorithms:  ID3 (Iterative Dichotomiser 3) uses entropy.  1. 2.  C4.5 (successor of ID3) slightly more advanced version of ID3 and uses entropy. 3.  CART (Classiﬁcation and Regression Tree) uses Gini Index  Pruning: It is a technique that reduces the size of decision trees by removing sections of tree that provide li(cid:425)le power to classify instances.  o  Pre-pruning: we decide during the building process when to stop adding nodes.  It eliminates  unnecessary complexity of model.  o  Post-pruning: Post-pruning waits until the full decision tree has been built and then prunes the  a(cid:425)ributes by subtree Replacement.  Decision Tree Advantages:  o  Very easy to understand, as they represent rules. o  Capable of modelling nonlinear functions.  Decision Tree Disadvantages:  o  Sensitive to small changes in the data. o  May overﬁt easily.      