Summary – Topic 8   We use weights and assign them to the contribution of data point neighbours in clustering  algorithms so that the nearer neighbours contribute more to the average than more further  ones.   We can perform cross-validation on every possible number of K = 1, …, Kmax and assess  the model based on training and test data.   A decision tree is a map of all possible outcomes of a given series of interconnected choices   Decision trees are utilized to weigh possible actions against one another on the basis of  their costs, benefits, and probabilities.   Regression trees are simply decision trees that use a regression model   The overall aim of regression trees is to find regions R1, R2,…, RJ which minimises the  training error as shown below:     Classification and Regression Trees (CART) is a term introduced by Leo Breiman to make  reference  to  decision  tree  algorithms  that  can  be  used  for  classification  or  regression  predictive modelling problems.   The Gini index represents the measure of inequality and is calculated as :         Entropy is calculated as :     The ID3 algorithm was developed by Ross Quilan in 1975 and is used to create a decision  tree from a dataset.   When it comes to pruning, it refers to a technique that reduces the size of decision trees by  getting rid of trees that provide little power to classify instances.  Quiz        