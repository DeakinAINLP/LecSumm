 This topic's subjects were K-Nearest Neighbours (KNN) and Decision Trees (DT). We learnt about KNN and its variations, the effect of distance measures on performance, and how to estimate the optimal number  of  neighbours  (K)  for  a  particular  task.  We  explored  regression/classification  trees,  the methods that build them, and how to utilise them to make predictions for DT. We also discussed model complexity and pruning approaches for improving model accuracy. Finally, we examined the benefits and drawbacks of decision trees, as well as the relevance of feature selection when employing them. Overall,  the  subjects  this  topic  concentrated  on  various  machine  learning  approaches  for  both supervised and unsupervised learning issues.  