 Ans: KNN algorithm is useful for both classification & regression.  ➢  KNN is simplest form of machine learning technique that classifies the datapoints on how its  neighbor is classified.  ➢  Voronoi diagram is a partition of a plane into regions close to each of a given set of objects. ➢  Shepard's method is a variation on inverse power, with two different weighting functions using  two separate neighborhoods.  ➢  As the value of K gets larger the decision boundaries will have lower variance but the bias will be  increased.  ➢  Decision trees is a hierarchal model that uses tree-like structure to compute the decisions &  their plausible consequences.  ➢  Types of decision trees: Regression trees, classification trees. ➢  Regression trees partition a data set into smaller groups and then fit a simple model (constant)  for each subgroup.  ➢  Classification tree is almost similar to regression tree except that it is used to predict  a qualitative response rather than a quantitative response.  ➢  The lower the Gini Index, the better the lower the likelihood of misclassification. ➢  Decision tree algorithms are : ID3 , C4.5, CART, where ID3 stands for Iterative Dichotomiser 3  ➢  which is a learning algorithm for Decision Tree. Iterative algorithm where a subset(window) of the training set is chosen at random to build a decision tree.  ➢  Complexity of model & pruning where the latter reduces the size of decision trees by removing  parts of tree that are less useful in classifying the instances.  ➢  There are two ways of pruning , pre-pruning & post- pruning where the former tells when to stop adding nodes & the later removes or replaces the unwanted branch once the final tree is built.  ➢  Pro’s of decision tree is that it is capable enough for modelling non-linear functions while at con  side it may overfit easily. Implementation of KNN algorithm & decision trees in python.   