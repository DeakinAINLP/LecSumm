In  this  topic  explored  the  supervised  learning  in  KNN  and  Decision  Tree.    In  KNN  the hyperparameter is K.  Basically, when a data point is closer to the prediction, it gives a higher rate in the prediction. K controls the shape of the decision boundary. To find the best K, can select the range of K values to test, and then by using cross-validation to see the score of accuracy, precision, recall and f1 score. Evaluation model by comparing the result to find out the best performance.  About decision tree is a map of the possible outcomes of a series of related options. It is easy and simple to interpret.  