The key points covered in topic eight are:  1.  Non-linear models such as kNN and decision trees.  There are no assumptions of linearity  between the features and targets.  2.  K nearest neighbours classifies a sample based on how the k nearest neighbours are  classified.  The distance metric to use for calculating the nearest neighbour is an important consideration.  This is not as intuitive and best distance metric to use may ultimately depend on the dataset.  3.  The choice of k for kNN is the most important hyperparameter that needs to be determined. 4.  For decision trees, the best features are selecting to split the tree based on information gain. 5.  Decision trees have the advantage of being very interpretable and the model is easily understood by visualising the tree.  However, decision trees are prone to overfitting. Important features can be identified using decision trees.  