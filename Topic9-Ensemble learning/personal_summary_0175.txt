In  this topic  we  learnt  about  K-Nearest  Neighbors(KNN)  and Decision Trees.  Both of  them  are  part  of Supervised Learning. ChatGpt is an example for Supervised Learning. In KNN nearest neighbors are being used to make the predictions. It works for classification, regression, recommendation models etcetera. In KNN, the "K" refers to the number of nearest neighbors to consider when making predictions. K controls the shape of the decision boundary. Small values of K results in low bias and high variance and high values increases bias and reduces variance. Cross validation or evaluation model can be used to find the best value of K. Learning in KNN is simple but the classification is time consuming for large datasets.  Decision tree make decisions based on a tree model. It can be defined as a map of the possible outcomes of a series of related options. It weights possible actions against one another. Decision trees starts with a single  node  and  branches  into  different  possible  outcomes.  For  regression  tress,  It  is  computationally infeasible to consider every partition of feature space into regions, hence a top down, greedy approach known as recursive binary splitting is used. In classification trees, classification error is being less sensitive for tree-growing hence it is not wise to use classification error as a constraint for making binary splits of trees. More sensitive measures like Gini Index(G) or Entropy are being commonly used instead.  In the last topic, we also learnt how to calculate Gini Index and Entropy in a mathematical way. Three popular  decision  tree  algorithms  are  ID3(Iterative  Dichotomiser  3),  C4.5,  CART(Classification  and Regression Tree). Pruning can be used to reduce complexity of decision tree models. Pruning is used to reduce the size of decision trees. Pre-pruning or post pruning are two way to prune trees. Post pruning waits  until  the  full  decision  tree  model  has  been  built  and  then  prunes  the  attributes  by  sub-tree replacement. Decision trees have various advantages like they are very easy to understand, capable of handling  non-linear  functions,  able  to  handle  categorical  variable  etcetera.  Moreover  it  has  certain disadvantages  like  its  sensitivity  to  small  changes,  chances  of  over  fitting,  performance  is  not  in competitiveness with other models like KNN, SVM etcetera.  