Summary â€“ Topic 7    Topic 7 is more focused on SVM formulation and finding a solution for linearly separable  data    The optimisation problem being solved in our context is:    Lagrange  multipliers  is  a  method  of  finding  the  local  maxima  and  minima  of  a  given  function to equality constraints    When it comes to finding a solution for linearly non-separable data, we face the trade off  between the margin and the number of errors in classifying the training instances which  leads to the soft margin concept as depicted below:        SVM with soft margin will utilise the following formulation:    The dual problem is demonstrated as:    The following diagram  shows what  happens  when we try to  separate 3 points with  any  combination of labels:  It is also worth noting that we define The Probabilistic Guarantee as :       