   SVM formulations aims to find a hyperplane so that margins are maximized while  satisfying the constraint   Quadratic programming    Using Lagrange multiplier can convert a constrained optimisation into an  unconstrained optimisation problem    Data can be linearly separable but with narrow margins, due to noise some instances  can not     In practice we need a trade off between the margin and the number of errors in classifying training instances    Soft margin, Some data points can cross the borders and be on the wrong side,  misclassification of outliers, noisy or difficult to classify instances.     VC dimension, shattered by a line, 4 points that can not be shattered by a single line  can be broken with two.    Multi class calssifacation in SVM, one vs all or one vs one.   One vs one trains multiple binary classifiers each trained to distinguish between two  classes             