 Two main points were covered in this topicâ€™s topic including linear SVM and non-linear SVM  SVM formulation and solution for linearly separable data  Support Vector Machines(SVM): Supervised machine learning model that uses classification algorithms for two-group classification problems. After giving an SVM model sets of labelled training data for each category, they're able to categorize new text.  Hyperplane: A plane of dimension one less than the dimension of data space, which divides the classes of data and that is the main aim of SVM  Dual problem is equivalent problem to the primal problem in SVM optimization. By using lagrange multipliers, the constrained optimization problem is transformed into an unconstrained optimization problem.  SVM formulation and solution for linearly non-separable data  Soft margin: Allows for some misclassification of outliers or difficult instances. Slack variables are added to the SVM formulation to account for misclassifications  The soft margin dual problem: The primal problem with soft margin is transformed into its dual form. The hyperplane equation and the classification function are derived based on the solution to the dual problem, similar to the formulation for linearly separable data.  Kernel trick and non-linear SVM  Linear regression aims to find a line that summarises the relationship between two continuous variables.  The error in regression is defined as the difference between the predicted value and the true value. The goal of linear regression is to minimize the empirical risk using the square loss function.  Support vector regression  SVR is different from traditional linear regression methods as it finds a hyperplane that best fits the data points in a continuous space, instead of fitting a line to the data points. SVM is used to categorical target variables whereas SVR is used for continuous target variables  Multi-class classification in SVM  In the One vs All approach, for each class, a binary SVM classifier is trained with samples from that class as positive examples and samples from the other classes as negative examples.  In the One vs One approach, multiple binary classifiers are trained, each trained to distinguish between two classes.  These approaches enable SVM to handle multi-class classification problems by breaking them down into a series of binary classification tasks.  