 In topic 7, we explored several related concepts of linear and logistic regression such as linear SVM and non-linear SVM.  The Support Vector Machine (SVM) is a machine learning algorithm that aims to find a hyperplane to separate data points of different classes. For linearly separable data, the SVM formulation solves an optimization problem known as quadratic programming.  Sometimes, data can be linearly separable but with a narrow margin. But,  due to noise, some of the instances may not be linearly separable.  During this topic, we have learnt how to find linear regression formula by doing linear hypothesis.  Multiclass classification in Support Vector Machine can be done as follows:  One vs all- In this approach,  for each class, a binary SVM classifier is trained with samples from that class being viewed as positive examples and samples from the other classes being viewed as negative examples  One vs One- In this method, the SVM algorithm trains multiple binary classifiers, each trained to distinguish between two classes.                    