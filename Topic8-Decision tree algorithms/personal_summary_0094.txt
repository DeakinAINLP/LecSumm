This topic provided an in-depth coverage of Support Vector Machines for linear and non-linear machine learning problems. We started by exploring the SVM formulation for linearly and non-linearly separable data.  We looked at linear regression formulation and how we can fit a hypothesis on a data set. We also looked at how to apply regression on support vectors.  We learned about the statistical theory behind SVM and how we can separate the data on a hyperplane.  We also explored multi-class classification in SVM and the use of techniques such One vs All, also known as One vs Rest and One vs One .  The second part of the topic focused on the use of the Python programming language and how it can be used in order to perform SVM using various kernels such as linear, polynomial and RBF.  