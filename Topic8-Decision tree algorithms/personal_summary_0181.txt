Summarise the main points that is covered in this topic  This topic we learnt about Support Vector Machine (SVM) for designing accurate classiÔ¨Åers. We also learnt about model complexity and how to tune the hyperparameters.  Support Vector Machine(SVM)  1.  This is a form of Supervised Learning 2.  Can be used as both Classification and Regression 3.  Primarily used for Classification problems 4.  The distance between the support vectors and the hyperplane should be as far as possible. Hence, we are trying to maximise the margin between the different support vectors  5.  Kernel function transforms a n-D data to a (n+1)-D data 6.  Soft margin  a.  This is defined when the training instances are not linearly separable. b.  Hence we define a parameter as slack variable or number of errors which will say  how many data points can be misclassified at most  7.  The parameter C - how much should an SVM care about getting everything right vs getting  the things that it gets right very right  a.  High value of C means the margin is very small between the classes b.  Medium value of C means the margin is bigger but there will be some  misclassifications  c.  Low value of C means that the margin is much bigger and there will be a few  misclassifications. This is to be used when we are more interested in finding the largest or most distinct set of cluster points  8.  The number of instances a hypothesis class can shatter or fit perfectly for all possible label  assignments is called its Vapnik-Chervonenkis Dimension or VC Dimension.  9.  Error for a SVM model can be reduced in either of the two ways -  a.  Reducing complexity of the model b.  Increasing the number of data points  10. We need to scale the data before we fit it into a SVM model  Advantages of SVM  1.  High dimensional input space 2.  Sparse document vectors 3.  Regularisation parameter - checks bias or overfitting of the data 4.  Avoid overfitting by the regularisation parameter  Multi-class Classification in SVM  1.  One vs All  a.  In this approach, for each class, a binary SVM classifier is trained with samples from that class being viewed as positive examples and samples from the other classes being viewed as negative examples  b.  For N number of classes, this approach will generate N models  2.  One vs One a.  In this method, the SVM algorithm trains multiple binary classifiers, each trained to distinguish between two classes.  b.  For N classes, we will have a total of (ùëÅ ‚àó (ùëÅ ‚àí 1))/2 classifiers. c.  Select the class which is the outcome of maximum number of binary classifiers  Types of Kernel in SVM  1.  Linear 2.  Polynomial 3.  RBF  