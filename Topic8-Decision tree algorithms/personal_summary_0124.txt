Support vector regression The basic idea behind SVR is to transform the data into a higher dimensional feature space using a kernel function, which allows non-linear relationships to be modeled. The kernel function is used to transform the data into a new space where it is easier to find a hyperplane that maximizes the margin. SVR is particularly useful when dealing with datasets that have non-linear relationships between the input and output variables. SVR can also handle outliers and is less prone to overfitting compared to other regression algorithms.  Multi-class classification in SVM  There are two approaches for SVM classifier: One vs all, and One vs One.  In the OvO approach, SVMs are trained for every possible pair of classes. This approach can handle unbalanced datasets where some classes have much fewer samples than others.  In the OvA approach, a single SVM is trained to distinguish between one class and the rest of the classes. In both cases, the choice of kernel function, regularization parameter, and kernel parameter can significantly affect the performance of the SVM. This approach is computationally efficient and can be used for large datasets. However, it may be sensitive to the imbalanced datasets.  