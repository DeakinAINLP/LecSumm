Topic 7 Key Learning Points    Support Vector Machines: “Support Vector Machine” (SVM) is a supervised learning machine learning algorithm that can be used for both classification or regression challenges. However, it is mostly used in classification problems, such as text classification  o  SVM for linearly separable data: solving the below minimization problem  o  SVM for linearly non-separable data: It is generally preferred not to interfere  with the boundary even with small noisy data points or outliers. It is acceptable to have large margins even though some of the constraints are violated. In practice, we need a trade-off between the margin and the number of errors in classifying the training instances. This trade-off brings us to the soft margin concept. Consider the following figure; the soft margin concept is defined when the training instances are not linearly separable. Slack variables Ci  are added to allow misclassification of outliers, noisy or difficult to classify instances. So basically we are allowing some of the data points to cross the borders and to be in the wrong side of the boundary or to be misclassified.    How to handle almost separable data points.   Linear regression Formulation       Statistical Learning Theory of SVM   Structural risk minimisation: seeks to prevent over-fitting by incorporating a penalty on the model complexity. This means, it prefers simpler functions over more complex functions. The general idea is to minimise the structural risk as where ℎ(f) is the complexity of hypothesis function f and Lambda is a penalty parameter:    Multi-class classification in SVM  Multiclass classification in SVM can be done as follows:  1.   One vs all 2.  One vs One  