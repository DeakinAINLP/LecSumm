Topic 7 Summary  This topic’s topic is SVM Models.  The SVM (singular vector machines) main objec(cid:415)ves:    It aims to ﬁnd a hyperplane so that the margin is maximized while sa(cid:415)sfying the constraints.  Hyperparameters:    C parameters: It is used as a way to achieve the trade-oﬀ between large margins and ﬁting  training data.  o  High value: Misclassiﬁca(cid:415)on is penalized heavily. o  Small value: Misclassiﬁca(cid:415)on is more tolerated.  Kernel trick for non-linear SVM:  o  Data is transformed into a higher dimension where it can be linearly separated to handle nonlinearity, a(cid:332)er which it is separated and remapped into the original dimension.  Kernel func(cid:415)on: A func(cid:415)on used to compute dot products in high dimensional feature space.  Vapnik-Chervonenkis (VC) Dimension: The number of instances a hypothesis class can sha(cid:425)er.  Methods of SVM:  o  One vs one: The SVM algorithm trains mul(cid:415)ple binary classiﬁers, each trained to dis(cid:415)nguish  between two classes.  o  One vs all: For each class, a binary SVM classiﬁer is trained with samples from that class being viewed as posi(cid:415)ve examples and samples from the other classes being viewed as nega(cid:415)ve examples.                 