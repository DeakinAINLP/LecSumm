 This topic talks about SVM, which is a classifier. First, it introduces its formulas including the margin function and the constraint function but the most frequently used one is the Lagrange multiplier function which units the above two functions into one. It tells us which margin is reasonable and how to be derived. Later it elaborates on how to minimize structural risk, which is vital to over-fitting prevention. Furthermore, it introduces two multi-class classification methods: One vs all and One vs One. Finally, it illustrates how to implement the above-mentioned algorithm using Python. What learned most is the Python implementation of the SVM especially the RBF kernel implementation since it demonstrates the solution of non-linear SVM issues. The difference between Logistic Regression and SVM also impressed me the most. I learned the inference of formulas from some online videos, which helped me a lot.  