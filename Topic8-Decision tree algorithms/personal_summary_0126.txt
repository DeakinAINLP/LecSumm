 The topics that were covered during topic 7 were concepts focusing on Linear SVM and Non-Linear SVM. Then, implementation of SVM in python.  I referred to the unit site contents for learning the topics that were covered in topic 7 along with the external video links and articles provided.  The learning journey started with the basic understanding of SVM formulation and solution for linear separable data, dual optimization problem. Then, I acquired knowledge about SVM formulation and solution for non-separable data, soft margin dual problem. I gained an idea on the concept of linear regression formulation , linear hypothesis and how it can be fitted to data points. Then, I gathered knowledge about support vector regression with an example of linear regression. Then, learnt about statistical theory of SVM in which the number of instances a hypothesis class can shatter which is called the Vapnik-Chervonenkis (VC) dimension illustration was also learnt along with the probabilistic guarantee. I gained an understanding of multi-class classification in SVM which can be done in two ways namely one vs all and one vs one. Finally, I acquired knowledge on implementation of SVM in python with linear kernel, polynomial kernel and using RBL kernel in which two parameters C and gamma are used.  