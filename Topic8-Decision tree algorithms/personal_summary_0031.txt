SUPPORT VECTOR MACHINE:  Linked to linear regression. An algorithm that can handle classification and regression problems for both linear and non-linear cases. SVM comes in Linear and Nonlinear forms. Linear form has two subtypes: perfectly separable (linearly separable) datapoints, and almost separable (linearly inseparable) datapoints.  Have an efficient training algorithm. Derived from statistical learning theory. SVMs are highly popular due to their efficient algorithm and can achieve high accuracy with sufficiently large training sets (99% accuracy for digit recognition).  Considered a complex model (especially for the time it was created).  Aim is to learn support vector. I.e. draw a line of separation between classes (classification labels). But can also be used to draw a regression line using Support Vector Regression (SVR). The question is if multiple lines can be drawn between classes, which is the best to use? There could be infinite choices. This is called the solution space. SVM can find the best line in the solution space.  To find the best line, the decision boundary needs to be as far away as possible from both data classes. Each class group has a border line between it and the decision boundary. The space between the borderlines is called the margin. The model needs to learn the margin and maximise this space, which minimises classification conflicts.  New data may be placed on the wrong side of its class border line. When this happens that data instance is considered misclassified. An SVM model may have a degree of tolerance to misclassification (linearly inseparable cases) or not (linearly separable cases). The degree of tolerance depends on the model, but ultimately this should be minimised. Support vectors can be used for regression, using what’s known as Support Vector Regression (SVR). SVR also defines a boundary line and a margin. However unlike SVM this time the boundary is used to contain the data instances – those outside are considered deviations. Thus the boundary will form a curved tube shape. This model of regression is considered complex and less popular than some alternatives.  MAXIMISING MARGIN:  Decision boundary in multiple-dimension space is known as the hyperplane.  Euclidean Distance needs to be found between each data point to the decision boundary. The shortest distance is perpendicular to the plane. If the minimum distance of the hyperplane to any instance is r, the support vectors are at r distance from the plane. The margin is the distance between these support vectors, and is thus 2r. This can be derived from w, the normal direction of the plane (the slope, as with linear regression).  This hyperplane is represented as f(x) = wT.x + b  To find w and b, SVM solves the optimisation problem:  Maximise: 2/||w|| subject to: (yi(wTxi + b) >= 1, for all i  This primal problem is a quadratic programming function with linear constraints. Solving it requires an unconstrained form.  Convert into a minimisation problem (minimise 0.5*w^0.5), then use Lagrange multipliers to convert into unconstrained form. The resulting dual problem is no longer in respect to W or b. Instead becomes dependent on alpha, the Lagrange multipliers. This derived problem represents the similarity of the two vectors, xiT.xj.  The time complexity is O(d^3) for the primal problem, but O(n^3) for the dual problem. Where d is the dimensions and n is the number of samples. The dual problem also allows for the usage of Kernals.  LINEARLY INSEPARABLE DATA POINTS:  Some datasets are almost separable, meaning that a hyperplane can be drawn between classes but with little to no border. Essentially outliers from classes show up too near to other classes. This is a bad line, as it can lead to easy misclassification of new data. To solve this we require a level of tolerance to misclassification in the training data. This is called soft margin. The soft margin tries to find the trade-off between the margin and the number of misclassifications. While some constraints may be violated, this should be minimised.  Some data instances may cross the borders. Slack variables are added to keep track of these. Slack variables for correctly classified data points are 0, misclassified are not. The sum of the slack variables needs to be minimised to minimise the misclassification. Noisy data, difficult to classify data, and outliers may end up crossing these borders.  There is a parameter, C, that is used for this trade-off. High values of C highly penalize misclassification, while lower values of C allow more misclassification. In other words the number of outliers allowed depends how high the value of C is. Too many or too few will lead to poor generalization.  KERNAL TRICK:  The kernal trick comes into play for non-separable data sets.  The trick is to transform the dataset into a linearly separable form by transforming it to a higher dimensional space. Then the hyperplane between them can be found. The problem is how to find appropriate values of each data instance on the new axis.  To achieve this transformation a kernel function is required. Kernal functions compute dot products in a high dimensional feature space. SVM implicitly performs the transformation as all computations are done in dot- product form. Replacing these dot-products with kernels performs the transformation. The kernels act as mapping functions.  According to Mercer’s theorem, every positive, semi-definite and symmetric function is a kernel function. On evaluation each pair of data instances becomes a cell in what’s called a Gram matrix. For N data instances, this will create an NxN Gram matrix, with each cell containing the result of the kernel function applied to that cell’s pair of data instances k(xi, xj). The kernel function can be Linear (dot product of xTi, xj), Polynomial (with degree p), radial basis function (RBF, which can be infinite dimensional), or others. Linear kernel will produce a linear boundary. Polynomial kernel requires optimisation of both C and p. The degree of p changes the nature of the boundary, higher degrees creates more flexible (curved) lines, which can lead to overfitting if p is too high.  STATISTICAL LEARNING THEORY OF SVM:  Highly complex models lead to overfitting, so structural risk minimisation is used to prevent this by applying penalties to model complexity. The overall goal is to reduce structural risk, which is the sum of empirical risk and the complexity of the hypothesis function under a penalty. STR(f) = EMP(f) + P*H(f). So validating an SVM model requires determining its complexity.  One measurement for this is Vapnik-Chervonenkis Dimension (VC). In this measurement hypothetical class labels are applied to N data instances. If the hypothesis class can learn these associations then it is sufficiently complex. The VC dimension can be found by finding every possible variation of class label. Then, for each case try to separate the data with a single line. For the highest number of N that every variation can be differentiated, the dataset has that N of VC dimensions. In practice this means that for D dimensions the model will have a minimum D+1 VC dimensions.  This means that the model complexity can be minimized by maximizing the margin, p, regardless of dimension size. Thus maximising margin size decreases complexity and thus reduces risk of overfitting.  MULTI-CLASS CLASSIFICATION IN SVM:  Comes in two forms: one vs all, one vs one.  For one-vs-all for each class the dataset is split into two groups, the class being viewed and the others. These form the positive and negative classes respectively. For each of these cases a binary SVM model is deployed. This is repeated for all classes. So for classes X, Y, Z we’ll compare X vs (Y and Z), Y vs (X and Z), Z vs (X and Y). Each model will generate a score, and each data instance will be classified under the model with the highest score for that data instance (if instance A is classified as 0.5 for X, 0.2 for Y, and 0.8  for Z, it will be labelled as Z). This method requires a separate model for each class, which can make it computationally expensive for higher numbers of classes.  In one vs one a model is generated for every combination of one class vs one other class (X vs Y, X vs Z, Y vs Z). Each model will determine a single label for the data instance and will “vote”. The label with the highest number of votes will be applied to the data instance. This method produces N*(N-1)/2 models. This approach can be more accurate than One-vs-All but can become far more computationally involved for higher class counts.       