Topic 7: SVM models  7.2 SVM formulation and solution for linearly separable data  Support Vector Machines (SVM) is a supervised learning  algorithm that in the case of linearly separated data, the solution involves finding the best hyperplane for separating the data points into two classes. SVM tries to find the best hyperplane out of the possible ones, that all points of one category are on one side of it and the remaining on the other. It does this by maximizing the distance between the points in either category, this distance is known as the margin.  SVM is supervised learning and fits under the category of classification.  Something to note is that maximizing 2/||w|| is the same as minimizing Â½ || w || ^2. This problem is known in constraint programming field as quadratic programming.  SVM formulation and solution for linearly non-separable data  It is not always the case that data will be linearly separatable.  While sometimes the margin may be small, in others it is not linearly separatable. As the cases in the figure above.  It is preferable to stay linear classified even with outliers and such. The slack variable give some leeway for the misclassification of outliers.  is used to  7.6 Statistical learning theory of SVM               