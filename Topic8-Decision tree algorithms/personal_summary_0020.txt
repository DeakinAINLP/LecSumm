SVM aims to find a hyperplane so that maximises the space between labelled clusters while still allowing room to account for outliers and noise in the dataset.  Sometimes data can be easily separated with a narrow margin, however this is not always the case especially with noisy data.  To account for potentially noisy data, we use a soft margin, this is where the hyperplane doesn’t separate 100% of the datapoints but can still separate most points resulting in a tolerable accuracy loss in exchange for better applicability for unseen data.  Sometimes dummy features (increasing number of features) can be introduced into the model in the case where the original dataset lacks the necessary dimensionality.  Multi-class classification in SVM works by using multiple hyperplanes to classify data, it does this by creating a plane for each point where the hyperplane represents whether that datapoint is or isn’t for a specific label. Then it can identify each point by labelling that datapoint based on which model it receives the highest score in.  