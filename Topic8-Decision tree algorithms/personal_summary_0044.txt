 OVERVIEW The topic of this topic is support vector machines (SVM), which is a supervised learning method capable of both regression and classification. For classification, the essence of the method is to fit a hyperplane to the data that acts as a separating boundary between the data classes. The optimal separating hyperplane is the one that on average is furthest from all data points and therefore has the widest possible margin separating the data by class. For regression, a hyperplane is fit to the data that has the smallest margin (distance to all data points) that encompasses the data. SVM’s can be used on data that is non-linearly separable using the so called “kernel trick” which maps the input data to a higher dimensional space where it is linearly separable by a hyperplane.  